
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]
No training. Loading data and results from: ./runs/08032024-110732/
WARNING: You did not provide a dataloader id. A new one has been generated: 150855
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 150855
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 399300 


WARNING: No key provided for the context initialization. Initializing at 0.

No training, loading model and results from ./runs/08032024-110732/ folder ...

WARNING: You did not provide a dataloader id. A new one has been generated: 150856
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 9
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (In-Domain): 9.405613e-06


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/08032024-110732/adapt/
 Seed: 6078

==  Begining in-domain visualisation ... ==
    Environment id: 3
    Trajectory id: 15
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/08032024-110732/results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.


=== Beginning adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 5000
    Total number of training steps: 5000
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 20, 2) (20,)
    Epoch:     0     LossContext: 0.03154960
    Epoch:     1     LossContext: 0.01245479
    Epoch:     2     LossContext: 0.00245148
    Epoch:     3     LossContext: 0.00491129
    Epoch:    10     LossContext: 0.00045387
    Epoch:    20     LossContext: 0.00031425
    Epoch:    30     LossContext: 0.00019908
    Epoch:    40     LossContext: 0.00015578
    Epoch:    50     LossContext: 0.00008282
    Epoch:    60     LossContext: 0.00001970
    Epoch:    70     LossContext: 0.00001811
    Epoch:    80     LossContext: 0.00001842
    Epoch:    90     LossContext: 0.00001498
    Epoch:   100     LossContext: 0.00001502
    Epoch:   110     LossContext: 0.00001454
    Epoch:   120     LossContext: 0.00001446
    Epoch:   130     LossContext: 0.00001434
    Epoch:   140     LossContext: 0.00001424
    Epoch:   150     LossContext: 0.00001415
    Epoch:   160     LossContext: 0.00001406
    Epoch:   170     LossContext: 0.00001397
    Epoch:   180     LossContext: 0.00001388
    Epoch:   190     LossContext: 0.00001379
    Epoch:   200     LossContext: 0.00001370
    Epoch:   210     LossContext: 0.00001360
    Epoch:   220     LossContext: 0.00001351
    Epoch:   230     LossContext: 0.00001342
    Epoch:   240     LossContext: 0.00001333
    Epoch:   250     LossContext: 0.00001324
    Epoch:   260     LossContext: 0.00001315
    Epoch:   270     LossContext: 0.00001306
    Epoch:   280     LossContext: 0.00001298
    Epoch:   290     LossContext: 0.00001289
    Epoch:   300     LossContext: 0.00001281
    Epoch:   310     LossContext: 0.00001273
    Epoch:   320     LossContext: 0.00001265
    Epoch:   330     LossContext: 0.00001257
    Epoch:   340     LossContext: 0.00001249
    Epoch:   350     LossContext: 0.00001241
    Epoch:   360     LossContext: 0.00001234
    Epoch:   370     LossContext: 0.00001226
    Epoch:   380     LossContext: 0.00001219
    Epoch:   390     LossContext: 0.00001211
    Epoch:   400     LossContext: 0.00001204
    Epoch:   410     LossContext: 0.00001197
    Epoch:   420     LossContext: 0.00001190
    Epoch:   430     LossContext: 0.00001183
    Epoch:   440     LossContext: 0.00001176
    Epoch:   450     LossContext: 0.00001169
    Epoch:   460     LossContext: 0.00001162
    Epoch:   470     LossContext: 0.00001155
    Epoch:   480     LossContext: 0.00001149
    Epoch:   490     LossContext: 0.00001143
    Epoch:   500     LossContext: 0.00001136
    Epoch:   510     LossContext: 0.00001130
    Epoch:   520     LossContext: 0.00001124
    Epoch:   530     LossContext: 0.00001118
    Epoch:   540     LossContext: 0.00001112
    Epoch:   550     LossContext: 0.00001106
    Epoch:   560     LossContext: 0.00001100
    Epoch:   570     LossContext: 0.00001094
    Epoch:   580     LossContext: 0.00001088
    Epoch:   590     LossContext: 0.00001083
    Epoch:   600     LossContext: 0.00001078
    Epoch:   610     LossContext: 0.00001072
    Epoch:   620     LossContext: 0.00001067
    Epoch:   630     LossContext: 0.00001062
    Epoch:   640     LossContext: 0.00001057
    Epoch:   650     LossContext: 0.00001052
    Epoch:   660     LossContext: 0.00001047
    Epoch:   670     LossContext: 0.00001042
    Epoch:   680     LossContext: 0.00001038
    Epoch:   690     LossContext: 0.00001033
    Epoch:   700     LossContext: 0.00001028
    Epoch:   710     LossContext: 0.00001023
    Epoch:   720     LossContext: 0.00001018
    Epoch:   730     LossContext: 0.00001014
    Epoch:   740     LossContext: 0.00001009
    Epoch:   750     LossContext: 0.00001005
    Epoch:   760     LossContext: 0.00001000
    Epoch:   770     LossContext: 0.00000996
    Epoch:   780     LossContext: 0.00000991
    Epoch:   790     LossContext: 0.00000987
    Epoch:   800     LossContext: 0.00000983
    Epoch:   810     LossContext: 0.00000979
    Epoch:   820     LossContext: 0.00000974
    Epoch:   830     LossContext: 0.00000970
    Epoch:   840     LossContext: 0.00000966
    Epoch:   850     LossContext: 0.00000962
    Epoch:   860     LossContext: 0.00000958
    Epoch:   870     LossContext: 0.00000954
    Epoch:   880     LossContext: 0.00000950
    Epoch:   890     LossContext: 0.00000946
    Epoch:   900     LossContext: 0.00000942
    Epoch:   910     LossContext: 0.00000938
    Epoch:   920     LossContext: 0.00000935
    Epoch:   930     LossContext: 0.00000931
    Epoch:   940     LossContext: 0.00000928
    Epoch:   950     LossContext: 0.00000924
    Epoch:   960     LossContext: 0.00000921
    Epoch:   970     LossContext: 0.00000917
    Epoch:   980     LossContext: 0.00000914
    Epoch:   990     LossContext: 0.00000910
    Epoch:  1000     LossContext: 0.00000907
    Epoch:  1010     LossContext: 0.00000904
    Epoch:  1020     LossContext: 0.00000901
    Epoch:  1030     LossContext: 0.00000897
    Epoch:  1040     LossContext: 0.00000894
    Epoch:  1050     LossContext: 0.00000891
    Epoch:  1060     LossContext: 0.00000888
    Epoch:  1070     LossContext: 0.00000885
    Epoch:  1080     LossContext: 0.00000882
    Epoch:  1090     LossContext: 0.00000879
    Epoch:  1100     LossContext: 0.00000876
    Epoch:  1110     LossContext: 0.00000873
    Epoch:  1120     LossContext: 0.00000870
    Epoch:  1130     LossContext: 0.00000867
    Epoch:  1140     LossContext: 0.00000864
    Epoch:  1150     LossContext: 0.00000861
    Epoch:  1160     LossContext: 0.00000858
    Epoch:  1170     LossContext: 0.00000855
    Epoch:  1180     LossContext: 0.00000853
    Epoch:  1190     LossContext: 0.00000850
    Epoch:  1200     LossContext: 0.00000847
    Epoch:  1210     LossContext: 0.00000844
    Epoch:  1220     LossContext: 0.00000841
    Epoch:  1230     LossContext: 0.00000839
    Epoch:  1240     LossContext: 0.00000836
    Epoch:  1250     LossContext: 0.00000833
    Epoch:  1260     LossContext: 0.00000830
    Epoch:  1270     LossContext: 0.00000828
    Epoch:  1280     LossContext: 0.00000825
    Epoch:  1290     LossContext: 0.00000824
    Epoch:  1300     LossContext: 0.00000822
    Epoch:  1310     LossContext: 0.00000821
    Epoch:  1320     LossContext: 0.00000819
    Epoch:  1330     LossContext: 0.00000818
    Epoch:  1340     LossContext: 0.00000817
    Epoch:  1350     LossContext: 0.00000815
    Epoch:  1360     LossContext: 0.00000814
    Epoch:  1370     LossContext: 0.00000813
    Epoch:  1380     LossContext: 0.00000811
    Epoch:  1390     LossContext: 0.00000810
    Epoch:  1400     LossContext: 0.00000809
    Epoch:  1410     LossContext: 0.00000807
    Epoch:  1420     LossContext: 0.00000806
    Epoch:  1430     LossContext: 0.00000805
    Epoch:  1440     LossContext: 0.00000804
    Epoch:  1450     LossContext: 0.00000802
    Epoch:  1460     LossContext: 0.00000801
    Epoch:  1470     LossContext: 0.00000800
    Epoch:  1480     LossContext: 0.00000798
    Epoch:  1490     LossContext: 0.00000797
    Epoch:  1500     LossContext: 0.00000796
    Epoch:  1510     LossContext: 0.00000795
    Epoch:  1520     LossContext: 0.00000793
    Epoch:  1530     LossContext: 0.00000792
    Epoch:  1540     LossContext: 0.00000791
    Epoch:  1550     LossContext: 0.00000790
    Epoch:  1560     LossContext: 0.00000788
    Epoch:  1570     LossContext: 0.00000787
    Epoch:  1580     LossContext: 0.00000786
    Epoch:  1590     LossContext: 0.00000785
    Epoch:  1600     LossContext: 0.00000784
    Epoch:  1610     LossContext: 0.00000782
    Epoch:  1620     LossContext: 0.00000781
    Epoch:  1630     LossContext: 0.00000780
    Epoch:  1640     LossContext: 0.00000779
    Epoch:  1650     LossContext: 0.00000778
    Epoch:  1660     LossContext: 0.00000777
    Epoch:  1670     LossContext: 0.00000775
    Epoch:  1680     LossContext: 0.00000774
    Epoch:  1690     LossContext: 0.00000773
    Epoch:  1700     LossContext: 0.00000772
    Epoch:  1710     LossContext: 0.00000771
    Epoch:  1720     LossContext: 0.00000770
    Epoch:  1730     LossContext: 0.00000769
    Epoch:  1740     LossContext: 0.00000768
    Epoch:  1750     LossContext: 0.00000766
    Epoch:  1760     LossContext: 0.00000765
    Epoch:  1770     LossContext: 0.00000764
    Epoch:  1780     LossContext: 0.00000763
    Epoch:  1790     LossContext: 0.00000762
    Epoch:  1800     LossContext: 0.00000761
    Epoch:  1810     LossContext: 0.00000760
    Epoch:  1820     LossContext: 0.00000759
    Epoch:  1830     LossContext: 0.00000758
    Epoch:  1840     LossContext: 0.00000757
    Epoch:  1850     LossContext: 0.00000755
    Epoch:  1860     LossContext: 0.00000754
    Epoch:  1870     LossContext: 0.00000753
    Epoch:  1880     LossContext: 0.00000752
    Epoch:  1890     LossContext: 0.00000751
    Epoch:  1900     LossContext: 0.00000750
    Epoch:  1910     LossContext: 0.00000749
    Epoch:  1920     LossContext: 0.00000748
    Epoch:  1930     LossContext: 0.00000747
    Epoch:  1940     LossContext: 0.00000746
    Epoch:  1950     LossContext: 0.00000745
    Epoch:  1960     LossContext: 0.00000744
    Epoch:  1970     LossContext: 0.00000743
    Epoch:  1980     LossContext: 0.00000742
    Epoch:  1990     LossContext: 0.00000741
    Epoch:  2000     LossContext: 0.00000740
    Epoch:  2010     LossContext: 0.00000740
    Epoch:  2020     LossContext: 0.00000739
    Epoch:  2030     LossContext: 0.00000738
    Epoch:  2040     LossContext: 0.00000737
    Epoch:  2050     LossContext: 0.00000736
    Epoch:  2060     LossContext: 0.00000735
    Epoch:  2070     LossContext: 0.00000734
    Epoch:  2080     LossContext: 0.00000733
    Epoch:  2090     LossContext: 0.00000732
    Epoch:  2100     LossContext: 0.00000731
    Epoch:  2110     LossContext: 0.00000730
    Epoch:  2120     LossContext: 0.00000730
    Epoch:  2130     LossContext: 0.00000729
    Epoch:  2140     LossContext: 0.00000728
    Epoch:  2150     LossContext: 0.00000727
    Epoch:  2160     LossContext: 0.00000726
    Epoch:  2170     LossContext: 0.00000725
    Epoch:  2180     LossContext: 0.00000724
    Epoch:  2190     LossContext: 0.00000723
    Epoch:  2200     LossContext: 0.00000723
    Epoch:  2210     LossContext: 0.00000722
    Epoch:  2220     LossContext: 0.00000721
    Epoch:  2230     LossContext: 0.00000720
    Epoch:  2240     LossContext: 0.00000719
    Epoch:  2250     LossContext: 0.00000718
    Epoch:  2260     LossContext: 0.00000718
    Epoch:  2270     LossContext: 0.00000717
    Epoch:  2280     LossContext: 0.00000716
    Epoch:  2290     LossContext: 0.00000715
    Epoch:  2300     LossContext: 0.00000714
    Epoch:  2310     LossContext: 0.00000714
    Epoch:  2320     LossContext: 0.00000713
    Epoch:  2330     LossContext: 0.00000712
    Epoch:  2340     LossContext: 0.00000711
    Epoch:  2350     LossContext: 0.00000710
    Epoch:  2360     LossContext: 0.00000710
    Epoch:  2370     LossContext: 0.00000709
    Epoch:  2380     LossContext: 0.00000708
    Epoch:  2390     LossContext: 0.00000707
    Epoch:  2400     LossContext: 0.00000706
    Epoch:  2410     LossContext: 0.00000706
    Epoch:  2420     LossContext: 0.00000705
    Epoch:  2430     LossContext: 0.00000704
    Epoch:  2440     LossContext: 0.00000703
    Epoch:  2450     LossContext: 0.00000703
    Epoch:  2460     LossContext: 0.00000702
    Epoch:  2470     LossContext: 0.00000701
    Epoch:  2480     LossContext: 0.00000700
    Epoch:  2490     LossContext: 0.00000699
    Epoch:  2500     LossContext: 0.00000699
    Epoch:  2510     LossContext: 0.00000698
    Epoch:  2520     LossContext: 0.00000697
    Epoch:  2530     LossContext: 0.00000696
    Epoch:  2540     LossContext: 0.00000696
    Epoch:  2550     LossContext: 0.00000695
    Epoch:  2560     LossContext: 0.00000694
    Epoch:  2570     LossContext: 0.00000694
    Epoch:  2580     LossContext: 0.00000693
    Epoch:  2590     LossContext: 0.00000693
    Epoch:  2600     LossContext: 0.00000693
    Epoch:  2610     LossContext: 0.00000692
    Epoch:  2620     LossContext: 0.00000692
    Epoch:  2630     LossContext: 0.00000692
    Epoch:  2640     LossContext: 0.00000691
    Epoch:  2650     LossContext: 0.00000691
    Epoch:  2660     LossContext: 0.00000691
    Epoch:  2670     LossContext: 0.00000690
    Epoch:  2680     LossContext: 0.00000690
    Epoch:  2690     LossContext: 0.00000689
    Epoch:  2700     LossContext: 0.00000689
    Epoch:  2710     LossContext: 0.00000689
    Epoch:  2720     LossContext: 0.00000688
    Epoch:  2730     LossContext: 0.00000688
    Epoch:  2740     LossContext: 0.00000688
    Epoch:  2750     LossContext: 0.00000687
    Epoch:  2760     LossContext: 0.00000687
    Epoch:  2770     LossContext: 0.00000687
    Epoch:  2780     LossContext: 0.00000686
    Epoch:  2790     LossContext: 0.00000686
    Epoch:  2800     LossContext: 0.00000686
    Epoch:  2810     LossContext: 0.00000685
    Epoch:  2820     LossContext: 0.00000685
    Epoch:  2830     LossContext: 0.00000685
    Epoch:  2840     LossContext: 0.00000684
    Epoch:  2850     LossContext: 0.00000684
    Epoch:  2860     LossContext: 0.00000684
    Epoch:  2870     LossContext: 0.00000683
    Epoch:  2880     LossContext: 0.00000683
    Epoch:  2890     LossContext: 0.00000683
    Epoch:  2900     LossContext: 0.00000682
    Epoch:  2910     LossContext: 0.00000682
    Epoch:  2920     LossContext: 0.00000681
    Epoch:  2930     LossContext: 0.00000681
    Epoch:  2940     LossContext: 0.00000681
    Epoch:  2950     LossContext: 0.00000680
    Epoch:  2960     LossContext: 0.00000680
    Epoch:  2970     LossContext: 0.00000680
    Epoch:  2980     LossContext: 0.00000679
    Epoch:  2990     LossContext: 0.00000679
    Epoch:  3000     LossContext: 0.00000679
    Epoch:  3010     LossContext: 0.00000678
    Epoch:  3020     LossContext: 0.00000678
    Epoch:  3030     LossContext: 0.00000678
    Epoch:  3040     LossContext: 0.00000677
    Epoch:  3050     LossContext: 0.00000677
    Epoch:  3060     LossContext: 0.00000677
    Epoch:  3070     LossContext: 0.00000676
    Epoch:  3080     LossContext: 0.00000676
    Epoch:  3090     LossContext: 0.00000675
    Epoch:  3100     LossContext: 0.00000675
    Epoch:  3110     LossContext: 0.00000675
    Epoch:  3120     LossContext: 0.00000674
    Epoch:  3130     LossContext: 0.00000674
    Epoch:  3140     LossContext: 0.00000674
    Epoch:  3150     LossContext: 0.00000673
    Epoch:  3160     LossContext: 0.00000673
    Epoch:  3170     LossContext: 0.00000673
    Epoch:  3180     LossContext: 0.00000672
    Epoch:  3190     LossContext: 0.00000672
    Epoch:  3200     LossContext: 0.00000672
    Epoch:  3210     LossContext: 0.00000671
    Epoch:  3220     LossContext: 0.00000671
    Epoch:  3230     LossContext: 0.00000670
    Epoch:  3240     LossContext: 0.00000670
    Epoch:  3250     LossContext: 0.00000670
    Epoch:  3260     LossContext: 0.00000669
    Epoch:  3270     LossContext: 0.00000669
    Epoch:  3280     LossContext: 0.00000669
    Epoch:  3290     LossContext: 0.00000668
    Epoch:  3300     LossContext: 0.00000668
    Epoch:  3310     LossContext: 0.00000667
    Epoch:  3320     LossContext: 0.00000667
    Epoch:  3330     LossContext: 0.00000667
    Epoch:  3340     LossContext: 0.00000666
    Epoch:  3350     LossContext: 0.00000666
    Epoch:  3360     LossContext: 0.00000666
    Epoch:  3370     LossContext: 0.00000665
    Epoch:  3380     LossContext: 0.00000665
    Epoch:  3390     LossContext: 0.00000664
    Epoch:  3400     LossContext: 0.00000664
    Epoch:  3410     LossContext: 0.00000664
    Epoch:  3420     LossContext: 0.00000663
    Epoch:  3430     LossContext: 0.00000663
    Epoch:  3440     LossContext: 0.00000663
    Epoch:  3450     LossContext: 0.00000662
    Epoch:  3460     LossContext: 0.00000662
    Epoch:  3470     LossContext: 0.00000662
    Epoch:  3480     LossContext: 0.00000661
    Epoch:  3490     LossContext: 0.00000661
    Epoch:  3500     LossContext: 0.00000660
    Epoch:  3510     LossContext: 0.00000660
    Epoch:  3520     LossContext: 0.00000660
    Epoch:  3530     LossContext: 0.00000659
    Epoch:  3540     LossContext: 0.00000659
    Epoch:  3550     LossContext: 0.00000659
    Epoch:  3560     LossContext: 0.00000658
    Epoch:  3570     LossContext: 0.00000658
    Epoch:  3580     LossContext: 0.00000658
    Epoch:  3590     LossContext: 0.00000657
    Epoch:  3600     LossContext: 0.00000657
    Epoch:  3610     LossContext: 0.00000656
    Epoch:  3620     LossContext: 0.00000656
    Epoch:  3630     LossContext: 0.00000656
    Epoch:  3640     LossContext: 0.00000655
    Epoch:  3650     LossContext: 0.00000655
    Epoch:  3660     LossContext: 0.00000655
    Epoch:  3670     LossContext: 0.00000654
    Epoch:  3680     LossContext: 0.00000654
    Epoch:  3690     LossContext: 0.00000653
    Epoch:  3700     LossContext: 0.00000653
    Epoch:  3710     LossContext: 0.00000653
    Epoch:  3720     LossContext: 0.00000652
    Epoch:  3730     LossContext: 0.00000652
    Epoch:  3740     LossContext: 0.00000652
    Epoch:  3750     LossContext: 0.00000651
    Epoch:  3760     LossContext: 0.00000651
    Epoch:  3770     LossContext: 0.00000651
    Epoch:  3780     LossContext: 0.00000650
    Epoch:  3790     LossContext: 0.00000650
    Epoch:  3800     LossContext: 0.00000650
    Epoch:  3810     LossContext: 0.00000649
    Epoch:  3820     LossContext: 0.00000649
    Epoch:  3830     LossContext: 0.00000648
    Epoch:  3840     LossContext: 0.00000648
    Epoch:  3850     LossContext: 0.00000648
    Epoch:  3860     LossContext: 0.00000647
    Epoch:  3870     LossContext: 0.00000647
    Epoch:  3880     LossContext: 0.00000647
    Epoch:  3890     LossContext: 0.00000646
    Epoch:  3900     LossContext: 0.00000646
    Epoch:  3910     LossContext: 0.00000646
    Epoch:  3920     LossContext: 0.00000645
    Epoch:  3930     LossContext: 0.00000645
    Epoch:  3940     LossContext: 0.00000645
    Epoch:  3950     LossContext: 0.00000644
    Epoch:  3960     LossContext: 0.00000644
    Epoch:  3970     LossContext: 0.00000644
    Epoch:  3980     LossContext: 0.00000643
    Epoch:  3990     LossContext: 0.00000643
    Epoch:  4000     LossContext: 0.00000643
    Epoch:  4010     LossContext: 0.00000642
    Epoch:  4020     LossContext: 0.00000642
    Epoch:  4030     LossContext: 0.00000642
    Epoch:  4040     LossContext: 0.00000641
    Epoch:  4050     LossContext: 0.00000641
    Epoch:  4060     LossContext: 0.00000641
    Epoch:  4070     LossContext: 0.00000640
    Epoch:  4080     LossContext: 0.00000640
    Epoch:  4090     LossContext: 0.00000640
    Epoch:  4100     LossContext: 0.00000639
    Epoch:  4110     LossContext: 0.00000639
    Epoch:  4120     LossContext: 0.00000639
    Epoch:  4130     LossContext: 0.00000638
    Epoch:  4140     LossContext: 0.00000638
    Epoch:  4150     LossContext: 0.00000638
    Epoch:  4160     LossContext: 0.00000637
    Epoch:  4170     LossContext: 0.00000637
    Epoch:  4180     LossContext: 0.00000636
    Epoch:  4190     LossContext: 0.00000636
    Epoch:  4200     LossContext: 0.00000636
    Epoch:  4210     LossContext: 0.00000635
    Epoch:  4220     LossContext: 0.00000635
    Epoch:  4230     LossContext: 0.00000635
    Epoch:  4240     LossContext: 0.00000634
    Epoch:  4250     LossContext: 0.00000634
    Epoch:  4260     LossContext: 0.00000634
    Epoch:  4270     LossContext: 0.00000633
    Epoch:  4280     LossContext: 0.00000633
    Epoch:  4290     LossContext: 0.00000633
    Epoch:  4300     LossContext: 0.00000632
    Epoch:  4310     LossContext: 0.00000632
    Epoch:  4320     LossContext: 0.00000632
    Epoch:  4330     LossContext: 0.00000631
    Epoch:  4340     LossContext: 0.00000631
    Epoch:  4350     LossContext: 0.00000630
    Epoch:  4360     LossContext: 0.00000630
    Epoch:  4370     LossContext: 0.00000630
    Epoch:  4380     LossContext: 0.00000630
    Epoch:  4390     LossContext: 0.00000629
    Epoch:  4400     LossContext: 0.00000629
    Epoch:  4410     LossContext: 0.00000629
    Epoch:  4420     LossContext: 0.00000629
    Epoch:  4430     LossContext: 0.00000628
    Epoch:  4440     LossContext: 0.00000629
    Epoch:  4450     LossContext: 0.00000628
    Epoch:  4460     LossContext: 0.00000629
    Epoch:  4470     LossContext: 0.00000629
    Epoch:  4480     LossContext: 0.00000631
    Epoch:  4490     LossContext: 0.00000633
    Epoch:  4500     LossContext: 0.00000633
    Epoch:  4510     LossContext: 0.00000648
    Epoch:  4520     LossContext: 0.00000629
    Epoch:  4530     LossContext: 0.00000668
    Epoch:  4540     LossContext: 0.00000649
    Epoch:  4550     LossContext: 0.00000652
    Epoch:  4560     LossContext: 0.00000672
    Epoch:  4570     LossContext: 0.00000627
    Epoch:  4580     LossContext: 0.00000704
    Epoch:  4590     LossContext: 0.00000626
    Epoch:  4600     LossContext: 0.00000668
    Epoch:  4610     LossContext: 0.00000652
    Epoch:  4620     LossContext: 0.00000625
    Epoch:  4630     LossContext: 0.00000707
    Epoch:  4640     LossContext: 0.00000627
    Epoch:  4650     LossContext: 0.00000678
    Epoch:  4660     LossContext: 0.00000631
    Epoch:  4670     LossContext: 0.00000631
    Epoch:  4680     LossContext: 0.00000722
    Epoch:  4690     LossContext: 0.00000623
    Epoch:  4700     LossContext: 0.00000674
    Epoch:  4710     LossContext: 0.00000620
    Epoch:  4720     LossContext: 0.00000629
    Epoch:  4730     LossContext: 0.00000747
    Epoch:  4740     LossContext: 0.00000628
    Epoch:  4750     LossContext: 0.00000657
    Epoch:  4760     LossContext: 0.00000619
    Epoch:  4770     LossContext: 0.00000692
    Epoch:  4780     LossContext: 0.00000624
    Epoch:  4790     LossContext: 0.00000663
    Epoch:  4800     LossContext: 0.00000641
    Epoch:  4810     LossContext: 0.00000621
    Epoch:  4820     LossContext: 0.00000714
    Epoch:  4830     LossContext: 0.00000615
    Epoch:  4840     LossContext: 0.00000674
    Epoch:  4850     LossContext: 0.00000622
    Epoch:  4860     LossContext: 0.00000623
    Epoch:  4870     LossContext: 0.00000727
    Epoch:  4880     LossContext: 0.00000618
    Epoch:  4890     LossContext: 0.00000669
    Epoch:  4900     LossContext: 0.00000613
    Epoch:  4910     LossContext: 0.00000655
    Epoch:  4920     LossContext: 0.00000669
    Epoch:  4930     LossContext: 0.00000636
    Epoch:  4940     LossContext: 0.00000657
    Epoch:  4950     LossContext: 0.00000612
    Epoch:  4960     LossContext: 0.00000678
    Epoch:  4970     LossContext: 0.00000642
    Epoch:  4980     LossContext: 0.00000660
    Epoch:  4990     LossContext: 0.00000628
    Epoch:  4999     LossContext: 0.00000614

Total gradient descent adaptation time: 0 hours 9 mins 50 secs
Environment weights at the end of the adaptation: [1.]

Saving adaptation parameters into ./runs/08032024-110732/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 9
    Number of adaptation environments: 1
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (OOD): 7.4479914e-07

==  Begining out-of-distribution visualisation ... ==
    Environment id: 0
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/08032024-110732/adapt/results_ood.png

Full evaluation of the model on many random seeds


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]


Mean and std of the scores across various datasets

          seed  ind_crit  ood_crit
count 2.00e+01  2.00e+01  2.00e+01
mean  5.61e+03  8.65e-06  2.83e-06
std   2.52e+03  7.16e-07  1.32e-06
