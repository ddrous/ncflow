
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/28032024-212427/
 Seed: 2026


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/28032024-212427/
 Seed: 4052


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Run folder created successfuly: ./runs/28032024-212427/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 212449
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 212450
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 308240 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training ... ===
    Number of examples in a batch: 4
    Number of train steps per epoch: 1
    Number of training epochs: 12000
    Total number of training steps: 12000

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (9, 4, 20, 2) (20,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (9, 4, 20, 2) (20,)
    Epoch:     0      LossTrajs: 1.81051588     ContextsNorm: 0.00000000     ValIndCrit: 1.69905579
    Epoch:     1      LossTrajs: 1.79867864     ContextsNorm: 0.00009955     ValIndCrit: 1.68794501
    Epoch:     2      LossTrajs: 1.78694451     ContextsNorm: 0.00019772     ValIndCrit: 1.67688167
    Epoch:     3      LossTrajs: 1.77525842     ContextsNorm: 0.00029538     ValIndCrit: 1.66586852
    Epoch:    10      LossTrajs: 1.69504881     ContextsNorm: 0.00098763     ValIndCrit: 1.59034157
    Epoch:    20      LossTrajs: 1.58327734     ContextsNorm: 0.00204752     ValIndCrit: 1.48499978
    Epoch:    30      LossTrajs: 1.47043419     ContextsNorm: 0.00323228     ValIndCrit: 1.37841725
    Epoch:    40      LossTrajs: 1.35091472     ContextsNorm: 0.00456352     ValIndCrit: 1.26545393
    Epoch:    50      LossTrajs: 1.21747684     ContextsNorm: 0.00604757     ValIndCrit: 1.13924050
    Epoch:    60      LossTrajs: 1.06050313     ContextsNorm: 0.00768173     ValIndCrit: 0.99091405
    Epoch:    70      LossTrajs: 0.86900747     ContextsNorm: 0.00945012     ValIndCrit: 0.81132168
    Epoch:    80      LossTrajs: 0.64040452     ContextsNorm: 0.01132117     ValIndCrit: 0.60168099
    Epoch:    90      LossTrajs: 0.40956655     ContextsNorm: 0.01321488     ValIndCrit: 0.40435812
    Epoch:   100      LossTrajs: 0.28206250     ContextsNorm: 0.01476456     ValIndCrit: 0.32456502
    Epoch:   110      LossTrajs: 0.28208616     ContextsNorm: 0.01518187     ValIndCrit: 0.34100023
    Epoch:   120      LossTrajs: 0.26776144     ContextsNorm: 0.01466924     ValIndCrit: 0.31874478
    Epoch:   130      LossTrajs: 0.26232326     ContextsNorm: 0.01422186     ValIndCrit: 0.30834070
    Epoch:   140      LossTrajs: 0.25920725     ContextsNorm: 0.01408189     ValIndCrit: 0.30512014
    Epoch:   150      LossTrajs: 0.25606090     ContextsNorm: 0.01403332     ValIndCrit: 0.30374089
    Epoch:   160      LossTrajs: 0.25396490     ContextsNorm: 0.01391143     ValIndCrit: 0.30184761
    Epoch:   170      LossTrajs: 0.25175324     ContextsNorm: 0.01372859     ValIndCrit: 0.29896298
    Epoch:   180      LossTrajs: 0.24981907     ContextsNorm: 0.01354969     ValIndCrit: 0.29631153
    Epoch:   190      LossTrajs: 0.24774002     ContextsNorm: 0.01339326     ValIndCrit: 0.29409188
    Epoch:   200      LossTrajs: 0.24574834     ContextsNorm: 0.01324201     ValIndCrit: 0.29197034
    Epoch:   210      LossTrajs: 0.24375309     ContextsNorm: 0.01308345     ValIndCrit: 0.28971502
    Epoch:   220      LossTrajs: 0.24163614     ContextsNorm: 0.01292460     ValIndCrit: 0.28732231
    Epoch:   230      LossTrajs: 0.23946472     ContextsNorm: 0.01285607     ValIndCrit: 0.28488001
