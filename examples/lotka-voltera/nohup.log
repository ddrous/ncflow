
############# Neural Context Flow #############

Jax version: 0.4.28
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/06082024-103701/
 Seed: 2026


############# Neural Context Flow #############

Jax version: 0.4.28
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/06082024-103701/
 Seed: 4052


############# Neural Context Flow #############

Jax version: 0.4.28
Available devices: [cuda(id=0)]
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 103719
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 103719
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 308240 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training ... ===
    Number of examples in a batch: 4
    Number of train steps per epoch: 1
    Number of training epochs: 1200
    Total number of training steps: 1200

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (9, 4, 20, 2) (20,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (9, 4, 20, 2) (20,)
    Epoch:     0      LossTrajs: 1.81051505     ContextsNorm: 0.00000000     ValIndCrit: 1.67688715
    Epoch:     1      LossTrajs: 1.77526259     ContextsNorm: 0.00029862     ValIndCrit: 1.64407837
    Epoch:     2      LossTrajs: 1.74059379     ContextsNorm: 0.00058607     ValIndCrit: 1.61175835
    Epoch:     3      LossTrajs: 1.70642138     ContextsNorm: 0.00087280     ValIndCrit: 1.57988763
    Epoch:    10      LossTrajs: 1.47491801     ContextsNorm: 0.00294749     ValIndCrit: 1.36252010
    Epoch:    20      LossTrajs: 1.12891471     ContextsNorm: 0.00619634     ValIndCrit: 1.03462923
    Epoch:    30      LossTrajs: 0.69413924     ContextsNorm: 0.00987164     ValIndCrit: 0.62675971
    Epoch:    40      LossTrajs: 0.28609121     ContextsNorm: 0.01380285     ValIndCrit: 0.32579455
    Epoch:    50      LossTrajs: 0.29696023     ContextsNorm: 0.01396704     ValIndCrit: 0.34930059
    Epoch:    60      LossTrajs: 0.26092190     ContextsNorm: 0.01227916     ValIndCrit: 0.30364108
    Epoch:    70      LossTrajs: 0.25444230     ContextsNorm: 0.01194682     ValIndCrit: 0.29646894
    Epoch:    80      LossTrajs: 0.24606827     ContextsNorm: 0.01198325     ValIndCrit: 0.29396299
    Epoch:    90      LossTrajs: 0.24016875     ContextsNorm: 0.01193300     ValIndCrit: 0.28629911
    Epoch:   100      LossTrajs: 0.23394956     ContextsNorm: 0.01195142     ValIndCrit: 0.27751172
    Epoch:   110      LossTrajs: 0.22760250     ContextsNorm: 0.01205641     ValIndCrit: 0.27036586
    Epoch:   120      LossTrajs: 0.22086754     ContextsNorm: 0.01213041     ValIndCrit: 0.26261660
    Epoch:   130      LossTrajs: 0.21365543     ContextsNorm: 0.01213784     ValIndCrit: 0.25341693
    Epoch:   140      LossTrajs: 0.20591280     ContextsNorm: 0.01232872     ValIndCrit: 0.24332979
    Epoch:   150      LossTrajs: 0.19759224     ContextsNorm: 0.01251165     ValIndCrit: 0.23245059
    Epoch:   160      LossTrajs: 0.18877818     ContextsNorm: 0.01267962     ValIndCrit: 0.22054179
    Epoch:   170      LossTrajs: 0.17965989     ContextsNorm: 0.01289425     ValIndCrit: 0.20785464
    Epoch:   180      LossTrajs: 0.17051364     ContextsNorm: 0.01325476     ValIndCrit: 0.19481184
    Epoch:   190      LossTrajs: 0.16162515     ContextsNorm: 0.01359062     ValIndCrit: 0.18181951
    Epoch:   200      LossTrajs: 0.15310633     ContextsNorm: 0.01386473     ValIndCrit: 0.16908215
    Epoch:   210      LossTrajs: 0.14470613     ContextsNorm: 0.01404692     ValIndCrit: 0.15650944
    Epoch:   220      LossTrajs: 0.13585885     ContextsNorm: 0.01411356     ValIndCrit: 0.14381316
    Epoch:   230      LossTrajs: 0.12593901     ContextsNorm: 0.01406157     ValIndCrit: 0.13088079
    Epoch:   240      LossTrajs: 0.11500495     ContextsNorm: 0.01396212     ValIndCrit: 0.11803725
    Epoch:   250      LossTrajs: 0.10374942     ContextsNorm: 0.01392146     ValIndCrit: 0.10594648
    Epoch:   260      LossTrajs: 0.09310999     ContextsNorm: 0.01388481     ValIndCrit: 0.09511176
    Epoch:   270      LossTrajs: 0.08370952     ContextsNorm: 0.01384280     ValIndCrit: 0.08579338
    Epoch:   280      LossTrajs: 0.07569477     ContextsNorm: 0.01381175     ValIndCrit: 0.07803236
    Epoch:   290      LossTrajs: 0.06926804     ContextsNorm: 0.01382440     ValIndCrit: 0.07171690
    Epoch:   300      LossTrajs: 0.06420325     ContextsNorm: 0.01388524     ValIndCrit: 0.06665008
    Epoch:   310      LossTrajs: 0.06025919     ContextsNorm: 0.01398644     ValIndCrit: 0.06262249
    Epoch:   320      LossTrajs: 0.05712979     ContextsNorm: 0.01412081     ValIndCrit: 0.05937656
    Epoch:   330      LossTrajs: 0.05450072     ContextsNorm: 0.01428446     ValIndCrit: 0.05664416
    Epoch:   340      LossTrajs: 0.05239836     ContextsNorm: 0.01447692     ValIndCrit: 0.05420553
    Epoch:   350      LossTrajs: 0.05013497     ContextsNorm: 0.01466025     ValIndCrit: 0.05189624
    Epoch:   360      LossTrajs: 0.04795634     ContextsNorm: 0.01488870     ValIndCrit: 0.04978744
    Epoch:   370      LossTrajs: 0.04598027     ContextsNorm: 0.01516790     ValIndCrit: 0.04785218
    Epoch:   380      LossTrajs: 0.04401393     ContextsNorm: 0.01545945     ValIndCrit: 0.04612186
    Epoch:   390      LossTrajs: 0.04186653     ContextsNorm: 0.01575930     ValIndCrit: 0.04446714
    Epoch:   400      LossTrajs: 0.03962656     ContextsNorm: 0.01608570     ValIndCrit: 0.04190453
    Epoch:   410      LossTrajs: 0.03669590     ContextsNorm: 0.01648862     ValIndCrit: 0.03840470
    Epoch:   420      LossTrajs: 0.03170335     ContextsNorm: 0.01699653     ValIndCrit: 0.03262904
    Epoch:   430      LossTrajs: 0.02482282     ContextsNorm: 0.01753413     ValIndCrit: 0.02565858
    Epoch:   440      LossTrajs: 0.02129798     ContextsNorm: 0.01795620     ValIndCrit: 0.02264409
    Epoch:   450      LossTrajs: 0.01950255     ContextsNorm: 0.01806225     ValIndCrit: 0.02069079
    Epoch:   460      LossTrajs: 0.01818966     ContextsNorm: 0.01801962     ValIndCrit: 0.01943460
    Epoch:   470      LossTrajs: 0.01715278     ContextsNorm: 0.01797060     ValIndCrit: 0.01862229
    Epoch:   480      LossTrajs: 0.01628452     ContextsNorm: 0.01798053     ValIndCrit: 0.01777018
    Epoch:   490      LossTrajs: 0.01588267     ContextsNorm: 0.01801828     ValIndCrit: 0.01715352
    Epoch:   500      LossTrajs: 0.01477832     ContextsNorm: 0.01801816     ValIndCrit: 0.01626616
    Epoch:   510      LossTrajs: 0.01394894     ContextsNorm: 0.01798699     ValIndCrit: 0.01530797
    Epoch:   520      LossTrajs: 0.01310610     ContextsNorm: 0.01799743     ValIndCrit: 0.01455480
    Epoch:   530      LossTrajs: 0.01233625     ContextsNorm: 0.01804523     ValIndCrit: 0.01389365
    Epoch:   540      LossTrajs: 0.01160832     ContextsNorm: 0.01809482     ValIndCrit: 0.01322453
    Epoch:   550      LossTrajs: 0.01096405     ContextsNorm: 0.01815364     ValIndCrit: 0.01257985
    Epoch:   560      LossTrajs: 0.01037859     ContextsNorm: 0.01822725     ValIndCrit: 0.01199968
    Epoch:   570      LossTrajs: 0.00984479     ContextsNorm: 0.01829628     ValIndCrit: 0.01148524
    Epoch:   580      LossTrajs: 0.00944168     ContextsNorm: 0.01835782     ValIndCrit: 0.01101303
    Epoch:   590      LossTrajs: 0.00896693     ContextsNorm: 0.01842588     ValIndCrit: 0.01059546
    Epoch:   600      LossTrajs: 0.00853394     ContextsNorm: 0.01847608     ValIndCrit: 0.01028080
    Epoch:   610      LossTrajs: 0.00814930     ContextsNorm: 0.01850715     ValIndCrit: 0.00997645
    Epoch:   620      LossTrajs: 0.00784273     ContextsNorm: 0.01852952     ValIndCrit: 0.00974152
    Epoch:   630      LossTrajs: 0.00749366     ContextsNorm: 0.01852832     ValIndCrit: 0.00947512
    Epoch:   640      LossTrajs: 0.00715690     ContextsNorm: 0.01853568     ValIndCrit: 0.00926928
    Epoch:   650      LossTrajs: 0.00688607     ContextsNorm: 0.01854502     ValIndCrit: 0.00902847
    Epoch:   660      LossTrajs: 0.00666509     ContextsNorm: 0.01855327     ValIndCrit: 0.00881371
    Epoch:   670      LossTrajs: 0.00650027     ContextsNorm: 0.01855264     ValIndCrit: 0.00865784
    Epoch:   680      LossTrajs: 0.00628737     ContextsNorm: 0.01851034     ValIndCrit: 0.00857363
    Epoch:   690      LossTrajs: 0.00605752     ContextsNorm: 0.01847289     ValIndCrit: 0.00838685
    Epoch:   700      LossTrajs: 0.00585885     ContextsNorm: 0.01846582     ValIndCrit: 0.00820164
    Epoch:   710      LossTrajs: 0.00567552     ContextsNorm: 0.01845289     ValIndCrit: 0.00802449
    Epoch:   720      LossTrajs: 0.00556073     ContextsNorm: 0.01843805     ValIndCrit: 0.00779304
    Epoch:   730      LossTrajs: 0.00538672     ContextsNorm: 0.01842223     ValIndCrit: 0.00765634
    Epoch:   740      LossTrajs: 0.00522281     ContextsNorm: 0.01840852     ValIndCrit: 0.00753178
    Epoch:   750      LossTrajs: 0.00506342     ContextsNorm: 0.01840594     ValIndCrit: 0.00737438
    Epoch:   760      LossTrajs: 0.00494087     ContextsNorm: 0.01842115     ValIndCrit: 0.00721666
    Epoch:   770      LossTrajs: 0.00477623     ContextsNorm: 0.01842912     ValIndCrit: 0.00702732
    Epoch:   780      LossTrajs: 0.00462096     ContextsNorm: 0.01843570     ValIndCrit: 0.00687272
    Epoch:   790      LossTrajs: 0.00447086     ContextsNorm: 0.01845556     ValIndCrit: 0.00671700
    Epoch:   800      LossTrajs: 0.00432516     ContextsNorm: 0.01848372     ValIndCrit: 0.00654960
    Epoch:   810      LossTrajs: 0.00418485     ContextsNorm: 0.01851802     ValIndCrit: 0.00638612
    Epoch:   820      LossTrajs: 0.00405162     ContextsNorm: 0.01855433     ValIndCrit: 0.00621932
    Epoch:   830      LossTrajs: 0.00392680     ContextsNorm: 0.01859248     ValIndCrit: 0.00605617
    Epoch:   840      LossTrajs: 0.00381195     ContextsNorm: 0.01863050     ValIndCrit: 0.00590179
    Epoch:   850      LossTrajs: 0.00370669     ContextsNorm: 0.01866764     ValIndCrit: 0.00575352
    Epoch:   860      LossTrajs: 0.00361039     ContextsNorm: 0.01870219     ValIndCrit: 0.00560349
    Epoch:   870      LossTrajs: 0.00352071     ContextsNorm: 0.01873353     ValIndCrit: 0.00546202
    Epoch:   880      LossTrajs: 0.00343618     ContextsNorm: 0.01876132     ValIndCrit: 0.00533031
    Epoch:   890      LossTrajs: 0.00335447     ContextsNorm: 0.01878580     ValIndCrit: 0.00520413
    Epoch:   900      LossTrajs: 0.00327442     ContextsNorm: 0.01880796     ValIndCrit: 0.00508723
    Epoch:   910      LossTrajs: 0.00319496     ContextsNorm: 0.01882830     ValIndCrit: 0.00496859
    Epoch:   920      LossTrajs: 0.00311674     ContextsNorm: 0.01884753     ValIndCrit: 0.00485926
    Epoch:   930      LossTrajs: 0.00303902     ContextsNorm: 0.01886660     ValIndCrit: 0.00474392
    Epoch:   940      LossTrajs: 0.00296177     ContextsNorm: 0.01888616     ValIndCrit: 0.00463531
    Epoch:   950      LossTrajs: 0.00288443     ContextsNorm: 0.01890545     ValIndCrit: 0.00453484
    Epoch:   960      LossTrajs: 0.00280775     ContextsNorm: 0.01892521     ValIndCrit: 0.00442198
    Epoch:   970      LossTrajs: 0.00273177     ContextsNorm: 0.01894502     ValIndCrit: 0.00431864
    Epoch:   980      LossTrajs: 0.00265631     ContextsNorm: 0.01896504     ValIndCrit: 0.00421732
    Epoch:   990      LossTrajs: 0.00258128     ContextsNorm: 0.01898469     ValIndCrit: 0.00411073
    Epoch:  1000      LossTrajs: 0.00250726     ContextsNorm: 0.01900384     ValIndCrit: 0.00400344
    Epoch:  1010      LossTrajs: 0.00243369     ContextsNorm: 0.01902278     ValIndCrit: 0.00391560
    Epoch:  1020      LossTrajs: 0.00239083     ContextsNorm: 0.01904158     ValIndCrit: 0.00381615
    Epoch:  1030      LossTrajs: 0.00230470     ContextsNorm: 0.01905639     ValIndCrit: 0.00370853
    Epoch:  1040      LossTrajs: 0.00222718     ContextsNorm: 0.01907571     ValIndCrit: 0.00358473
    Epoch:  1050      LossTrajs: 0.00215338     ContextsNorm: 0.01909056     ValIndCrit: 0.00348771
    Epoch:  1060      LossTrajs: 0.00208239     ContextsNorm: 0.01909967     ValIndCrit: 0.00338711
    Epoch:  1070      LossTrajs: 0.00202095     ContextsNorm: 0.01911052     ValIndCrit: 0.00328664
    Epoch:  1080      LossTrajs: 0.00195152     ContextsNorm: 0.01912734     ValIndCrit: 0.00322137
    Epoch:  1090      LossTrajs: 0.00188757     ContextsNorm: 0.01913666     ValIndCrit: 0.00313309
    Epoch:  1100      LossTrajs: 0.00182693     ContextsNorm: 0.01915051     ValIndCrit: 0.00305103
    Epoch:  1110      LossTrajs: 0.00177184     ContextsNorm: 0.01916808     ValIndCrit: 0.00296996
    Epoch:  1120      LossTrajs: 0.00171223     ContextsNorm: 0.01918398     ValIndCrit: 0.00288736
    Epoch:  1130      LossTrajs: 0.00165629     ContextsNorm: 0.01919403     ValIndCrit: 0.00281290
    Epoch:  1140      LossTrajs: 0.00160204     ContextsNorm: 0.01920160     ValIndCrit: 0.00273995
    Epoch:  1150      LossTrajs: 0.00155074     ContextsNorm: 0.01921013     ValIndCrit: 0.00267718
    Epoch:  1160      LossTrajs: 0.00150145     ContextsNorm: 0.01921947     ValIndCrit: 0.00261441
    Epoch:  1170      LossTrajs: 0.00145394     ContextsNorm: 0.01922818     ValIndCrit: 0.00254838
    Epoch:  1180      LossTrajs: 0.00140840     ContextsNorm: 0.01923628     ValIndCrit: 0.00248532
    Epoch:  1190      LossTrajs: 0.00136467     ContextsNorm: 0.01924288     ValIndCrit: 0.00242521
    Epoch:  1199      LossTrajs: 0.00132665     ContextsNorm: 0.01924803     ValIndCrit: 0.00237399

Total gradient descent training time: 0 hours 7 mins 18 secs
Environment weights at the end of the training: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111
 0.11111111 0.11111111 0.11111111]
WARNING: You did not provide a dataloader id. A new one has been generated: 104438
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 9
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (In-Domain): 0.002373993


############# Neural Context Flow #############

Jax version: 0.4.28
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/06082024-103701/adapt/
 Seed: 6078


############# Neural Context Flow #############

Jax version: 0.4.28
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt_test
 Savepath: ./runs/06082024-103701/adapt/
 Seed: 6078

==  Begining in-domain visualisation ... ==
    Environment id: 4
    Trajectory id: 30
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/06082024-103701/results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 1500
    Total number of training steps: 1500

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 20, 2) (20,)
    Epoch:     0     LossContext: 0.01168468
    Epoch:     1     LossContext: 0.00305951
    Epoch:     2     LossContext: 0.00147197
    Epoch:     3     LossContext: 0.00484161
    Epoch:    10     LossContext: 0.00199958
    Epoch:    20     LossContext: 0.00086202
    Epoch:    30     LossContext: 0.00066186
    Epoch:    40     LossContext: 0.00063954
    Epoch:    50     LossContext: 0.00056089
    Epoch:    60     LossContext: 0.00055954
    Epoch:    70     LossContext: 0.00055614
    Epoch:    80     LossContext: 0.00055467
    Epoch:    90     LossContext: 0.00055361
    Epoch:   100     LossContext: 0.00055258
    Epoch:   110     LossContext: 0.00055162
    Epoch:   120     LossContext: 0.00055066
    Epoch:   130     LossContext: 0.00054969
    Epoch:   140     LossContext: 0.00054872
    Epoch:   150     LossContext: 0.00054777
    Epoch:   160     LossContext: 0.00054682
    Epoch:   170     LossContext: 0.00054589
    Epoch:   180     LossContext: 0.00054498
    Epoch:   190     LossContext: 0.00054412
    Epoch:   200     LossContext: 0.00054328
    Epoch:   210     LossContext: 0.00054247
    Epoch:   220     LossContext: 0.00054166
    Epoch:   230     LossContext: 0.00054088
    Epoch:   240     LossContext: 0.00054011
    Epoch:   250     LossContext: 0.00053936
    Epoch:   260     LossContext: 0.00053861
    Epoch:   270     LossContext: 0.00053788
    Epoch:   280     LossContext: 0.00053717
    Epoch:   290     LossContext: 0.00053648
    Epoch:   300     LossContext: 0.00053579
    Epoch:   310     LossContext: 0.00053512
    Epoch:   320     LossContext: 0.00053447
    Epoch:   330     LossContext: 0.00053383
    Epoch:   340     LossContext: 0.00053320
    Epoch:   350     LossContext: 0.00053258
    Epoch:   360     LossContext: 0.00053197
    Epoch:   370     LossContext: 0.00053137
    Epoch:   380     LossContext: 0.00053077
    Epoch:   390     LossContext: 0.00053020
    Epoch:   400     LossContext: 0.00052963
    Epoch:   410     LossContext: 0.00052907
    Epoch:   420     LossContext: 0.00052852
    Epoch:   430     LossContext: 0.00052799
    Epoch:   440     LossContext: 0.00052746
    Epoch:   450     LossContext: 0.00052694
    Epoch:   460     LossContext: 0.00052643
    Epoch:   470     LossContext: 0.00052593
    Epoch:   480     LossContext: 0.00052544
    Epoch:   490     LossContext: 0.00052495
    Epoch:   500     LossContext: 0.00052447
    Epoch:   510     LossContext: 0.00052400
    Epoch:   520     LossContext: 0.00052354
    Epoch:   530     LossContext: 0.00052309
    Epoch:   540     LossContext: 0.00052264
    Epoch:   550     LossContext: 0.00052220
    Epoch:   560     LossContext: 0.00052177
    Epoch:   570     LossContext: 0.00052135
    Epoch:   580     LossContext: 0.00052093
    Epoch:   590     LossContext: 0.00052053
    Epoch:   600     LossContext: 0.00052012
    Epoch:   610     LossContext: 0.00051973
    Epoch:   620     LossContext: 0.00051934
    Epoch:   630     LossContext: 0.00051895
    Epoch:   640     LossContext: 0.00051858
    Epoch:   650     LossContext: 0.00051821
    Epoch:   660     LossContext: 0.00051784
    Epoch:   670     LossContext: 0.00051748
    Epoch:   680     LossContext: 0.00051713
    Epoch:   690     LossContext: 0.00051677
    Epoch:   700     LossContext: 0.00051643
    Epoch:   710     LossContext: 0.00051609
    Epoch:   720     LossContext: 0.00051575
    Epoch:   730     LossContext: 0.00051542
    Epoch:   740     LossContext: 0.00051510
    Epoch:   750     LossContext: 0.00051477
    Epoch:   760     LossContext: 0.00051446
    Epoch:   770     LossContext: 0.00051415
    Epoch:   780     LossContext: 0.00051384
    Epoch:   790     LossContext: 0.00051353
    Epoch:   800     LossContext: 0.00051323
    Epoch:   810     LossContext: 0.00051294
    Epoch:   820     LossContext: 0.00051265
    Epoch:   830     LossContext: 0.00051236
    Epoch:   840     LossContext: 0.00051208
    Epoch:   850     LossContext: 0.00051179
    Epoch:   860     LossContext: 0.00051152
    Epoch:   870     LossContext: 0.00051124
    Epoch:   880     LossContext: 0.00051097
    Epoch:   890     LossContext: 0.00051071
    Epoch:   900     LossContext: 0.00051044
    Epoch:   910     LossContext: 0.00051019
    Epoch:   920     LossContext: 0.00050993
    Epoch:   930     LossContext: 0.00050967
    Epoch:   940     LossContext: 0.00050942
    Epoch:   950     LossContext: 0.00050917
    Epoch:   960     LossContext: 0.00050893
    Epoch:   970     LossContext: 0.00050868
    Epoch:   980     LossContext: 0.00050845
    Epoch:   990     LossContext: 0.00050821
    Epoch:  1000     LossContext: 0.00050797
    Epoch:  1010     LossContext: 0.00050774
    Epoch:  1020     LossContext: 0.00050751
    Epoch:  1030     LossContext: 0.00050728
    Epoch:  1040     LossContext: 0.00050705
    Epoch:  1050     LossContext: 0.00050683
    Epoch:  1060     LossContext: 0.00050660
    Epoch:  1070     LossContext: 0.00050638
    Epoch:  1080     LossContext: 0.00050616
    Epoch:  1090     LossContext: 0.00050594
    Epoch:  1100     LossContext: 0.00050573
    Epoch:  1110     LossContext: 0.00050551
    Epoch:  1120     LossContext: 0.00050530
    Epoch:  1130     LossContext: 0.00050509
    Epoch:  1140     LossContext: 0.00050489
    Epoch:  1150     LossContext: 0.00050468
    Epoch:  1160     LossContext: 0.00050448
    Epoch:  1170     LossContext: 0.00050427
    Epoch:  1180     LossContext: 0.00050407
    Epoch:  1190     LossContext: 0.00050387
    Epoch:  1200     LossContext: 0.00050367
    Epoch:  1210     LossContext: 0.00050347
    Epoch:  1220     LossContext: 0.00050328
    Epoch:  1230     LossContext: 0.00050308
    Epoch:  1240     LossContext: 0.00050289
    Epoch:  1250     LossContext: 0.00050270
    Epoch:  1260     LossContext: 0.00050250
    Epoch:  1270     LossContext: 0.00050231
    Epoch:  1280     LossContext: 0.00050212
    Epoch:  1290     LossContext: 0.00050194
    Epoch:  1300     LossContext: 0.00050175
    Epoch:  1310     LossContext: 0.00050157
    Epoch:  1320     LossContext: 0.00050138
    Epoch:  1330     LossContext: 0.00050120
    Epoch:  1340     LossContext: 0.00050103
    Epoch:  1350     LossContext: 0.00050085
    Epoch:  1360     LossContext: 0.00050067
    Epoch:  1370     LossContext: 0.00050049
    Epoch:  1380     LossContext: 0.00050032
    Epoch:  1390     LossContext: 0.00050014
    Epoch:  1400     LossContext: 0.00049996
    Epoch:  1410     LossContext: 0.00049979
    Epoch:  1420     LossContext: 0.00049962
    Epoch:  1430     LossContext: 0.00049945
    Epoch:  1440     LossContext: 0.00049928
    Epoch:  1450     LossContext: 0.00049911
    Epoch:  1460     LossContext: 0.00049893
    Epoch:  1470     LossContext: 0.00049877
    Epoch:  1480     LossContext: 0.00049860
    Epoch:  1490     LossContext: 0.00049844
    Epoch:  1499     LossContext: 0.00049829

Gradient descent adaptation time: 0 hours 0 mins 51 secs

Adapting to environment 1 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.08891252
    Epoch:     1     LossContext: 0.05806850
    Epoch:     2     LossContext: 0.03340244
    Epoch:     3     LossContext: 0.01608528
    Epoch:    10     LossContext: 0.00277882
    Epoch:    20     LossContext: 0.00372732
    Epoch:    30     LossContext: 0.00297677
    Epoch:    40     LossContext: 0.00159652
    Epoch:    50     LossContext: 0.00126970
    Epoch:    60     LossContext: 0.00128396
    Epoch:    70     LossContext: 0.00119896
    Epoch:    80     LossContext: 0.00119613
    Epoch:    90     LossContext: 0.00119091
    Epoch:   100     LossContext: 0.00118711
    Epoch:   110     LossContext: 0.00118655
    Epoch:   120     LossContext: 0.00118519
    Epoch:   130     LossContext: 0.00118445
    Epoch:   140     LossContext: 0.00118353
    Epoch:   150     LossContext: 0.00118267
    Epoch:   160     LossContext: 0.00118176
    Epoch:   170     LossContext: 0.00118085
    Epoch:   180     LossContext: 0.00117991
    Epoch:   190     LossContext: 0.00117894
    Epoch:   200     LossContext: 0.00117796
    Epoch:   210     LossContext: 0.00117696
    Epoch:   220     LossContext: 0.00117594
    Epoch:   230     LossContext: 0.00117490
    Epoch:   240     LossContext: 0.00117385
    Epoch:   250     LossContext: 0.00117278
    Epoch:   260     LossContext: 0.00117170
    Epoch:   270     LossContext: 0.00117060
    Epoch:   280     LossContext: 0.00116949
    Epoch:   290     LossContext: 0.00116836
    Epoch:   300     LossContext: 0.00116722
    Epoch:   310     LossContext: 0.00116607
    Epoch:   320     LossContext: 0.00116492
    Epoch:   330     LossContext: 0.00116375
    Epoch:   340     LossContext: 0.00116257
    Epoch:   350     LossContext: 0.00116138
    Epoch:   360     LossContext: 0.00116018
    Epoch:   370     LossContext: 0.00115899
    Epoch:   380     LossContext: 0.00115778
    Epoch:   390     LossContext: 0.00115657
    Epoch:   400     LossContext: 0.00115534
    Epoch:   410     LossContext: 0.00115412
    Epoch:   420     LossContext: 0.00115289
    Epoch:   430     LossContext: 0.00115165
    Epoch:   440     LossContext: 0.00115043
    Epoch:   450     LossContext: 0.00114920
    Epoch:   460     LossContext: 0.00114796
    Epoch:   470     LossContext: 0.00114673
    Epoch:   480     LossContext: 0.00114551
    Epoch:   490     LossContext: 0.00114429
    Epoch:   500     LossContext: 0.00114308
    Epoch:   510     LossContext: 0.00114187
    Epoch:   520     LossContext: 0.00114066
    Epoch:   530     LossContext: 0.00113946
    Epoch:   540     LossContext: 0.00113825
    Epoch:   550     LossContext: 0.00113706
    Epoch:   560     LossContext: 0.00113587
    Epoch:   570     LossContext: 0.00113470
    Epoch:   580     LossContext: 0.00113354
    Epoch:   590     LossContext: 0.00113238
    Epoch:   600     LossContext: 0.00113123
    Epoch:   610     LossContext: 0.00113009
    Epoch:   620     LossContext: 0.00112897
    Epoch:   630     LossContext: 0.00112787
    Epoch:   640     LossContext: 0.00112676
    Epoch:   650     LossContext: 0.00112567
    Epoch:   660     LossContext: 0.00112458
    Epoch:   670     LossContext: 0.00112350
    Epoch:   680     LossContext: 0.00112242
    Epoch:   690     LossContext: 0.00112136
    Epoch:   700     LossContext: 0.00112029
    Epoch:   710     LossContext: 0.00111924
    Epoch:   720     LossContext: 0.00111819
    Epoch:   730     LossContext: 0.00111716
    Epoch:   740     LossContext: 0.00111614
    Epoch:   750     LossContext: 0.00111513
    Epoch:   760     LossContext: 0.00111412
    Epoch:   770     LossContext: 0.00111313
    Epoch:   780     LossContext: 0.00111215
    Epoch:   790     LossContext: 0.00111118
    Epoch:   800     LossContext: 0.00111023
    Epoch:   810     LossContext: 0.00110928
    Epoch:   820     LossContext: 0.00110835
    Epoch:   830     LossContext: 0.00110742
    Epoch:   840     LossContext: 0.00110651
    Epoch:   850     LossContext: 0.00110561
    Epoch:   860     LossContext: 0.00110470
    Epoch:   870     LossContext: 0.00110381
    Epoch:   880     LossContext: 0.00110294
    Epoch:   890     LossContext: 0.00110207
    Epoch:   900     LossContext: 0.00110120
    Epoch:   910     LossContext: 0.00110034
    Epoch:   920     LossContext: 0.00109949
    Epoch:   930     LossContext: 0.00109865
    Epoch:   940     LossContext: 0.00109782
    Epoch:   950     LossContext: 0.00109700
    Epoch:   960     LossContext: 0.00109619
    Epoch:   970     LossContext: 0.00109539
    Epoch:   980     LossContext: 0.00109460
    Epoch:   990     LossContext: 0.00109382
    Epoch:  1000     LossContext: 0.00109304
    Epoch:  1010     LossContext: 0.00109228
    Epoch:  1020     LossContext: 0.00109153
    Epoch:  1030     LossContext: 0.00109078
    Epoch:  1040     LossContext: 0.00109004
    Epoch:  1050     LossContext: 0.00108931
    Epoch:  1060     LossContext: 0.00108859
    Epoch:  1070     LossContext: 0.00108788
    Epoch:  1080     LossContext: 0.00108717
    Epoch:  1090     LossContext: 0.00108647
    Epoch:  1100     LossContext: 0.00108579
    Epoch:  1110     LossContext: 0.00108510
    Epoch:  1120     LossContext: 0.00108443
    Epoch:  1130     LossContext: 0.00108376
    Epoch:  1140     LossContext: 0.00108310
    Epoch:  1150     LossContext: 0.00108244
    Epoch:  1160     LossContext: 0.00108179
    Epoch:  1170     LossContext: 0.00108115
    Epoch:  1180     LossContext: 0.00108052
    Epoch:  1190     LossContext: 0.00107991
    Epoch:  1200     LossContext: 0.00107929
    Epoch:  1210     LossContext: 0.00107869
    Epoch:  1220     LossContext: 0.00107809
    Epoch:  1230     LossContext: 0.00107750
    Epoch:  1240     LossContext: 0.00107692
    Epoch:  1250     LossContext: 0.00107635
    Epoch:  1260     LossContext: 0.00107578
    Epoch:  1270     LossContext: 0.00107522
    Epoch:  1280     LossContext: 0.00107466
    Epoch:  1290     LossContext: 0.00107411
    Epoch:  1300     LossContext: 0.00107357
    Epoch:  1310     LossContext: 0.00107303
    Epoch:  1320     LossContext: 0.00107251
    Epoch:  1330     LossContext: 0.00107198
    Epoch:  1340     LossContext: 0.00107147
    Epoch:  1350     LossContext: 0.00107096
    Epoch:  1360     LossContext: 0.00107047
    Epoch:  1370     LossContext: 0.00106997
    Epoch:  1380     LossContext: 0.00106949
    Epoch:  1390     LossContext: 0.00106902
    Epoch:  1400     LossContext: 0.00106855
    Epoch:  1410     LossContext: 0.00106808
    Epoch:  1420     LossContext: 0.00106763
    Epoch:  1430     LossContext: 0.00106718
    Epoch:  1440     LossContext: 0.00106674
    Epoch:  1450     LossContext: 0.00106630
    Epoch:  1460     LossContext: 0.00106587
    Epoch:  1470     LossContext: 0.00106544
    Epoch:  1480     LossContext: 0.00106502
    Epoch:  1490     LossContext: 0.00106460
    Epoch:  1499     LossContext: 0.00106423

Gradient descent adaptation time: 0 hours 0 mins 48 secs

Adapting to environment 2 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.09414241
    Epoch:     1     LossContext: 0.06634825
    Epoch:     2     LossContext: 0.04627371
    Epoch:     3     LossContext: 0.03178526
    Epoch:    10     LossContext: 0.00228035
    Epoch:    20     LossContext: 0.00662393
    Epoch:    30     LossContext: 0.00378682
    Epoch:    40     LossContext: 0.00205992
    Epoch:    50     LossContext: 0.00233955
    Epoch:    60     LossContext: 0.00203489
    Epoch:    70     LossContext: 0.00205524
    Epoch:    80     LossContext: 0.00201749
    Epoch:    90     LossContext: 0.00201260
    Epoch:   100     LossContext: 0.00200229
    Epoch:   110     LossContext: 0.00199596
    Epoch:   120     LossContext: 0.00198860
    Epoch:   130     LossContext: 0.00198181
    Epoch:   140     LossContext: 0.00197479
    Epoch:   150     LossContext: 0.00196782
    Epoch:   160     LossContext: 0.00196079
    Epoch:   170     LossContext: 0.00195373
    Epoch:   180     LossContext: 0.00194667
    Epoch:   190     LossContext: 0.00193962
    Epoch:   200     LossContext: 0.00193259
    Epoch:   210     LossContext: 0.00192561
    Epoch:   220     LossContext: 0.00191868
    Epoch:   230     LossContext: 0.00191178
    Epoch:   240     LossContext: 0.00190496
    Epoch:   250     LossContext: 0.00189820
    Epoch:   260     LossContext: 0.00189153
    Epoch:   270     LossContext: 0.00188493
    Epoch:   280     LossContext: 0.00187840
    Epoch:   290     LossContext: 0.00187194
    Epoch:   300     LossContext: 0.00186555
    Epoch:   310     LossContext: 0.00185925
    Epoch:   320     LossContext: 0.00185303
    Epoch:   330     LossContext: 0.00184690
    Epoch:   340     LossContext: 0.00184083
    Epoch:   350     LossContext: 0.00183482
    Epoch:   360     LossContext: 0.00182890
    Epoch:   370     LossContext: 0.00182305
    Epoch:   380     LossContext: 0.00181727
    Epoch:   390     LossContext: 0.00181156
    Epoch:   400     LossContext: 0.00180592
    Epoch:   410     LossContext: 0.00180035
    Epoch:   420     LossContext: 0.00179481
    Epoch:   430     LossContext: 0.00178934
    Epoch:   440     LossContext: 0.00178391
    Epoch:   450     LossContext: 0.00177853
    Epoch:   460     LossContext: 0.00177321
    Epoch:   470     LossContext: 0.00176793
    Epoch:   480     LossContext: 0.00176268
    Epoch:   490     LossContext: 0.00175749
    Epoch:   500     LossContext: 0.00175234
    Epoch:   510     LossContext: 0.00174723
    Epoch:   520     LossContext: 0.00174216
    Epoch:   530     LossContext: 0.00173712
    Epoch:   540     LossContext: 0.00173211
    Epoch:   550     LossContext: 0.00172712
    Epoch:   560     LossContext: 0.00172216
    Epoch:   570     LossContext: 0.00171721
    Epoch:   580     LossContext: 0.00171228
    Epoch:   590     LossContext: 0.00170737
    Epoch:   600     LossContext: 0.00170247
    Epoch:   610     LossContext: 0.00169759
    Epoch:   620     LossContext: 0.00169271
    Epoch:   630     LossContext: 0.00168784
    Epoch:   640     LossContext: 0.00168299
    Epoch:   650     LossContext: 0.00167816
    Epoch:   660     LossContext: 0.00167334
    Epoch:   670     LossContext: 0.00166854
    Epoch:   680     LossContext: 0.00166374
    Epoch:   690     LossContext: 0.00165895
    Epoch:   700     LossContext: 0.00165416
    Epoch:   710     LossContext: 0.00164939
    Epoch:   720     LossContext: 0.00164462
    Epoch:   730     LossContext: 0.00163987
    Epoch:   740     LossContext: 0.00163513
    Epoch:   750     LossContext: 0.00163040
    Epoch:   760     LossContext: 0.00162569
    Epoch:   770     LossContext: 0.00162099
    Epoch:   780     LossContext: 0.00161631
    Epoch:   790     LossContext: 0.00161163
    Epoch:   800     LossContext: 0.00160697
    Epoch:   810     LossContext: 0.00160231
    Epoch:   820     LossContext: 0.00159766
    Epoch:   830     LossContext: 0.00159302
    Epoch:   840     LossContext: 0.00158840
    Epoch:   850     LossContext: 0.00158379
    Epoch:   860     LossContext: 0.00157918
    Epoch:   870     LossContext: 0.00157458
    Epoch:   880     LossContext: 0.00156999
    Epoch:   890     LossContext: 0.00156542
    Epoch:   900     LossContext: 0.00156087
    Epoch:   910     LossContext: 0.00155633
    Epoch:   920     LossContext: 0.00155182
    Epoch:   930     LossContext: 0.00154731
    Epoch:   940     LossContext: 0.00154282
    Epoch:   950     LossContext: 0.00153834
    Epoch:   960     LossContext: 0.00153386
    Epoch:   970     LossContext: 0.00152940
    Epoch:   980     LossContext: 0.00152495
    Epoch:   990     LossContext: 0.00152052
    Epoch:  1000     LossContext: 0.00151610
    Epoch:  1010     LossContext: 0.00151169
    Epoch:  1020     LossContext: 0.00150730
    Epoch:  1030     LossContext: 0.00150291
    Epoch:  1040     LossContext: 0.00149854
    Epoch:  1050     LossContext: 0.00149419
    Epoch:  1060     LossContext: 0.00148985
    Epoch:  1070     LossContext: 0.00148553
    Epoch:  1080     LossContext: 0.00148123
    Epoch:  1090     LossContext: 0.00147693
    Epoch:  1100     LossContext: 0.00147266
    Epoch:  1110     LossContext: 0.00146840
    Epoch:  1120     LossContext: 0.00146416
    Epoch:  1130     LossContext: 0.00145993
    Epoch:  1140     LossContext: 0.00145573
    Epoch:  1150     LossContext: 0.00145154
    Epoch:  1160     LossContext: 0.00144736
    Epoch:  1170     LossContext: 0.00144320
    Epoch:  1180     LossContext: 0.00143907
    Epoch:  1190     LossContext: 0.00143495
    Epoch:  1200     LossContext: 0.00143084
    Epoch:  1210     LossContext: 0.00142676
    Epoch:  1220     LossContext: 0.00142269
    Epoch:  1230     LossContext: 0.00141865
    Epoch:  1240     LossContext: 0.00141463
    Epoch:  1250     LossContext: 0.00141063
    Epoch:  1260     LossContext: 0.00140665
    Epoch:  1270     LossContext: 0.00140269
    Epoch:  1280     LossContext: 0.00139876
    Epoch:  1290     LossContext: 0.00139485
    Epoch:  1300     LossContext: 0.00139096
    Epoch:  1310     LossContext: 0.00138709
    Epoch:  1320     LossContext: 0.00138324
    Epoch:  1330     LossContext: 0.00137942
    Epoch:  1340     LossContext: 0.00137562
    Epoch:  1350     LossContext: 0.00137184
    Epoch:  1360     LossContext: 0.00136809
    Epoch:  1370     LossContext: 0.00136437
    Epoch:  1380     LossContext: 0.00136067
    Epoch:  1390     LossContext: 0.00135699
    Epoch:  1400     LossContext: 0.00135334
    Epoch:  1410     LossContext: 0.00134971
    Epoch:  1420     LossContext: 0.00134610
    Epoch:  1430     LossContext: 0.00134253
    Epoch:  1440     LossContext: 0.00133898
    Epoch:  1450     LossContext: 0.00133546
    Epoch:  1460     LossContext: 0.00133196
    Epoch:  1470     LossContext: 0.00132848
    Epoch:  1480     LossContext: 0.00132503
    Epoch:  1490     LossContext: 0.00132161
    Epoch:  1499     LossContext: 0.00131855

Gradient descent adaptation time: 0 hours 0 mins 48 secs

Adapting to environment 3 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.05961886
    Epoch:     1     LossContext: 0.03997638
    Epoch:     2     LossContext: 0.02702745
    Epoch:     3     LossContext: 0.01839374
    Epoch:    10     LossContext: 0.00252123
    Epoch:    20     LossContext: 0.00264724
    Epoch:    30     LossContext: 0.00263637
    Epoch:    40     LossContext: 0.00180706
    Epoch:    50     LossContext: 0.00130536
    Epoch:    60     LossContext: 0.00127195
    Epoch:    70     LossContext: 0.00126727
    Epoch:    80     LossContext: 0.00122962
    Epoch:    90     LossContext: 0.00121534
    Epoch:   100     LossContext: 0.00120158
    Epoch:   110     LossContext: 0.00118640
    Epoch:   120     LossContext: 0.00117237
    Epoch:   130     LossContext: 0.00115812
    Epoch:   140     LossContext: 0.00114389
    Epoch:   150     LossContext: 0.00112975
    Epoch:   160     LossContext: 0.00111571
    Epoch:   170     LossContext: 0.00110182
    Epoch:   180     LossContext: 0.00108816
    Epoch:   190     LossContext: 0.00107472
    Epoch:   200     LossContext: 0.00106154
    Epoch:   210     LossContext: 0.00104863
    Epoch:   220     LossContext: 0.00103603
    Epoch:   230     LossContext: 0.00102378
    Epoch:   240     LossContext: 0.00101188
    Epoch:   250     LossContext: 0.00100034
    Epoch:   260     LossContext: 0.00098917
    Epoch:   270     LossContext: 0.00097837
    Epoch:   280     LossContext: 0.00096792
    Epoch:   290     LossContext: 0.00095784
    Epoch:   300     LossContext: 0.00094811
    Epoch:   310     LossContext: 0.00093875
    Epoch:   320     LossContext: 0.00092973
    Epoch:   330     LossContext: 0.00092106
    Epoch:   340     LossContext: 0.00091274
    Epoch:   350     LossContext: 0.00090475
    Epoch:   360     LossContext: 0.00089709
    Epoch:   370     LossContext: 0.00088975
    Epoch:   380     LossContext: 0.00088273
    Epoch:   390     LossContext: 0.00087601
    Epoch:   400     LossContext: 0.00086958
    Epoch:   410     LossContext: 0.00086342
    Epoch:   420     LossContext: 0.00085752
    Epoch:   430     LossContext: 0.00085187
    Epoch:   440     LossContext: 0.00084647
    Epoch:   450     LossContext: 0.00084132
    Epoch:   460     LossContext: 0.00083638
    Epoch:   470     LossContext: 0.00083166
    Epoch:   480     LossContext: 0.00082715
    Epoch:   490     LossContext: 0.00082282
    Epoch:   500     LossContext: 0.00081868
    Epoch:   510     LossContext: 0.00081471
    Epoch:   520     LossContext: 0.00081090
    Epoch:   530     LossContext: 0.00080723
    Epoch:   540     LossContext: 0.00080370
    Epoch:   550     LossContext: 0.00080030
    Epoch:   560     LossContext: 0.00079702
    Epoch:   570     LossContext: 0.00079388
    Epoch:   580     LossContext: 0.00079084
    Epoch:   590     LossContext: 0.00078791
    Epoch:   600     LossContext: 0.00078508
    Epoch:   610     LossContext: 0.00078234
    Epoch:   620     LossContext: 0.00077968
    Epoch:   630     LossContext: 0.00077709
    Epoch:   640     LossContext: 0.00077457
    Epoch:   650     LossContext: 0.00077212
    Epoch:   660     LossContext: 0.00076973
    Epoch:   670     LossContext: 0.00076739
    Epoch:   680     LossContext: 0.00076510
    Epoch:   690     LossContext: 0.00076286
    Epoch:   700     LossContext: 0.00076067
    Epoch:   710     LossContext: 0.00075853
    Epoch:   720     LossContext: 0.00075642
    Epoch:   730     LossContext: 0.00075435
    Epoch:   740     LossContext: 0.00075232
    Epoch:   750     LossContext: 0.00075032
    Epoch:   760     LossContext: 0.00074835
    Epoch:   770     LossContext: 0.00074640
    Epoch:   780     LossContext: 0.00074448
    Epoch:   790     LossContext: 0.00074259
    Epoch:   800     LossContext: 0.00074073
    Epoch:   810     LossContext: 0.00073888
    Epoch:   820     LossContext: 0.00073706
    Epoch:   830     LossContext: 0.00073527
    Epoch:   840     LossContext: 0.00073349
    Epoch:   850     LossContext: 0.00073173
    Epoch:   860     LossContext: 0.00072998
    Epoch:   870     LossContext: 0.00072825
    Epoch:   880     LossContext: 0.00072653
    Epoch:   890     LossContext: 0.00072483
    Epoch:   900     LossContext: 0.00072314
    Epoch:   910     LossContext: 0.00072147
    Epoch:   920     LossContext: 0.00071980
    Epoch:   930     LossContext: 0.00071815
    Epoch:   940     LossContext: 0.00071652
    Epoch:   950     LossContext: 0.00071489
    Epoch:   960     LossContext: 0.00071328
    Epoch:   970     LossContext: 0.00071167
    Epoch:   980     LossContext: 0.00071008
    Epoch:   990     LossContext: 0.00070850
    Epoch:  1000     LossContext: 0.00070693
    Epoch:  1010     LossContext: 0.00070538
    Epoch:  1020     LossContext: 0.00070384
    Epoch:  1030     LossContext: 0.00070231
    Epoch:  1040     LossContext: 0.00070079
    Epoch:  1050     LossContext: 0.00069928
    Epoch:  1060     LossContext: 0.00069778
    Epoch:  1070     LossContext: 0.00069630
    Epoch:  1080     LossContext: 0.00069482
    Epoch:  1090     LossContext: 0.00069336
    Epoch:  1100     LossContext: 0.00069190
    Epoch:  1110     LossContext: 0.00069045
    Epoch:  1120     LossContext: 0.00068901
    Epoch:  1130     LossContext: 0.00068757
    Epoch:  1140     LossContext: 0.00068615
    Epoch:  1150     LossContext: 0.00068473
    Epoch:  1160     LossContext: 0.00068333
    Epoch:  1170     LossContext: 0.00068193
    Epoch:  1180     LossContext: 0.00068055
    Epoch:  1190     LossContext: 0.00067917
    Epoch:  1200     LossContext: 0.00067780
    Epoch:  1210     LossContext: 0.00067644
    Epoch:  1220     LossContext: 0.00067509
    Epoch:  1230     LossContext: 0.00067375
    Epoch:  1240     LossContext: 0.00067242
    Epoch:  1250     LossContext: 0.00067110
    Epoch:  1260     LossContext: 0.00066979
    Epoch:  1270     LossContext: 0.00066849
    Epoch:  1280     LossContext: 0.00066720
    Epoch:  1290     LossContext: 0.00066591
    Epoch:  1300     LossContext: 0.00066464
    Epoch:  1310     LossContext: 0.00066337
    Epoch:  1320     LossContext: 0.00066211
    Epoch:  1330     LossContext: 0.00066087
    Epoch:  1340     LossContext: 0.00065963
    Epoch:  1350     LossContext: 0.00065840
    Epoch:  1360     LossContext: 0.00065718
    Epoch:  1370     LossContext: 0.00065598
    Epoch:  1380     LossContext: 0.00065478
    Epoch:  1390     LossContext: 0.00065360
    Epoch:  1400     LossContext: 0.00065243
    Epoch:  1410     LossContext: 0.00065127
    Epoch:  1420     LossContext: 0.00065012
    Epoch:  1430     LossContext: 0.00064898
    Epoch:  1440     LossContext: 0.00064785
    Epoch:  1450     LossContext: 0.00064672
    Epoch:  1460     LossContext: 0.00064561
    Epoch:  1470     LossContext: 0.00064450
    Epoch:  1480     LossContext: 0.00064340
    Epoch:  1490     LossContext: 0.00064231
    Epoch:  1499     LossContext: 0.00064134

Gradient descent adaptation time: 0 hours 0 mins 48 secs
WARNING: No key provided for the context initialization. Initializing at 0.

Saving adaptation parameters into ./runs/06082024-103701/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 9
    Number of adaptation environments: 4
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (OOD): 0.002529574

==  Begining out-of-distribution visualisation ... ==
    Environment id: 2
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/06082024-103701/adapt/results_ood.png
