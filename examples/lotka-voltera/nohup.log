
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/26032024-042602/
 Seed: 2026


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/26032024-042602/
 Seed: 4052


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Run folder created successfuly: ./runs/26032024-042602/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 042625
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 042625
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 308240 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training with proximal alternating minimization ... ===
    Number of examples in a batch: 4
    Maximum number of steps per inner minimization: 25
    Maximum number of outer minimizations: 250
    Maximum total number of training steps: 6250

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (9, 4, 20, 2) (20,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (9, 4, 20, 2) (20,)
    Outer Step:     0      LossTrajs: 1.72332108     ContextsNorm: 0.00000000     ValIndCrit: 1.80412650
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.71e-06
        -DiffCxt:  inf
    Outer Step:     1      LossTrajs: 1.45291436     ContextsNorm: 0.00247815     ValIndCrit: 1.52608299
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.69e-06
        -DiffCxt:  1.66e-03
    Outer Step:     2      LossTrajs: 1.16321874     ContextsNorm: 0.00563642     ValIndCrit: 1.22159600
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.21e-05
        -DiffCxt:  5.37e-04
    Outer Step:     3      LossTrajs: 0.76230705     ContextsNorm: 0.00961201     ValIndCrit: 0.78233796
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.34e-05
        -DiffCxt:  2.66e-04
    Outer Step:    10      LossTrajs: 0.23632234     ContextsNorm: 0.00949616     ValIndCrit: 0.27058664
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.44e-07
        -DiffCxt:  6.10e-06
    Outer Step:    20      LossTrajs: 0.10783720     ContextsNorm: 0.01091975     ValIndCrit: 0.13353617
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.91e-07
        -DiffCxt:  1.15e-06
    Outer Step:    30      LossTrajs: 0.06073795     ContextsNorm: 0.01177699     ValIndCrit: 0.07332037
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.39e-07
        -DiffCxt:  7.54e-07
    Outer Step:    40      LossTrajs: 0.03375013     ContextsNorm: 0.01468138     ValIndCrit: 0.03661178
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.43e-06
        -DiffCxt:  5.76e-06
    Outer Step:    50      LossTrajs: 0.01681991     ContextsNorm: 0.01432756     ValIndCrit: 0.01838390
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.86e-07
        -DiffCxt:  1.08e-06
    Outer Step:    60      LossTrajs: 0.01105587     ContextsNorm: 0.01412013     ValIndCrit: 0.01290254
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.03e-07
        -DiffCxt:  2.63e-07
    Outer Step:    70      LossTrajs: 0.00747119     ContextsNorm: 0.01390279     ValIndCrit: 0.00922751
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.19e-07
        -DiffCxt:  1.53e-07
    Outer Step:    80      LossTrajs: 0.00555174     ContextsNorm: 0.01359908     ValIndCrit: 0.00709644
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.13e-08
        -DiffCxt:  1.87e-07
    Outer Step:    90      LossTrajs: 0.00358081     ContextsNorm: 0.01361413     ValIndCrit: 0.00476081
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.84e-08
        -DiffCxt:  1.44e-07
    Outer Step:   100      LossTrajs: 0.00245311     ContextsNorm: 0.01359680     ValIndCrit: 0.00337736
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.91e-08
        -DiffCxt:  1.76e-07
    Outer Step:   110      LossTrajs: 0.00173001     ContextsNorm: 0.01368644     ValIndCrit: 0.00245452
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.05e-08
        -DiffCxt:  1.06e-07
    Outer Step:   120      LossTrajs: 0.00124333     ContextsNorm: 0.01374028     ValIndCrit: 0.00174639
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.15e-08
        -DiffCxt:  5.65e-08
    Outer Step:   130      LossTrajs: 0.00087663     ContextsNorm: 0.01376000     ValIndCrit: 0.00121721
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.06e-08
        -DiffCxt:  5.54e-08
    Outer Step:   140      LossTrajs: 0.00060172     ContextsNorm: 0.01358019     ValIndCrit: 0.00083105
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.79e-08
        -DiffCxt:  2.91e-08
    Outer Step:   150      LossTrajs: 0.00041693     ContextsNorm: 0.01360292     ValIndCrit: 0.00061704
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.24e-08
        -DiffCxt:  3.91e-08
    Outer Step:   160      LossTrajs: 0.00028905     ContextsNorm: 0.01348885     ValIndCrit: 0.00050599
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.01e-08
        -DiffCxt:  2.99e-08
    Outer Step:   170      LossTrajs: 0.00025131     ContextsNorm: 0.01343328     ValIndCrit: 0.00042604
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.20e-08
        -DiffCxt:  4.01e-08
    Outer Step:   180      LossTrajs: 0.00020427     ContextsNorm: 0.01344960     ValIndCrit: 0.00037012
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.40e-09
        -DiffCxt:  6.87e-08
    Outer Step:   190      LossTrajs: 0.00016627     ContextsNorm: 0.01342876     ValIndCrit: 0.00031423
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.14e-08
        -DiffCxt:  3.13e-08
    Outer Step:   200      LossTrajs: 0.00014692     ContextsNorm: 0.01331472     ValIndCrit: 0.00027818
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.63e-08
        -DiffCxt:  3.49e-08
    Outer Step:   210      LossTrajs: 0.00013059     ContextsNorm: 0.01333723     ValIndCrit: 0.00023990
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.51e-08
        -DiffCxt:  5.26e-08
    Outer Step:   220      LossTrajs: 0.00011757     ContextsNorm: 0.01334765     ValIndCrit: 0.00021415
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.10e-09
        -DiffCxt:  2.77e-08
    Outer Step:   230      LossTrajs: 0.00010437     ContextsNorm: 0.01330783     ValIndCrit: 0.00018273
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.19e-09
        -DiffCxt:  1.10e-07
    Outer Step:   240      LossTrajs: 0.00009153     ContextsNorm: 0.01332780     ValIndCrit: 0.00016525
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.15e-09
        -DiffCxt:  8.16e-08
    Outer Step:   249      LossTrajs: 0.00009954     ContextsNorm: 0.01326415     ValIndCrit: 0.00014863
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.80e-08
        -DiffCxt:  7.42e-08

Total gradient descent training time: 0 hours 41 mins 55 secs
Environment weights at the end of the training: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111
 0.11111111 0.11111111 0.11111111]
WARNING: You did not provide a dataloader id. A new one has been generated: 050822
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 9
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (In-Domain): 0.00014862957


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/26032024-042602/adapt/
 Seed: 6078

==  Begining in-domain visualisation ... ==
    Environment id: 6
    Trajectory id: 24
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/26032024-042602/results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 15
    Total number of training steps: 15

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 20, 2) (20,)
    Epoch:     0     LossContext: 0.01592918
    Epoch:     1     LossContext: 0.00340333
    Epoch:     2     LossContext: 0.00059946
    Epoch:     3     LossContext: 0.00608473
    Epoch:    10     LossContext: 0.00275068
    Epoch:    14     LossContext: 0.00023357

Gradient descent adaptation time: 0 hours 0 mins 9 secs

Adapting to environment 1 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.06713697
    Epoch:     1     LossContext: 0.03838527
    Epoch:     2     LossContext: 0.02022956
    Epoch:     3     LossContext: 0.01003775
    Epoch:    10     LossContext: 0.00088286
    Epoch:    14     LossContext: 0.00175740

Gradient descent adaptation time: 0 hours 0 mins 0 secs

Adapting to environment 2 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.01701505
    Epoch:     1     LossContext: 0.00378968
    Epoch:     2     LossContext: 0.00239693
    Epoch:     3     LossContext: 0.00563134
    Epoch:    10     LossContext: 0.00200304
    Epoch:    14     LossContext: 0.00052168

Gradient descent adaptation time: 0 hours 0 mins 0 secs

Adapting to environment 3 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.06477506
    Epoch:     1     LossContext: 0.03644298
    Epoch:     2     LossContext: 0.01902182
    Epoch:     3     LossContext: 0.00957413
    Epoch:    10     LossContext: 0.00101771
    Epoch:    14     LossContext: 0.00177979

Gradient descent adaptation time: 0 hours 0 mins 0 secs
WARNING: No key provided for the context initialization. Initializing at 0.

Saving adaptation parameters into ./runs/26032024-042602/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 9
    Number of adaptation environments: 4
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (OOD): 0.001331251

==  Begining out-of-distribution visualisation ... ==
    Environment id: 1
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/26032024-042602/adapt/results_ood.png

Full evaluation of the model on many random seeds


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Mean and std of the scores across various datasets

          seed  ind_crit  ood_crit
count 5.00e+00  5.00e+00  5.00e+00
mean  7.06e+03  1.42e-04  1.88e-03
std   2.05e+03  1.10e-05  2.50e-04
