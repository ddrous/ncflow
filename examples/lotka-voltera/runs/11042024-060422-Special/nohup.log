cp: 'main_proximal_coercive.py' and './main_proximal_coercive.py' are the same file
cp: 'dataset.py' and './dataset.py' are the same file
cp: cannot stat '../../nodax': No such file or directory

############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./
 Seed: 2026


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./
 Seed: 4052


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 060657
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 060657
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 308240 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training with proximal alternating minimization ... ===
    Number of examples in a batch: 4
    Maximum number of steps per inner minimization: 25
    Maximum number of outer minimizations: 3000
    Maximum total number of training steps: 75000

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (9, 4, 20, 2) (20,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (9, 4, 20, 2) (20,)
    Outer Step:     0      LossTrajs: 1.81051505     ContextsNorm: 0.00000000     ValIndCrit: 1.69905567
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.70e-06
        -DiffCxt:  inf
    Outer Step:     1      LossTrajs: 1.52824581     ContextsNorm: 0.00132967     ValIndCrit: 1.43287265
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.67e-06
        -DiffCxt:  5.61e-04
    Outer Step:     2      LossTrajs: 1.22562730     ContextsNorm: 0.00391922     ValIndCrit: 1.14542639
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.11e-05
        -DiffCxt:  7.07e-04
    Outer Step:     3      LossTrajs: 0.81252283     ContextsNorm: 0.00774638     ValIndCrit: 0.74780232
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.19e-05
        -DiffCxt:  3.82e-04
    Outer Step:    10      LossTrajs: 0.23048142     ContextsNorm: 0.00969903     ValIndCrit: 0.27365205
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.34e-07
        -DiffCxt:  6.36e-06
    Outer Step:    20      LossTrajs: 0.16440547     ContextsNorm: 0.01046153     ValIndCrit: 0.18809311
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.43e-07
        -DiffCxt:  3.04e-07
    Outer Step:    30      LossTrajs: 0.07196472     ContextsNorm: 0.01074613     ValIndCrit: 0.07421149
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.85e-07
        -DiffCxt:  2.91e-06
    Outer Step:    40      LossTrajs: 0.02182614     ContextsNorm: 0.01408049     ValIndCrit: 0.02348913
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.35e-07
        -DiffCxt:  1.90e-06
    Outer Step:    50      LossTrajs: 0.01032556     ContextsNorm: 0.01486682     ValIndCrit: 0.01271910
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.73e-08
        -DiffCxt:  3.17e-07
    Outer Step:    60      LossTrajs: 0.00713072     ContextsNorm: 0.01490472     ValIndCrit: 0.00951107
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.86e-08
        -DiffCxt:  1.45e-07
    Outer Step:    70      LossTrajs: 0.00540509     ContextsNorm: 0.01498296     ValIndCrit: 0.00770599
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.98e-07
        -DiffCxt:  9.08e-08
    Outer Step:    80      LossTrajs: 0.00428605     ContextsNorm: 0.01522600     ValIndCrit: 0.00662603
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.80e-08
        -DiffCxt:  1.98e-07
    Outer Step:    90      LossTrajs: 0.00348063     ContextsNorm: 0.01523689     ValIndCrit: 0.00561341
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.13e-08
        -DiffCxt:  2.34e-07
    Outer Step:   100      LossTrajs: 0.00253076     ContextsNorm: 0.01529258     ValIndCrit: 0.00439639
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.98e-08
        -DiffCxt:  1.26e-07
    Outer Step:   110      LossTrajs: 0.00182833     ContextsNorm: 0.01524812     ValIndCrit: 0.00340014
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.88e-08
        -DiffCxt:  1.58e-07
    Outer Step:   120      LossTrajs: 0.00136298     ContextsNorm: 0.01510125     ValIndCrit: 0.00266096
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.73e-08
        -DiffCxt:  5.88e-08
    Outer Step:   130      LossTrajs: 0.00100199     ContextsNorm: 0.01522545     ValIndCrit: 0.00210533
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.82e-08
        -DiffCxt:  1.91e-07
    Outer Step:   140      LossTrajs: 0.00078349     ContextsNorm: 0.01528970     ValIndCrit: 0.00162995
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.79e-08
        -DiffCxt:  5.83e-08
    Outer Step:   150      LossTrajs: 0.00059101     ContextsNorm: 0.01522364     ValIndCrit: 0.00127634
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.20e-08
        -DiffCxt:  4.45e-08
    Outer Step:   160      LossTrajs: 0.00042616     ContextsNorm: 0.01513065     ValIndCrit: 0.00100362
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.45e-08
        -DiffCxt:  2.71e-08
    Outer Step:   170      LossTrajs: 0.00034042     ContextsNorm: 0.01507645     ValIndCrit: 0.00078328
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.20e-08
        -DiffCxt:  1.37e-08
    Outer Step:   180      LossTrajs: 0.00029228     ContextsNorm: 0.01510041     ValIndCrit: 0.00061818
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.05e-08
        -DiffCxt:  6.78e-08
    Outer Step:   190      LossTrajs: 0.00021523     ContextsNorm: 0.01510452     ValIndCrit: 0.00048696
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.02e-08
        -DiffCxt:  1.51e-08
    Outer Step:   200      LossTrajs: 0.00018122     ContextsNorm: 0.01515773     ValIndCrit: 0.00039288
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.19e-08
        -DiffCxt:  1.82e-08
    Outer Step:   210      LossTrajs: 0.00014477     ContextsNorm: 0.01513746     ValIndCrit: 0.00032387
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.21e-08
        -DiffCxt:  4.22e-08
    Outer Step:   220      LossTrajs: 0.00012337     ContextsNorm: 0.01518648     ValIndCrit: 0.00028304
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.72e-08
        -DiffCxt:  3.81e-08
    Outer Step:   230      LossTrajs: 0.00010486     ContextsNorm: 0.01521981     ValIndCrit: 0.00024252
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.26e-08
        -DiffCxt:  1.36e-08
    Outer Step:   240      LossTrajs: 0.00008766     ContextsNorm: 0.01518489     ValIndCrit: 0.00021976
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   23
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.70e-08
        -DiffCxt:  8.76e-09
    Outer Step:   250      LossTrajs: 0.00008551     ContextsNorm: 0.01515364     ValIndCrit: 0.00018731
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.61e-08
        -DiffCxt:  1.36e-07
    Outer Step:   260      LossTrajs: 0.00006939     ContextsNorm: 0.01510151     ValIndCrit: 0.00017494
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.69e-08
        -DiffCxt:  3.05e-08
    Outer Step:   270      LossTrajs: 0.00006896     ContextsNorm: 0.01503034     ValIndCrit: 0.00015628
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.72e-08
        -DiffCxt:  1.48e-08
    Outer Step:   280      LossTrajs: 0.00006023     ContextsNorm: 0.01505784     ValIndCrit: 0.00014411
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.47e-08
        -DiffCxt:  1.80e-08
    Outer Step:   290      LossTrajs: 0.00005826     ContextsNorm: 0.01499915     ValIndCrit: 0.00013549
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.30e-08
        -DiffCxt:  1.85e-08
    Outer Step:   300      LossTrajs: 0.00005129     ContextsNorm: 0.01501102     ValIndCrit: 0.00012727
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.44e-08
        -DiffCxt:  4.67e-08
    Outer Step:   310      LossTrajs: 0.00004637     ContextsNorm: 0.01500269     ValIndCrit: 0.00011827
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.02e-08
        -DiffCxt:  3.56e-08
    Outer Step:   320      LossTrajs: 0.00004365     ContextsNorm: 0.01495341     ValIndCrit: 0.00011349
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.24e-08
        -DiffCxt:  5.57e-08
    Outer Step:   330      LossTrajs: 0.00004200     ContextsNorm: 0.01493444     ValIndCrit: 0.00010276
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.92e-08
        -DiffCxt:  2.49e-07
    Outer Step:   340      LossTrajs: 0.00004085     ContextsNorm: 0.01490571     ValIndCrit: 0.00010085
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.29e-08
        -DiffCxt:  8.34e-08
    Outer Step:   350      LossTrajs: 0.00003747     ContextsNorm: 0.01485799     ValIndCrit: 0.00009359
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.01e-08
        -DiffCxt:  9.06e-08
    Outer Step:   360      LossTrajs: 0.00003498     ContextsNorm: 0.01488295     ValIndCrit: 0.00009033
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.19e-08
        -DiffCxt:  7.67e-08
    Outer Step:   370      LossTrajs: 0.00003511     ContextsNorm: 0.01486287     ValIndCrit: 0.00008447
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.28e-08
        -DiffCxt:  4.15e-08
    Outer Step:   380      LossTrajs: 0.00003251     ContextsNorm: 0.01490661     ValIndCrit: 0.00008174
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.96e-08
        -DiffCxt:  3.80e-08
    Outer Step:   390      LossTrajs: 0.00003174     ContextsNorm: 0.01491143     ValIndCrit: 0.00007841
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.36e-08
        -DiffCxt:  8.30e-08
    Outer Step:   400      LossTrajs: 0.00003064     ContextsNorm: 0.01487923     ValIndCrit: 0.00007336
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.50e-08
        -DiffCxt:  6.15e-08
    Outer Step:   410      LossTrajs: 0.00003200     ContextsNorm: 0.01485075     ValIndCrit: 0.00007244
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.04e-08
        -DiffCxt:  5.00e-08
    Outer Step:   420      LossTrajs: 0.00002753     ContextsNorm: 0.01477550     ValIndCrit: 0.00007014
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.21e-08
        -DiffCxt:  4.51e-08
    Outer Step:   430      LossTrajs: 0.00002826     ContextsNorm: 0.01475343     ValIndCrit: 0.00006796
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.75e-08
        -DiffCxt:  6.38e-08
    Outer Step:   440      LossTrajs: 0.00002811     ContextsNorm: 0.01469471     ValIndCrit: 0.00006582
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.83e-08
        -DiffCxt:  4.20e-08
    Outer Step:   450      LossTrajs: 0.00002667     ContextsNorm: 0.01462004     ValIndCrit: 0.00006208
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.66e-09
        -DiffCxt:  5.42e-08
    Outer Step:   460      LossTrajs: 0.00002611     ContextsNorm: 0.01458682     ValIndCrit: 0.00006320
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.11e-08
        -DiffCxt:  2.33e-07
    Outer Step:   470      LossTrajs: 0.00002882     ContextsNorm: 0.01451723     ValIndCrit: 0.00006682
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.07e-08
        -DiffCxt:  1.32e-06
    Outer Step:   480      LossTrajs: 0.00002508     ContextsNorm: 0.01447413     ValIndCrit: 0.00005832
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.29e-09
        -DiffCxt:  1.87e-07
    Outer Step:   490      LossTrajs: 0.00002525     ContextsNorm: 0.01442516     ValIndCrit: 0.00005586
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.11e-08
        -DiffCxt:  5.02e-07
    Outer Step:   500      LossTrajs: 0.00002445     ContextsNorm: 0.01441161     ValIndCrit: 0.00005464
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.86e-08
        -DiffCxt:  5.48e-07
    Outer Step:   510      LossTrajs: 0.00002222     ContextsNorm: 0.01435198     ValIndCrit: 0.00005168
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.05e-08
        -DiffCxt:  7.38e-08
    Outer Step:   520      LossTrajs: 0.00002249     ContextsNorm: 0.01433224     ValIndCrit: 0.00005093
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.01e-09
        -DiffCxt:  1.05e-07
    Outer Step:   530      LossTrajs: 0.00002200     ContextsNorm: 0.01435987     ValIndCrit: 0.00005005
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.74e-08
        -DiffCxt:  4.78e-07
    Outer Step:   540      LossTrajs: 0.00002450     ContextsNorm: 0.01432751     ValIndCrit: 0.00004951
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.85e-08
        -DiffCxt:  3.81e-08
    Outer Step:   550      LossTrajs: 0.00002219     ContextsNorm: 0.01426267     ValIndCrit: 0.00004885
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.11e-09
        -DiffCxt:  6.08e-08
    Outer Step:   560      LossTrajs: 0.00002872     ContextsNorm: 0.01421310     ValIndCrit: 0.00004869
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.70e-08
        -DiffCxt:  9.24e-08
    Outer Step:   570      LossTrajs: 0.00002115     ContextsNorm: 0.01420138     ValIndCrit: 0.00004936
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.30e-08
        -DiffCxt:  2.17e-07
    Outer Step:   580      LossTrajs: 0.00002060     ContextsNorm: 0.01416264     ValIndCrit: 0.00004564
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.01e-08
        -DiffCxt:  3.34e-08
    Outer Step:   590      LossTrajs: 0.00002234     ContextsNorm: 0.01410436     ValIndCrit: 0.00004536
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.10e-08
        -DiffCxt:  3.88e-07
    Outer Step:   600      LossTrajs: 0.00002233     ContextsNorm: 0.01402044     ValIndCrit: 0.00004488
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.72e-08
        -DiffCxt:  1.84e-07
    Outer Step:   610      LossTrajs: 0.00002099     ContextsNorm: 0.01399649     ValIndCrit: 0.00004380
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.33e-08
        -DiffCxt:  3.31e-08
    Outer Step:   620      LossTrajs: 0.00002121     ContextsNorm: 0.01399096     ValIndCrit: 0.00004409
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.16e-08
        -DiffCxt:  1.30e-07
    Outer Step:   630      LossTrajs: 0.00001971     ContextsNorm: 0.01402980     ValIndCrit: 0.00004289
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.53e-08
        -DiffCxt:  4.44e-08
    Outer Step:   640      LossTrajs: 0.00002215     ContextsNorm: 0.01405075     ValIndCrit: 0.00004556
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.64e-08
        -DiffCxt:  4.25e-07
    Outer Step:   650      LossTrajs: 0.00002162     ContextsNorm: 0.01405273     ValIndCrit: 0.00004112
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.31e-08
        -DiffCxt:  1.63e-07
    Outer Step:   660      LossTrajs: 0.00002086     ContextsNorm: 0.01401357     ValIndCrit: 0.00004068
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.90e-08
        -DiffCxt:  4.85e-08
    Outer Step:   670      LossTrajs: 0.00001936     ContextsNorm: 0.01404300     ValIndCrit: 0.00004011
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.03e-08
        -DiffCxt:  4.91e-08
    Outer Step:   680      LossTrajs: 0.00001921     ContextsNorm: 0.01400552     ValIndCrit: 0.00004021
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.12e-08
        -DiffCxt:  4.56e-08
    Outer Step:   690      LossTrajs: 0.00001947     ContextsNorm: 0.01401801     ValIndCrit: 0.00003962
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.63e-09
        -DiffCxt:  1.32e-07
    Outer Step:   700      LossTrajs: 0.00002076     ContextsNorm: 0.01396959     ValIndCrit: 0.00003919
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.07e-08
        -DiffCxt:  1.28e-07
    Outer Step:   710      LossTrajs: 0.00001959     ContextsNorm: 0.01397102     ValIndCrit: 0.00003854
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.60e-08
        -DiffCxt:  2.72e-07
    Outer Step:   720      LossTrajs: 0.00001969     ContextsNorm: 0.01391985     ValIndCrit: 0.00003934
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.45e-08
        -DiffCxt:  1.08e-07
    Outer Step:   730      LossTrajs: 0.00003449     ContextsNorm: 0.01379234     ValIndCrit: 0.00004209
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.19e-07
        -DiffCxt:  5.74e-07
    Outer Step:   740      LossTrajs: 0.00002439     ContextsNorm: 0.01385671     ValIndCrit: 0.00003700
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.98e-08
        -DiffCxt:  9.71e-07
    Outer Step:   750      LossTrajs: 0.00001813     ContextsNorm: 0.01382507     ValIndCrit: 0.00003807
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.17e-09
        -DiffCxt:  1.05e-07
    Outer Step:   760      LossTrajs: 0.00001793     ContextsNorm: 0.01376197     ValIndCrit: 0.00003711
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.58e-09
        -DiffCxt:  4.67e-08
    Outer Step:   770      LossTrajs: 0.00001772     ContextsNorm: 0.01378571     ValIndCrit: 0.00003592
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.66e-09
        -DiffCxt:  4.35e-08
    Outer Step:   780      LossTrajs: 0.00001809     ContextsNorm: 0.01373393     ValIndCrit: 0.00003668
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.20e-09
        -DiffCxt:  5.01e-08
    Outer Step:   790      LossTrajs: 0.00001839     ContextsNorm: 0.01367160     ValIndCrit: 0.00003513
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.15e-08
        -DiffCxt:  1.73e-07
    Outer Step:   800      LossTrajs: 0.00002050     ContextsNorm: 0.01367286     ValIndCrit: 0.00003654
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.99e-08
        -DiffCxt:  3.58e-07
    Outer Step:   810      LossTrajs: 0.00002099     ContextsNorm: 0.01366122     ValIndCrit: 0.00003610
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.37e-08
        -DiffCxt:  4.02e-07
    Outer Step:   820      LossTrajs: 0.00001887     ContextsNorm: 0.01363806     ValIndCrit: 0.00003497
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.52e-08
        -DiffCxt:  1.90e-07
    Outer Step:   830      LossTrajs: 0.00001741     ContextsNorm: 0.01365947     ValIndCrit: 0.00003454
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.93e-09
        -DiffCxt:  6.34e-08
    Outer Step:   840      LossTrajs: 0.00001823     ContextsNorm: 0.01357004     ValIndCrit: 0.00003728
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.31e-08
        -DiffCxt:  5.25e-08
    Outer Step:   850      LossTrajs: 0.00001784     ContextsNorm: 0.01355777     ValIndCrit: 0.00003627
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.15e-08
        -DiffCxt:  1.60e-07
    Outer Step:   860      LossTrajs: 0.00001715     ContextsNorm: 0.01360056     ValIndCrit: 0.00003347
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.15e-09
        -DiffCxt:  5.39e-08
    Outer Step:   870      LossTrajs: 0.00001703     ContextsNorm: 0.01356791     ValIndCrit: 0.00003346
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.76e-09
        -DiffCxt:  4.63e-08
    Outer Step:   880      LossTrajs: 0.00001860     ContextsNorm: 0.01365291     ValIndCrit: 0.00003335
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.58e-08
        -DiffCxt:  6.91e-08
    Outer Step:   890      LossTrajs: 0.00001762     ContextsNorm: 0.01365751     ValIndCrit: 0.00003315
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.85e-08
        -DiffCxt:  1.12e-07
    Outer Step:   900      LossTrajs: 0.00001708     ContextsNorm: 0.01361606     ValIndCrit: 0.00003408
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.05e-09
        -DiffCxt:  4.83e-08
    Outer Step:   910      LossTrajs: 0.00001711     ContextsNorm: 0.01359879     ValIndCrit: 0.00003266
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.49e-09
        -DiffCxt:  2.69e-08
    Outer Step:   920      LossTrajs: 0.00001772     ContextsNorm: 0.01355286     ValIndCrit: 0.00003312
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.90e-09
        -DiffCxt:  3.58e-08
    Outer Step:   930      LossTrajs: 0.00001953     ContextsNorm: 0.01356047     ValIndCrit: 0.00003197
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.98e-08
        -DiffCxt:  1.89e-07
    Outer Step:   940      LossTrajs: 0.00001693     ContextsNorm: 0.01348755     ValIndCrit: 0.00003283
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.03e-08
        -DiffCxt:  2.98e-08
    Outer Step:   950      LossTrajs: 0.00001722     ContextsNorm: 0.01350765     ValIndCrit: 0.00003357
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.92e-08
        -DiffCxt:  7.37e-08
    Outer Step:   960      LossTrajs: 0.00001693     ContextsNorm: 0.01349818     ValIndCrit: 0.00003240
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.66e-08
        -DiffCxt:  2.23e-08
    Outer Step:   970      LossTrajs: 0.00001784     ContextsNorm: 0.01348368     ValIndCrit: 0.00003208
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.78e-08
        -DiffCxt:  5.99e-08
    Outer Step:   980      LossTrajs: 0.00001717     ContextsNorm: 0.01344176     ValIndCrit: 0.00003526
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.89e-08
        -DiffCxt:  3.95e-07
    Outer Step:   990      LossTrajs: 0.00001668     ContextsNorm: 0.01345582     ValIndCrit: 0.00003142
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.80e-09
        -DiffCxt:  2.61e-08
    Outer Step:  1000      LossTrajs: 0.00001957     ContextsNorm: 0.01347887     ValIndCrit: 0.00003149
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.22e-08
        -DiffCxt:  1.48e-07
    Outer Step:  1010      LossTrajs: 0.00003487     ContextsNorm: 0.01344459     ValIndCrit: 0.00003715
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.40e-07
        -DiffCxt:  6.57e-07
    Outer Step:  1020      LossTrajs: 0.00001658     ContextsNorm: 0.01339510     ValIndCrit: 0.00003118
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.88e-09
        -DiffCxt:  3.15e-08
    Outer Step:  1030      LossTrajs: 0.00001618     ContextsNorm: 0.01338668     ValIndCrit: 0.00003010
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.23e-09
        -DiffCxt:  9.92e-08
    Outer Step:  1040      LossTrajs: 0.00001640     ContextsNorm: 0.01333142     ValIndCrit: 0.00003037
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.15e-08
        -DiffCxt:  8.45e-08
    Outer Step:  1050      LossTrajs: 0.00001597     ContextsNorm: 0.01329729     ValIndCrit: 0.00003042
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.10e-09
        -DiffCxt:  3.05e-08
    Outer Step:  1060      LossTrajs: 0.00001616     ContextsNorm: 0.01328539     ValIndCrit: 0.00002987
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.35e-09
        -DiffCxt:  5.75e-08
    Outer Step:  1070      LossTrajs: 0.00001689     ContextsNorm: 0.01324971     ValIndCrit: 0.00003107
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.95e-08
        -DiffCxt:  2.63e-07
    Outer Step:  1080      LossTrajs: 0.00001717     ContextsNorm: 0.01328003     ValIndCrit: 0.00003203
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.06e-08
        -DiffCxt:  5.09e-07
    Outer Step:  1090      LossTrajs: 0.00001712     ContextsNorm: 0.01320436     ValIndCrit: 0.00002972
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.26e-08
        -DiffCxt:  1.49e-07
    Outer Step:  1100      LossTrajs: 0.00001583     ContextsNorm: 0.01322441     ValIndCrit: 0.00002965
        Saving best model so far ...
        -NbInnerStepsNode:   15
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.13e-10
        -DiffCxt:  3.21e-08
    Outer Step:  1110      LossTrajs: 0.00001862     ContextsNorm: 0.01320545     ValIndCrit: 0.00003094
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.43e-08
        -DiffCxt:  9.35e-07
    Outer Step:  1120      LossTrajs: 0.00001616     ContextsNorm: 0.01317821     ValIndCrit: 0.00002847
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.17e-08
        -DiffCxt:  4.44e-08
    Outer Step:  1130      LossTrajs: 0.00001585     ContextsNorm: 0.01314920     ValIndCrit: 0.00002874
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.79e-09
        -DiffCxt:  6.75e-08
    Outer Step:  1140      LossTrajs: 0.00001581     ContextsNorm: 0.01311305     ValIndCrit: 0.00002905
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.81e-09
        -DiffCxt:  6.33e-08
    Outer Step:  1150      LossTrajs: 0.00001674     ContextsNorm: 0.01310706     ValIndCrit: 0.00002879
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.19e-08
        -DiffCxt:  2.28e-07
    Outer Step:  1160      LossTrajs: 0.00003667     ContextsNorm: 0.01315176     ValIndCrit: 0.00003129
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.95e-07
        -DiffCxt:  1.87e-06
    Outer Step:  1170      LossTrajs: 0.00001602     ContextsNorm: 0.01319978     ValIndCrit: 0.00002771
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.58e-09
        -DiffCxt:  5.92e-08
    Outer Step:  1180      LossTrajs: 0.00001627     ContextsNorm: 0.01313020     ValIndCrit: 0.00002871
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.98e-09
        -DiffCxt:  1.31e-07
    Outer Step:  1190      LossTrajs: 0.00001562     ContextsNorm: 0.01305957     ValIndCrit: 0.00002911
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.04e-08
        -DiffCxt:  5.17e-08
    Outer Step:  1200      LossTrajs: 0.00001608     ContextsNorm: 0.01304072     ValIndCrit: 0.00002858
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.78e-08
        -DiffCxt:  8.84e-08
    Outer Step:  1210      LossTrajs: 0.00002273     ContextsNorm: 0.01300263     ValIndCrit: 0.00002948
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.41e-08
        -DiffCxt:  2.63e-07
    Outer Step:  1220      LossTrajs: 0.00002200     ContextsNorm: 0.01303210     ValIndCrit: 0.00002875
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.11e-07
        -DiffCxt:  1.50e-06
    Outer Step:  1230      LossTrajs: 0.00001555     ContextsNorm: 0.01300681     ValIndCrit: 0.00002782
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.05e-09
        -DiffCxt:  2.57e-08
    Outer Step:  1240      LossTrajs: 0.00001817     ContextsNorm: 0.01304381     ValIndCrit: 0.00003022
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.24e-08
        -DiffCxt:  3.88e-07
    Outer Step:  1250      LossTrajs: 0.00001526     ContextsNorm: 0.01301974     ValIndCrit: 0.00002768
        Saving best model so far ...
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.62e-10
        -DiffCxt:  1.39e-08
    Outer Step:  1260      LossTrajs: 0.00001512     ContextsNorm: 0.01300084     ValIndCrit: 0.00002739
        Saving best model so far ...
        -NbInnerStepsNode:    4
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.61e-10
        -DiffCxt:  1.74e-08
    Outer Step:  1270      LossTrajs: 0.00001572     ContextsNorm: 0.01298191     ValIndCrit: 0.00002783
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.27e-09
        -DiffCxt:  5.19e-08
    Outer Step:  1280      LossTrajs: 0.00001786     ContextsNorm: 0.01297754     ValIndCrit: 0.00002741
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.91e-08
        -DiffCxt:  2.73e-07
    Outer Step:  1290      LossTrajs: 0.00001539     ContextsNorm: 0.01297357     ValIndCrit: 0.00002724
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.22e-08
        -DiffCxt:  5.98e-08
    Outer Step:  1300      LossTrajs: 0.00001563     ContextsNorm: 0.01294379     ValIndCrit: 0.00002678
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.03e-08
        -DiffCxt:  6.03e-08
    Outer Step:  1310      LossTrajs: 0.00001883     ContextsNorm: 0.01289058     ValIndCrit: 0.00002902
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.99e-08
        -DiffCxt:  1.24e-06
    Outer Step:  1320      LossTrajs: 0.00001627     ContextsNorm: 0.01291045     ValIndCrit: 0.00002693
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.59e-08
        -DiffCxt:  1.33e-07
    Outer Step:  1330      LossTrajs: 0.00001519     ContextsNorm: 0.01292389     ValIndCrit: 0.00002651
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.87e-09
        -DiffCxt:  6.29e-08
    Outer Step:  1340      LossTrajs: 0.00001526     ContextsNorm: 0.01292622     ValIndCrit: 0.00002647
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.48e-09
        -DiffCxt:  4.23e-08
    Outer Step:  1350      LossTrajs: 0.00001493     ContextsNorm: 0.01290762     ValIndCrit: 0.00002650
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.05e-10
        -DiffCxt:  2.60e-08
    Outer Step:  1360      LossTrajs: 0.00001514     ContextsNorm: 0.01289593     ValIndCrit: 0.00002626
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.09e-10
        -DiffCxt:  5.00e-08
    Outer Step:  1370      LossTrajs: 0.00001777     ContextsNorm: 0.01295644     ValIndCrit: 0.00003060
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.40e-07
        -DiffCxt:  1.76e-06
    Outer Step:  1380      LossTrajs: 0.00001498     ContextsNorm: 0.01291665     ValIndCrit: 0.00002616
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.58e-10
        -DiffCxt:  3.20e-08
    Outer Step:  1390      LossTrajs: 0.00001687     ContextsNorm: 0.01284358     ValIndCrit: 0.00002587
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.12e-08
        -DiffCxt:  3.18e-07
    Outer Step:  1400      LossTrajs: 0.00001494     ContextsNorm: 0.01283172     ValIndCrit: 0.00002621
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.89e-10
        -DiffCxt:  2.82e-08
    Outer Step:  1410      LossTrajs: 0.00001489     ContextsNorm: 0.01282435     ValIndCrit: 0.00002625
        -NbInnerStepsNode:    5
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.48e-10
        -DiffCxt:  2.72e-08
    Outer Step:  1420      LossTrajs: 0.00001479     ContextsNorm: 0.01279444     ValIndCrit: 0.00002630
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.16e-10
        -DiffCxt:  3.39e-08
    Outer Step:  1430      LossTrajs: 0.00001485     ContextsNorm: 0.01278943     ValIndCrit: 0.00002602
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.60e-10
        -DiffCxt:  1.88e-08
    Outer Step:  1440      LossTrajs: 0.00001461     ContextsNorm: 0.01275550     ValIndCrit: 0.00002672
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.11e-10
        -DiffCxt:  1.04e-07
    Outer Step:  1450      LossTrajs: 0.00001582     ContextsNorm: 0.01275576     ValIndCrit: 0.00002637
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.61e-08
        -DiffCxt:  4.33e-07
    Outer Step:  1460      LossTrajs: 0.00001493     ContextsNorm: 0.01273684     ValIndCrit: 0.00002502
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.58e-09
        -DiffCxt:  6.62e-08
    Outer Step:  1470      LossTrajs: 0.00001562     ContextsNorm: 0.01274833     ValIndCrit: 0.00002603
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.13e-08
        -DiffCxt:  8.00e-08
    Outer Step:  1480      LossTrajs: 0.00001600     ContextsNorm: 0.01276519     ValIndCrit: 0.00002491
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.47e-08
        -DiffCxt:  5.17e-08
    Outer Step:  1490      LossTrajs: 0.00001640     ContextsNorm: 0.01277167     ValIndCrit: 0.00002731
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.87e-08
        -DiffCxt:  3.75e-07
    Outer Step:  1500      LossTrajs: 0.00001711     ContextsNorm: 0.01271133     ValIndCrit: 0.00002643
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.07e-08
        -DiffCxt:  2.50e-07
    Outer Step:  1510      LossTrajs: 0.00001654     ContextsNorm: 0.01274741     ValIndCrit: 0.00002548
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.14e-08
        -DiffCxt:  1.35e-07
    Outer Step:  1520      LossTrajs: 0.00001468     ContextsNorm: 0.01267006     ValIndCrit: 0.00002431
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.00e-08
        -DiffCxt:  7.60e-08
    Outer Step:  1530      LossTrajs: 0.00001507     ContextsNorm: 0.01269135     ValIndCrit: 0.00002487
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.98e-09
        -DiffCxt:  6.12e-08
    Outer Step:  1540      LossTrajs: 0.00001504     ContextsNorm: 0.01264866     ValIndCrit: 0.00002503
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.23e-09
        -DiffCxt:  2.27e-08
    Outer Step:  1550      LossTrajs: 0.00001506     ContextsNorm: 0.01261035     ValIndCrit: 0.00002435
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.47e-08
        -DiffCxt:  7.23e-08
    Outer Step:  1560      LossTrajs: 0.00001440     ContextsNorm: 0.01256678     ValIndCrit: 0.00002436
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.10e-09
        -DiffCxt:  4.59e-08
    Outer Step:  1570      LossTrajs: 0.00001478     ContextsNorm: 0.01254828     ValIndCrit: 0.00002412
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.42e-09
        -DiffCxt:  3.39e-08
    Outer Step:  1580      LossTrajs: 0.00002509     ContextsNorm: 0.01252760     ValIndCrit: 0.00002578
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.46e-07
        -DiffCxt:  6.51e-07
    Outer Step:  1590      LossTrajs: 0.00001448     ContextsNorm: 0.01253809     ValIndCrit: 0.00002433
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.86e-09
        -DiffCxt:  2.83e-08
    Outer Step:  1600      LossTrajs: 0.00001467     ContextsNorm: 0.01249673     ValIndCrit: 0.00002460
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.46e-08
        -DiffCxt:  1.62e-07
    Outer Step:  1610      LossTrajs: 0.00001444     ContextsNorm: 0.01249596     ValIndCrit: 0.00002386
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.39e-09
        -DiffCxt:  3.06e-08
    Outer Step:  1620      LossTrajs: 0.00002901     ContextsNorm: 0.01255269     ValIndCrit: 0.00002830
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.51e-07
        -DiffCxt:  2.19e-06
    Outer Step:  1630      LossTrajs: 0.00001433     ContextsNorm: 0.01256491     ValIndCrit: 0.00002392
        -NbInnerStepsNode:    5
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.41e-10
        -DiffCxt:  2.67e-08
    Outer Step:  1640      LossTrajs: 0.00001435     ContextsNorm: 0.01254752     ValIndCrit: 0.00002354
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.56e-10
        -DiffCxt:  1.90e-08
    Outer Step:  1650      LossTrajs: 0.00001423     ContextsNorm: 0.01251728     ValIndCrit: 0.00002387
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.55e-10
        -DiffCxt:  3.52e-08
    Outer Step:  1660      LossTrajs: 0.00001417     ContextsNorm: 0.01249604     ValIndCrit: 0.00002380
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.00e-10
        -DiffCxt:  2.41e-08
    Outer Step:  1670      LossTrajs: 0.00001428     ContextsNorm: 0.01247684     ValIndCrit: 0.00002346
        Saving best model so far ...
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.57e-10
        -DiffCxt:  5.11e-08
    Outer Step:  1680      LossTrajs: 0.00001428     ContextsNorm: 0.01246544     ValIndCrit: 0.00002392
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.53e-09
        -DiffCxt:  7.09e-08
    Outer Step:  1690      LossTrajs: 0.00001463     ContextsNorm: 0.01250221     ValIndCrit: 0.00002437
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.15e-09
        -DiffCxt:  8.17e-08
    Outer Step:  1700      LossTrajs: 0.00001481     ContextsNorm: 0.01251971     ValIndCrit: 0.00002321
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.91e-08
        -DiffCxt:  2.03e-07
    Outer Step:  1710      LossTrajs: 0.00001437     ContextsNorm: 0.01247570     ValIndCrit: 0.00002372
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.61e-09
        -DiffCxt:  7.85e-08
    Outer Step:  1720      LossTrajs: 0.00001509     ContextsNorm: 0.01246950     ValIndCrit: 0.00002321
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.33e-09
        -DiffCxt:  9.19e-08
    Outer Step:  1730      LossTrajs: 0.00001426     ContextsNorm: 0.01245213     ValIndCrit: 0.00002318
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.15e-09
        -DiffCxt:  4.97e-08
    Outer Step:  1740      LossTrajs: 0.00001458     ContextsNorm: 0.01247462     ValIndCrit: 0.00002341
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.04e-09
        -DiffCxt:  8.95e-08
    Outer Step:  1750      LossTrajs: 0.00001464     ContextsNorm: 0.01258795     ValIndCrit: 0.00002275
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   22
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.28e-09
        -DiffCxt:  8.11e-09
    Outer Step:  1760      LossTrajs: 0.00001434     ContextsNorm: 0.01254563     ValIndCrit: 0.00002351
        -NbInnerStepsNode:    4
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.21e-10
        -DiffCxt:  4.02e-08
    Outer Step:  1770      LossTrajs: 0.00001421     ContextsNorm: 0.01252325     ValIndCrit: 0.00002332
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.30e-10
        -DiffCxt:  1.65e-08
    Outer Step:  1780      LossTrajs: 0.00001405     ContextsNorm: 0.01250647     ValIndCrit: 0.00002308
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.42e-10
        -DiffCxt:  3.64e-08
    Outer Step:  1790      LossTrajs: 0.00001410     ContextsNorm: 0.01248753     ValIndCrit: 0.00002337
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.62e-10
        -DiffCxt:  3.30e-08
    Outer Step:  1800      LossTrajs: 0.00001403     ContextsNorm: 0.01246278     ValIndCrit: 0.00002308
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.71e-10
        -DiffCxt:  5.39e-08
    Outer Step:  1810      LossTrajs: 0.00001411     ContextsNorm: 0.01245229     ValIndCrit: 0.00002255
        Saving best model so far ...
        -NbInnerStepsNode:    5
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.08e-10
        -DiffCxt:  5.90e-08
    Outer Step:  1820      LossTrajs: 0.00001420     ContextsNorm: 0.01246816     ValIndCrit: 0.00002275
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.92e-09
        -DiffCxt:  8.88e-08
    Outer Step:  1830      LossTrajs: 0.00001401     ContextsNorm: 0.01247446     ValIndCrit: 0.00002320
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.88e-09
        -DiffCxt:  3.85e-08
    Outer Step:  1840      LossTrajs: 0.00001439     ContextsNorm: 0.01245281     ValIndCrit: 0.00002318
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.24e-09
        -DiffCxt:  1.22e-07
    Outer Step:  1850      LossTrajs: 0.00001876     ContextsNorm: 0.01250930     ValIndCrit: 0.00002447
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.32e-08
        -DiffCxt:  6.94e-07
    Outer Step:  1860      LossTrajs: 0.00001417     ContextsNorm: 0.01250948     ValIndCrit: 0.00002298
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   22
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.07e-10
        -DiffCxt:  8.80e-09
    Outer Step:  1870      LossTrajs: 0.00001394     ContextsNorm: 0.01249537     ValIndCrit: 0.00002301
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   21
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.27e-10
        -DiffCxt:  9.82e-09
    Outer Step:  1880      LossTrajs: 0.00001399     ContextsNorm: 0.01247781     ValIndCrit: 0.00002271
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.63e-10
        -DiffCxt:  1.75e-08
    Outer Step:  1890      LossTrajs: 0.00001403     ContextsNorm: 0.01245640     ValIndCrit: 0.00002339
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.14e-10
        -DiffCxt:  2.28e-08
    Outer Step:  1900      LossTrajs: 0.00001404     ContextsNorm: 0.01244146     ValIndCrit: 0.00002323
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.72e-10
        -DiffCxt:  7.01e-08
    Outer Step:  1910      LossTrajs: 0.00001412     ContextsNorm: 0.01243974     ValIndCrit: 0.00002234
        Saving best model so far ...
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.17e-10
        -DiffCxt:  6.17e-08
    Outer Step:  1920      LossTrajs: 0.00001730     ContextsNorm: 0.01243033     ValIndCrit: 0.00002391
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.47e-08
        -DiffCxt:  5.75e-07
    Outer Step:  1930      LossTrajs: 0.00001442     ContextsNorm: 0.01250095     ValIndCrit: 0.00002236
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.85e-09
        -DiffCxt:  9.27e-08
    Outer Step:  1940      LossTrajs: 0.00001409     ContextsNorm: 0.01243077     ValIndCrit: 0.00002308
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.85e-09
        -DiffCxt:  5.51e-08
    Outer Step:  1950      LossTrajs: 0.00001737     ContextsNorm: 0.01243485     ValIndCrit: 0.00002379
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.48e-08
        -DiffCxt:  7.61e-08
    Outer Step:  1960      LossTrajs: 0.00001656     ContextsNorm: 0.01244101     ValIndCrit: 0.00002224
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.37e-08
        -DiffCxt:  7.23e-07
    Outer Step:  1970      LossTrajs: 0.00001405     ContextsNorm: 0.01242376     ValIndCrit: 0.00002240
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.48e-09
        -DiffCxt:  1.20e-07
    Outer Step:  1980      LossTrajs: 0.00001408     ContextsNorm: 0.01243138     ValIndCrit: 0.00002202
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.41e-08
        -DiffCxt:  9.47e-08
    Outer Step:  1990      LossTrajs: 0.00001404     ContextsNorm: 0.01246134     ValIndCrit: 0.00002199
        Saving best model so far ...
        -NbInnerStepsNode:    3
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.11e-10
        -DiffCxt:  1.55e-08
    Outer Step:  2000      LossTrajs: 0.00001402     ContextsNorm: 0.01243184     ValIndCrit: 0.00002241
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.60e-09
        -DiffCxt:  4.02e-08
    Outer Step:  2010      LossTrajs: 0.00001822     ContextsNorm: 0.01251970     ValIndCrit: 0.00002258
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.59e-08
        -DiffCxt:  4.84e-07
    Outer Step:  2020      LossTrajs: 0.00001409     ContextsNorm: 0.01249910     ValIndCrit: 0.00002188
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.53e-09
        -DiffCxt:  3.30e-08
    Outer Step:  2030      LossTrajs: 0.00001413     ContextsNorm: 0.01248540     ValIndCrit: 0.00002213
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.74e-09
        -DiffCxt:  3.13e-08
    Outer Step:  2040      LossTrajs: 0.00001450     ContextsNorm: 0.01258905     ValIndCrit: 0.00002097
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.99e-09
        -DiffCxt:  4.36e-08
    Outer Step:  2050      LossTrajs: 0.00001436     ContextsNorm: 0.01254860     ValIndCrit: 0.00002193
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.11e-09
        -DiffCxt:  2.93e-08
    Outer Step:  2060      LossTrajs: 0.00001410     ContextsNorm: 0.01238226     ValIndCrit: 0.00002178
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.20e-09
        -DiffCxt:  2.58e-08
    Outer Step:  2070      LossTrajs: 0.00001609     ContextsNorm: 0.01234049     ValIndCrit: 0.00002249
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.01e-09
        -DiffCxt:  1.73e-07
    Outer Step:  2080      LossTrajs: 0.00001557     ContextsNorm: 0.01234766     ValIndCrit: 0.00002438
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.18e-08
        -DiffCxt:  8.13e-07
    Outer Step:  2090      LossTrajs: 0.00001447     ContextsNorm: 0.01238936     ValIndCrit: 0.00002226
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.34e-08
        -DiffCxt:  1.08e-07
    Outer Step:  2100      LossTrajs: 0.00003359     ContextsNorm: 0.01227738     ValIndCrit: 0.00002369
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.82e-07
        -DiffCxt:  3.00e-06
    Outer Step:  2110      LossTrajs: 0.00001457     ContextsNorm: 0.01225806     ValIndCrit: 0.00002167
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.96e-09
        -DiffCxt:  1.17e-07
    Outer Step:  2120      LossTrajs: 0.00001381     ContextsNorm: 0.01224988     ValIndCrit: 0.00002136
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.14e-09
        -DiffCxt:  5.23e-08
    Outer Step:  2130      LossTrajs: 0.00002837     ContextsNorm: 0.01225829     ValIndCrit: 0.00003100
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.19e-07
        -DiffCxt:  3.54e-06
    Outer Step:  2140      LossTrajs: 0.00001506     ContextsNorm: 0.01224626     ValIndCrit: 0.00002066
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.55e-08
        -DiffCxt:  6.77e-08
    Outer Step:  2150      LossTrajs: 0.00001429     ContextsNorm: 0.01217992     ValIndCrit: 0.00002180
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.96e-09
        -DiffCxt:  6.37e-08
    Outer Step:  2160      LossTrajs: 0.00001495     ContextsNorm: 0.01219547     ValIndCrit: 0.00002224
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.82e-08
        -DiffCxt:  3.54e-07
    Outer Step:  2170      LossTrajs: 0.00001440     ContextsNorm: 0.01216308     ValIndCrit: 0.00002126
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.77e-08
        -DiffCxt:  1.41e-07
    Outer Step:  2180      LossTrajs: 0.00001349     ContextsNorm: 0.01211367     ValIndCrit: 0.00002124
        -NbInnerStepsNode:    6
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.84e-10
        -DiffCxt:  2.63e-08
    Outer Step:  2190      LossTrajs: 0.00001392     ContextsNorm: 0.01204182     ValIndCrit: 0.00002089
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.96e-08
        -DiffCxt:  4.99e-08
    Outer Step:  2200      LossTrajs: 0.00001691     ContextsNorm: 0.01200055     ValIndCrit: 0.00002129
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.62e-08
        -DiffCxt:  3.02e-07
    Outer Step:  2210      LossTrajs: 0.00001390     ContextsNorm: 0.01201410     ValIndCrit: 0.00002070
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.49e-08
        -DiffCxt:  3.45e-08
    Outer Step:  2220      LossTrajs: 0.00001481     ContextsNorm: 0.01196176     ValIndCrit: 0.00002062
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.50e-08
        -DiffCxt:  1.09e-07
    Outer Step:  2230      LossTrajs: 0.00001345     ContextsNorm: 0.01199052     ValIndCrit: 0.00002139
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.68e-09
        -DiffCxt:  3.93e-08
    Outer Step:  2240      LossTrajs: 0.00001385     ContextsNorm: 0.01200912     ValIndCrit: 0.00002098
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.54e-09
        -DiffCxt:  2.34e-08
    Outer Step:  2250      LossTrajs: 0.00001410     ContextsNorm: 0.01200266     ValIndCrit: 0.00002112
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.89e-08
        -DiffCxt:  1.86e-07
    Outer Step:  2260      LossTrajs: 0.00001376     ContextsNorm: 0.01193150     ValIndCrit: 0.00002002
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.72e-08
        -DiffCxt:  1.69e-07
    Outer Step:  2270      LossTrajs: 0.00001334     ContextsNorm: 0.01192547     ValIndCrit: 0.00002065
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.23e-09
        -DiffCxt:  3.05e-08
    Outer Step:  2280      LossTrajs: 0.00001335     ContextsNorm: 0.01190919     ValIndCrit: 0.00002040
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.67e-09
        -DiffCxt:  3.49e-08
    Outer Step:  2290      LossTrajs: 0.00001328     ContextsNorm: 0.01190664     ValIndCrit: 0.00002003
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.05e-08
        -DiffCxt:  5.87e-08
    Outer Step:  2300      LossTrajs: 0.00001678     ContextsNorm: 0.01189409     ValIndCrit: 0.00002441
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.14e-08
        -DiffCxt:  7.26e-07
    Outer Step:  2310      LossTrajs: 0.00001371     ContextsNorm: 0.01179769     ValIndCrit: 0.00002003
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.60e-09
        -DiffCxt:  9.14e-08
    Outer Step:  2320      LossTrajs: 0.00001426     ContextsNorm: 0.01176625     ValIndCrit: 0.00002041
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.82e-08
        -DiffCxt:  1.59e-07
    Outer Step:  2330      LossTrajs: 0.00001330     ContextsNorm: 0.01174932     ValIndCrit: 0.00002029
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.20e-09
        -DiffCxt:  3.13e-08
    Outer Step:  2340      LossTrajs: 0.00001301     ContextsNorm: 0.01173588     ValIndCrit: 0.00001987
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.78e-10
        -DiffCxt:  4.93e-08
    Outer Step:  2350      LossTrajs: 0.00001616     ContextsNorm: 0.01176199     ValIndCrit: 0.00002077
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.46e-08
        -DiffCxt:  1.47e-07
    Outer Step:  2360      LossTrajs: 0.00001296     ContextsNorm: 0.01175289     ValIndCrit: 0.00001967
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.75e-10
        -DiffCxt:  2.94e-08
    Outer Step:  2370      LossTrajs: 0.00001301     ContextsNorm: 0.01172729     ValIndCrit: 0.00002013
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.16e-09
        -DiffCxt:  2.90e-08
    Outer Step:  2380      LossTrajs: 0.00001557     ContextsNorm: 0.01170760     ValIndCrit: 0.00001990
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.17e-08
        -DiffCxt:  7.53e-07
    Outer Step:  2390      LossTrajs: 0.00001280     ContextsNorm: 0.01166798     ValIndCrit: 0.00002005
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.78e-10
        -DiffCxt:  3.11e-08
    Outer Step:  2400      LossTrajs: 0.00001371     ContextsNorm: 0.01170263     ValIndCrit: 0.00001995
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.91e-08
        -DiffCxt:  3.21e-07
    Outer Step:  2410      LossTrajs: 0.00001293     ContextsNorm: 0.01171003     ValIndCrit: 0.00001968
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.42e-10
        -DiffCxt:  1.75e-08
    Outer Step:  2420      LossTrajs: 0.00001741     ContextsNorm: 0.01169427     ValIndCrit: 0.00001907
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.86e-08
        -DiffCxt:  1.02e-07
    Outer Step:  2430      LossTrajs: 0.00001312     ContextsNorm: 0.01168921     ValIndCrit: 0.00002069
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.09e-09
        -DiffCxt:  6.52e-08
    Outer Step:  2440      LossTrajs: 0.00002087     ContextsNorm: 0.01168250     ValIndCrit: 0.00002377
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.07e-07
        -DiffCxt:  1.14e-06
    Outer Step:  2450      LossTrajs: 0.00001287     ContextsNorm: 0.01169491     ValIndCrit: 0.00001913
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.71e-10
        -DiffCxt:  2.46e-08
    Outer Step:  2460      LossTrajs: 0.00001287     ContextsNorm: 0.01168014     ValIndCrit: 0.00001980
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.29e-10
        -DiffCxt:  2.37e-08
    Outer Step:  2470      LossTrajs: 0.00001286     ContextsNorm: 0.01166460     ValIndCrit: 0.00001939
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.36e-10
        -DiffCxt:  3.88e-08
    Outer Step:  2480      LossTrajs: 0.00001282     ContextsNorm: 0.01166266     ValIndCrit: 0.00001955
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.38e-10
        -DiffCxt:  1.90e-08
    Outer Step:  2490      LossTrajs: 0.00001295     ContextsNorm: 0.01164559     ValIndCrit: 0.00001955
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.15e-10
        -DiffCxt:  4.97e-08
    Outer Step:  2500      LossTrajs: 0.00001280     ContextsNorm: 0.01163537     ValIndCrit: 0.00001945
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.23e-10
        -DiffCxt:  6.31e-08
    Outer Step:  2510      LossTrajs: 0.00001286     ContextsNorm: 0.01161576     ValIndCrit: 0.00001943
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.93e-10
        -DiffCxt:  7.44e-08
    Outer Step:  2520      LossTrajs: 0.00001308     ContextsNorm: 0.01160579     ValIndCrit: 0.00001887
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.70e-09
        -DiffCxt:  1.73e-07
    Outer Step:  2530      LossTrajs: 0.00001699     ContextsNorm: 0.01155439     ValIndCrit: 0.00002075
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.61e-08
        -DiffCxt:  3.03e-07
    Outer Step:  2540      LossTrajs: 0.00001854     ContextsNorm: 0.01152773     ValIndCrit: 0.00002093
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.05e-08
        -DiffCxt:  3.78e-07
    Outer Step:  2550      LossTrajs: 0.00001268     ContextsNorm: 0.01151701     ValIndCrit: 0.00001907
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.49e-09
        -DiffCxt:  5.88e-08
    Outer Step:  2560      LossTrajs: 0.00001282     ContextsNorm: 0.01148021     ValIndCrit: 0.00001887
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.04e-09
        -DiffCxt:  4.80e-08
    Outer Step:  2570      LossTrajs: 0.00001344     ContextsNorm: 0.01152368     ValIndCrit: 0.00001928
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.07e-09
        -DiffCxt:  6.33e-08
    Outer Step:  2580      LossTrajs: 0.00001281     ContextsNorm: 0.01152042     ValIndCrit: 0.00001971
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.14e-09
        -DiffCxt:  2.01e-08
    Outer Step:  2590      LossTrajs: 0.00001316     ContextsNorm: 0.01156960     ValIndCrit: 0.00001918
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.93e-09
        -DiffCxt:  6.24e-08
    Outer Step:  2600      LossTrajs: 0.00001277     ContextsNorm: 0.01154512     ValIndCrit: 0.00001894
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   23
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.46e-10
        -DiffCxt:  8.73e-09
    Outer Step:  2610      LossTrajs: 0.00002040     ContextsNorm: 0.01161859     ValIndCrit: 0.00002104
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.19e-07
        -DiffCxt:  7.10e-07
    Outer Step:  2620      LossTrajs: 0.00001276     ContextsNorm: 0.01154554     ValIndCrit: 0.00001897
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.15e-10
        -DiffCxt:  3.78e-08
    Outer Step:  2630      LossTrajs: 0.00001279     ContextsNorm: 0.01151201     ValIndCrit: 0.00001904
        -NbInnerStepsNode:    3
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.52e-10
        -DiffCxt:  6.16e-08
    Outer Step:  2640      LossTrajs: 0.00001266     ContextsNorm: 0.01149868     ValIndCrit: 0.00001909
        -NbInnerStepsNode:    9
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.32e-10
        -DiffCxt:  4.29e-08
    Outer Step:  2650      LossTrajs: 0.00001262     ContextsNorm: 0.01148007     ValIndCrit: 0.00001894
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.65e-10
        -DiffCxt:  4.45e-08
    Outer Step:  2660      LossTrajs: 0.00001257     ContextsNorm: 0.01146694     ValIndCrit: 0.00001897
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.08e-10
        -DiffCxt:  2.66e-08
    Outer Step:  2670      LossTrajs: 0.00001265     ContextsNorm: 0.01145810     ValIndCrit: 0.00001881
        Saving best model so far ...
        -NbInnerStepsNode:    6
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.04e-10
        -DiffCxt:  4.15e-08
    Outer Step:  2680      LossTrajs: 0.00001285     ContextsNorm: 0.01146526     ValIndCrit: 0.00001881
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.32e-09
        -DiffCxt:  7.02e-08
    Outer Step:  2690      LossTrajs: 0.00001254     ContextsNorm: 0.01147262     ValIndCrit: 0.00001875
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.98e-10
        -DiffCxt:  5.72e-08
    Outer Step:  2700      LossTrajs: 0.00001377     ContextsNorm: 0.01147013     ValIndCrit: 0.00001909
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.14e-08
        -DiffCxt:  1.99e-07
    Outer Step:  2710      LossTrajs: 0.00003040     ContextsNorm: 0.01154138     ValIndCrit: 0.00001762
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 2.66e-07
        -DiffCxt:  6.36e-07
    Outer Step:  2720      LossTrajs: 0.00001266     ContextsNorm: 0.01152124     ValIndCrit: 0.00001846
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   19
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.18e-10
        -DiffCxt:  8.82e-09
    Outer Step:  2730      LossTrajs: 0.00001265     ContextsNorm: 0.01150395     ValIndCrit: 0.00001873
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.96e-10
        -DiffCxt:  5.10e-08
    Outer Step:  2740      LossTrajs: 0.00001262     ContextsNorm: 0.01148883     ValIndCrit: 0.00001894
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.41e-10
        -DiffCxt:  3.92e-08
    Outer Step:  2750      LossTrajs: 0.00001259     ContextsNorm: 0.01146328     ValIndCrit: 0.00001862
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.68e-10
        -DiffCxt:  3.30e-08
    Outer Step:  2760      LossTrajs: 0.00001259     ContextsNorm: 0.01143093     ValIndCrit: 0.00001874
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.51e-10
        -DiffCxt:  6.88e-08
    Outer Step:  2770      LossTrajs: 0.00001263     ContextsNorm: 0.01142560     ValIndCrit: 0.00001880
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.80e-10
        -DiffCxt:  1.79e-08
    Outer Step:  2780      LossTrajs: 0.00001251     ContextsNorm: 0.01142033     ValIndCrit: 0.00001873
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.26e-10
        -DiffCxt:  5.15e-08
    Outer Step:  2790      LossTrajs: 0.00001265     ContextsNorm: 0.01139937     ValIndCrit: 0.00001852
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.89e-10
        -DiffCxt:  8.44e-08
    Outer Step:  2800      LossTrajs: 0.00001254     ContextsNorm: 0.01137766     ValIndCrit: 0.00001931
        -NbInnerStepsNode:    3
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.17e-10
        -DiffCxt:  1.62e-07
    Outer Step:  2810      LossTrajs: 0.00001253     ContextsNorm: 0.01136744     ValIndCrit: 0.00001869
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.69e-10
        -DiffCxt:  8.23e-08
    Outer Step:  2820      LossTrajs: 0.00001242     ContextsNorm: 0.01134764     ValIndCrit: 0.00001885
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.15e-10
        -DiffCxt:  7.97e-08
    Outer Step:  2830      LossTrajs: 0.00001252     ContextsNorm: 0.01133393     ValIndCrit: 0.00001866
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.77e-10
        -DiffCxt:  1.07e-07
    Outer Step:  2840      LossTrajs: 0.00001244     ContextsNorm: 0.01132637     ValIndCrit: 0.00001872
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.38e-10
        -DiffCxt:  1.28e-07
    Outer Step:  2850      LossTrajs: 0.00001243     ContextsNorm: 0.01131094     ValIndCrit: 0.00001879
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.68e-10
        -DiffCxt:  7.01e-08
    Outer Step:  2860      LossTrajs: 0.00001232     ContextsNorm: 0.01129542     ValIndCrit: 0.00001902
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.53e-10
        -DiffCxt:  2.18e-07
    Outer Step:  2870      LossTrajs: 0.00001245     ContextsNorm: 0.01128645     ValIndCrit: 0.00001923
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.74e-10
        -DiffCxt:  1.27e-07
    Outer Step:  2880      LossTrajs: 0.00001248     ContextsNorm: 0.01128354     ValIndCrit: 0.00001848
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 4.58e-10
        -DiffCxt:  7.47e-08
    Outer Step:  2890      LossTrajs: 0.00001244     ContextsNorm: 0.01127595     ValIndCrit: 0.00001888
        -NbInnerStepsNode:   13
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 9.15e-10
        -DiffCxt:  2.40e-07
    Outer Step:  2900      LossTrajs: 0.00001236     ContextsNorm: 0.01126403     ValIndCrit: 0.00001882
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.14e-10
        -DiffCxt:  1.11e-07
    Outer Step:  2910      LossTrajs: 0.00001240     ContextsNorm: 0.01124449     ValIndCrit: 0.00001878
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.97e-10
        -DiffCxt:  9.21e-08
    Outer Step:  2920      LossTrajs: 0.00001242     ContextsNorm: 0.01122964     ValIndCrit: 0.00001879
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.31e-10
        -DiffCxt:  2.70e-07
    Outer Step:  2930      LossTrajs: 0.00001252     ContextsNorm: 0.01122219     ValIndCrit: 0.00001921
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.36e-09
        -DiffCxt:  1.49e-07
    Outer Step:  2940      LossTrajs: 0.00001239     ContextsNorm: 0.01120882     ValIndCrit: 0.00001836
        -NbInnerStepsNode:   23
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.69e-10
        -DiffCxt:  1.48e-07
    Outer Step:  2950      LossTrajs: 0.00001255     ContextsNorm: 0.01120086     ValIndCrit: 0.00001960
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.37e-09
        -DiffCxt:  1.97e-07
    Outer Step:  2960      LossTrajs: 0.00001260     ContextsNorm: 0.01118619     ValIndCrit: 0.00001860
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.85e-09
        -DiffCxt:  4.21e-08
    Outer Step:  2970      LossTrajs: 0.00001229     ContextsNorm: 0.01117085     ValIndCrit: 0.00001860
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.16e-10
        -DiffCxt:  9.91e-08
    Outer Step:  2980      LossTrajs: 0.00001213     ContextsNorm: 0.01114120     ValIndCrit: 0.00001897
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 7.31e-10
        -DiffCxt:  4.28e-08
    Outer Step:  2990      LossTrajs: 0.00001232     ContextsNorm: 0.01113240     ValIndCrit: 0.00001888
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 8.72e-10
        -DiffCxt:  6.42e-08
    Outer Step:  2999      LossTrajs: 0.00001459     ContextsNorm: 0.01114589     ValIndCrit: 0.00001888
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.23e-08
        -DiffCxt:  3.25e-07

Total gradient descent training time: 6 hours 7 mins 24 secs
Environment weights at the end of the training: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111
 0.11111111 0.11111111 0.11111111]
WARNING: You did not provide a dataloader id. A new one has been generated: 121424
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 9
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (In-Domain): 1.7621127e-05


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./adapt/
 Seed: 6078


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt_test
 Savepath: ./adapt/
 Seed: 6078

==  Begining in-domain visualisation ... ==
    Environment id: 5
    Trajectory id: 10
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 1500
    Total number of training steps: 1500

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 20, 2) (20,)
    Epoch:     0     LossContext: 0.02804177
    Epoch:     1     LossContext: 0.01386511
    Epoch:     2     LossContext: 0.00377265
    Epoch:     3     LossContext: 0.00037586
    Epoch:    10     LossContext: 0.00070005
    Epoch:    20     LossContext: 0.00090844
    Epoch:    30     LossContext: 0.00062284
    Epoch:    40     LossContext: 0.00009939
    Epoch:    50     LossContext: 0.00002739
    Epoch:    60     LossContext: 0.00004346
    Epoch:    70     LossContext: 0.00001411
    Epoch:    80     LossContext: 0.00001766
    Epoch:    90     LossContext: 0.00001423
    Epoch:   100     LossContext: 0.00001403
    Epoch:   110     LossContext: 0.00001402
    Epoch:   120     LossContext: 0.00001384
    Epoch:   130     LossContext: 0.00001379
    Epoch:   140     LossContext: 0.00001378
    Epoch:   150     LossContext: 0.00001376
    Epoch:   160     LossContext: 0.00001374
    Epoch:   170     LossContext: 0.00001372
    Epoch:   180     LossContext: 0.00001370
    Epoch:   190     LossContext: 0.00001368
    Epoch:   200     LossContext: 0.00001366
    Epoch:   210     LossContext: 0.00001364
    Epoch:   220     LossContext: 0.00001362
    Epoch:   230     LossContext: 0.00001360
    Epoch:   240     LossContext: 0.00001358
    Epoch:   250     LossContext: 0.00001355
    Epoch:   260     LossContext: 0.00001353
    Epoch:   270     LossContext: 0.00001351
    Epoch:   280     LossContext: 0.00001350
    Epoch:   290     LossContext: 0.00001348
    Epoch:   300     LossContext: 0.00001346
    Epoch:   310     LossContext: 0.00001344
    Epoch:   320     LossContext: 0.00001342
    Epoch:   330     LossContext: 0.00001340
    Epoch:   340     LossContext: 0.00001339
    Epoch:   350     LossContext: 0.00001337
    Epoch:   360     LossContext: 0.00001335
    Epoch:   370     LossContext: 0.00001333
    Epoch:   380     LossContext: 0.00001331
    Epoch:   390     LossContext: 0.00001329
    Epoch:   400     LossContext: 0.00001327
    Epoch:   410     LossContext: 0.00001325
    Epoch:   420     LossContext: 0.00001323
    Epoch:   430     LossContext: 0.00001321
    Epoch:   440     LossContext: 0.00001319
    Epoch:   450     LossContext: 0.00001317
    Epoch:   460     LossContext: 0.00001315
    Epoch:   470     LossContext: 0.00001313
    Epoch:   480     LossContext: 0.00001310
    Epoch:   490     LossContext: 0.00001308
    Epoch:   500     LossContext: 0.00001306
    Epoch:   510     LossContext: 0.00001304
    Epoch:   520     LossContext: 0.00001302
    Epoch:   530     LossContext: 0.00001300
    Epoch:   540     LossContext: 0.00001298
    Epoch:   550     LossContext: 0.00001296
    Epoch:   560     LossContext: 0.00001293
    Epoch:   570     LossContext: 0.00001291
    Epoch:   580     LossContext: 0.00001289
    Epoch:   590     LossContext: 0.00001287
    Epoch:   600     LossContext: 0.00001285
    Epoch:   610     LossContext: 0.00001283
    Epoch:   620     LossContext: 0.00001280
    Epoch:   630     LossContext: 0.00001278
    Epoch:   640     LossContext: 0.00001276
    Epoch:   650     LossContext: 0.00001274
    Epoch:   660     LossContext: 0.00001272
    Epoch:   670     LossContext: 0.00001270
    Epoch:   680     LossContext: 0.00001268
    Epoch:   690     LossContext: 0.00001266
    Epoch:   700     LossContext: 0.00001264
    Epoch:   710     LossContext: 0.00001262
    Epoch:   720     LossContext: 0.00001260
    Epoch:   730     LossContext: 0.00001258
    Epoch:   740     LossContext: 0.00001256
    Epoch:   750     LossContext: 0.00001254
    Epoch:   760     LossContext: 0.00001252
    Epoch:   770     LossContext: 0.00001251
    Epoch:   780     LossContext: 0.00001249
    Epoch:   790     LossContext: 0.00001247
    Epoch:   800     LossContext: 0.00001245
    Epoch:   810     LossContext: 0.00001244
    Epoch:   820     LossContext: 0.00001242
    Epoch:   830     LossContext: 0.00001240
    Epoch:   840     LossContext: 0.00001239
    Epoch:   850     LossContext: 0.00001237
    Epoch:   860     LossContext: 0.00001236
    Epoch:   870     LossContext: 0.00001234
    Epoch:   880     LossContext: 0.00001232
    Epoch:   890     LossContext: 0.00001231
    Epoch:   900     LossContext: 0.00001229
    Epoch:   910     LossContext: 0.00001228
    Epoch:   920     LossContext: 0.00001226
    Epoch:   930     LossContext: 0.00001224
    Epoch:   940     LossContext: 0.00001223
    Epoch:   950     LossContext: 0.00001221
    Epoch:   960     LossContext: 0.00001220
    Epoch:   970     LossContext: 0.00001218
    Epoch:   980     LossContext: 0.00001217
    Epoch:   990     LossContext: 0.00001215
    Epoch:  1000     LossContext: 0.00001214
    Epoch:  1010     LossContext: 0.00001213
    Epoch:  1020     LossContext: 0.00001212
    Epoch:  1030     LossContext: 0.00001211
    Epoch:  1040     LossContext: 0.00001211
    Epoch:  1050     LossContext: 0.00001210
    Epoch:  1060     LossContext: 0.00001209
    Epoch:  1070     LossContext: 0.00001208
    Epoch:  1080     LossContext: 0.00001208
    Epoch:  1090     LossContext: 0.00001207
    Epoch:  1100     LossContext: 0.00001206
    Epoch:  1110     LossContext: 0.00001205
    Epoch:  1120     LossContext: 0.00001204
    Epoch:  1130     LossContext: 0.00001204
    Epoch:  1140     LossContext: 0.00001203
    Epoch:  1150     LossContext: 0.00001202
    Epoch:  1160     LossContext: 0.00001201
    Epoch:  1170     LossContext: 0.00001200
    Epoch:  1180     LossContext: 0.00001200
    Epoch:  1190     LossContext: 0.00001199
    Epoch:  1200     LossContext: 0.00001198
    Epoch:  1210     LossContext: 0.00001197
    Epoch:  1220     LossContext: 0.00001197
    Epoch:  1230     LossContext: 0.00001196
    Epoch:  1240     LossContext: 0.00001195
    Epoch:  1250     LossContext: 0.00001194
    Epoch:  1260     LossContext: 0.00001193
    Epoch:  1270     LossContext: 0.00001192
    Epoch:  1280     LossContext: 0.00001192
    Epoch:  1290     LossContext: 0.00001191
    Epoch:  1300     LossContext: 0.00001190
    Epoch:  1310     LossContext: 0.00001189
    Epoch:  1320     LossContext: 0.00001188
    Epoch:  1330     LossContext: 0.00001188
    Epoch:  1340     LossContext: 0.00001187
    Epoch:  1350     LossContext: 0.00001186
    Epoch:  1360     LossContext: 0.00001185
    Epoch:  1370     LossContext: 0.00001184
    Epoch:  1380     LossContext: 0.00001184
    Epoch:  1390     LossContext: 0.00001183
    Epoch:  1400     LossContext: 0.00001182
    Epoch:  1410     LossContext: 0.00001181
    Epoch:  1420     LossContext: 0.00001180
    Epoch:  1430     LossContext: 0.00001179
    Epoch:  1440     LossContext: 0.00001179
    Epoch:  1450     LossContext: 0.00001178
    Epoch:  1460     LossContext: 0.00001177
    Epoch:  1470     LossContext: 0.00001176
    Epoch:  1480     LossContext: 0.00001175
    Epoch:  1490     LossContext: 0.00001175
    Epoch:  1499     LossContext: 0.00001174

Gradient descent adaptation time: 0 hours 1 mins 41 secs

Adapting to environment 1 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.14156272
    Epoch:     1     LossContext: 0.10476312
    Epoch:     2     LossContext: 0.07020460
    Epoch:     3     LossContext: 0.03926151
    Epoch:    10     LossContext: 0.01424806
    Epoch:    20     LossContext: 0.00843479
    Epoch:    30     LossContext: 0.00211315
    Epoch:    40     LossContext: 0.00065433
    Epoch:    50     LossContext: 0.00024071
    Epoch:    60     LossContext: 0.00004094
    Epoch:    70     LossContext: 0.00007435
    Epoch:    80     LossContext: 0.00005328
    Epoch:    90     LossContext: 0.00003393
    Epoch:   100     LossContext: 0.00003438
    Epoch:   110     LossContext: 0.00003323
    Epoch:   120     LossContext: 0.00003296
    Epoch:   130     LossContext: 0.00003275
    Epoch:   140     LossContext: 0.00003264
    Epoch:   150     LossContext: 0.00003257
    Epoch:   160     LossContext: 0.00003252
    Epoch:   170     LossContext: 0.00003247
    Epoch:   180     LossContext: 0.00003241
    Epoch:   190     LossContext: 0.00003236
    Epoch:   200     LossContext: 0.00003230
    Epoch:   210     LossContext: 0.00003225
    Epoch:   220     LossContext: 0.00003219
    Epoch:   230     LossContext: 0.00003214
    Epoch:   240     LossContext: 0.00003208
    Epoch:   250     LossContext: 0.00003202
    Epoch:   260     LossContext: 0.00003196
    Epoch:   270     LossContext: 0.00003190
    Epoch:   280     LossContext: 0.00003184
    Epoch:   290     LossContext: 0.00003178
    Epoch:   300     LossContext: 0.00003172
    Epoch:   310     LossContext: 0.00003166
    Epoch:   320     LossContext: 0.00003160
    Epoch:   330     LossContext: 0.00003154
    Epoch:   340     LossContext: 0.00003148
    Epoch:   350     LossContext: 0.00003142
    Epoch:   360     LossContext: 0.00003136
    Epoch:   370     LossContext: 0.00003130
    Epoch:   380     LossContext: 0.00003124
    Epoch:   390     LossContext: 0.00003118
    Epoch:   400     LossContext: 0.00003111
    Epoch:   410     LossContext: 0.00003105
    Epoch:   420     LossContext: 0.00003099
    Epoch:   430     LossContext: 0.00003093
    Epoch:   440     LossContext: 0.00003087
    Epoch:   450     LossContext: 0.00003081
    Epoch:   460     LossContext: 0.00003074
    Epoch:   470     LossContext: 0.00003068
    Epoch:   480     LossContext: 0.00003062
    Epoch:   490     LossContext: 0.00003056
    Epoch:   500     LossContext: 0.00003050
    Epoch:   510     LossContext: 0.00003044
    Epoch:   520     LossContext: 0.00003037
    Epoch:   530     LossContext: 0.00003031
    Epoch:   540     LossContext: 0.00003025
    Epoch:   550     LossContext: 0.00003019
    Epoch:   560     LossContext: 0.00003013
    Epoch:   570     LossContext: 0.00003007
    Epoch:   580     LossContext: 0.00003001
    Epoch:   590     LossContext: 0.00002995
    Epoch:   600     LossContext: 0.00002989
    Epoch:   610     LossContext: 0.00002983
    Epoch:   620     LossContext: 0.00002977
    Epoch:   630     LossContext: 0.00002971
    Epoch:   640     LossContext: 0.00002965
    Epoch:   650     LossContext: 0.00002959
    Epoch:   660     LossContext: 0.00002953
    Epoch:   670     LossContext: 0.00002947
    Epoch:   680     LossContext: 0.00002942
    Epoch:   690     LossContext: 0.00002936
    Epoch:   700     LossContext: 0.00002930
    Epoch:   710     LossContext: 0.00002924
    Epoch:   720     LossContext: 0.00002918
    Epoch:   730     LossContext: 0.00002913
    Epoch:   740     LossContext: 0.00002907
    Epoch:   750     LossContext: 0.00002901
    Epoch:   760     LossContext: 0.00002896
    Epoch:   770     LossContext: 0.00002890
    Epoch:   780     LossContext: 0.00002884
    Epoch:   790     LossContext: 0.00002879
    Epoch:   800     LossContext: 0.00002873
    Epoch:   810     LossContext: 0.00002867
    Epoch:   820     LossContext: 0.00002862
    Epoch:   830     LossContext: 0.00002856
    Epoch:   840     LossContext: 0.00002851
    Epoch:   850     LossContext: 0.00002845
    Epoch:   860     LossContext: 0.00002839
    Epoch:   870     LossContext: 0.00002834
    Epoch:   880     LossContext: 0.00002828
    Epoch:   890     LossContext: 0.00002823
    Epoch:   900     LossContext: 0.00002817
    Epoch:   910     LossContext: 0.00002812
    Epoch:   920     LossContext: 0.00002807
    Epoch:   930     LossContext: 0.00002801
    Epoch:   940     LossContext: 0.00002796
    Epoch:   950     LossContext: 0.00002791
    Epoch:   960     LossContext: 0.00002785
    Epoch:   970     LossContext: 0.00002780
    Epoch:   980     LossContext: 0.00002775
    Epoch:   990     LossContext: 0.00002769
    Epoch:  1000     LossContext: 0.00002764
    Epoch:  1010     LossContext: 0.00002761
    Epoch:  1020     LossContext: 0.00002759
    Epoch:  1030     LossContext: 0.00002756
    Epoch:  1040     LossContext: 0.00002753
    Epoch:  1050     LossContext: 0.00002751
    Epoch:  1060     LossContext: 0.00002748
    Epoch:  1070     LossContext: 0.00002745
    Epoch:  1080     LossContext: 0.00002742
    Epoch:  1090     LossContext: 0.00002740
    Epoch:  1100     LossContext: 0.00002737
    Epoch:  1110     LossContext: 0.00002734
    Epoch:  1120     LossContext: 0.00002731
    Epoch:  1130     LossContext: 0.00002729
    Epoch:  1140     LossContext: 0.00002726
    Epoch:  1150     LossContext: 0.00002723
    Epoch:  1160     LossContext: 0.00002720
    Epoch:  1170     LossContext: 0.00002717
    Epoch:  1180     LossContext: 0.00002714
    Epoch:  1190     LossContext: 0.00002712
    Epoch:  1200     LossContext: 0.00002709
    Epoch:  1210     LossContext: 0.00002706
    Epoch:  1220     LossContext: 0.00002703
    Epoch:  1230     LossContext: 0.00002700
    Epoch:  1240     LossContext: 0.00002697
    Epoch:  1250     LossContext: 0.00002694
    Epoch:  1260     LossContext: 0.00002691
    Epoch:  1270     LossContext: 0.00002688
    Epoch:  1280     LossContext: 0.00002685
    Epoch:  1290     LossContext: 0.00002682
    Epoch:  1300     LossContext: 0.00002679
    Epoch:  1310     LossContext: 0.00002676
    Epoch:  1320     LossContext: 0.00002673
    Epoch:  1330     LossContext: 0.00002670
    Epoch:  1340     LossContext: 0.00002667
    Epoch:  1350     LossContext: 0.00002664
    Epoch:  1360     LossContext: 0.00002661
    Epoch:  1370     LossContext: 0.00002658
    Epoch:  1380     LossContext: 0.00002655
    Epoch:  1390     LossContext: 0.00002652
    Epoch:  1400     LossContext: 0.00002649
    Epoch:  1410     LossContext: 0.00002646
    Epoch:  1420     LossContext: 0.00002643
    Epoch:  1430     LossContext: 0.00002640
    Epoch:  1440     LossContext: 0.00002636
    Epoch:  1450     LossContext: 0.00002633
    Epoch:  1460     LossContext: 0.00002630
    Epoch:  1470     LossContext: 0.00002627
    Epoch:  1480     LossContext: 0.00002624
    Epoch:  1490     LossContext: 0.00002621
    Epoch:  1499     LossContext: 0.00002618

Gradient descent adaptation time: 0 hours 1 mins 31 secs

Adapting to environment 2 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.03376555
    Epoch:     1     LossContext: 0.01907480
    Epoch:     2     LossContext: 0.00943352
    Epoch:     3     LossContext: 0.00375705
    Epoch:    10     LossContext: 0.00331734
    Epoch:    20     LossContext: 0.00157227
    Epoch:    30     LossContext: 0.00061553
    Epoch:    40     LossContext: 0.00003191
    Epoch:    50     LossContext: 0.00013471
    Epoch:    60     LossContext: 0.00005843
    Epoch:    70     LossContext: 0.00002886
    Epoch:    80     LossContext: 0.00003035
    Epoch:    90     LossContext: 0.00002999
    Epoch:   100     LossContext: 0.00002848
    Epoch:   110     LossContext: 0.00002771
    Epoch:   120     LossContext: 0.00002740
    Epoch:   130     LossContext: 0.00002719
    Epoch:   140     LossContext: 0.00002700
    Epoch:   150     LossContext: 0.00002682
    Epoch:   160     LossContext: 0.00002663
    Epoch:   170     LossContext: 0.00002645
    Epoch:   180     LossContext: 0.00002627
    Epoch:   190     LossContext: 0.00002611
    Epoch:   200     LossContext: 0.00002595
    Epoch:   210     LossContext: 0.00002579
    Epoch:   220     LossContext: 0.00002564
    Epoch:   230     LossContext: 0.00002549
    Epoch:   240     LossContext: 0.00002534
    Epoch:   250     LossContext: 0.00002519
    Epoch:   260     LossContext: 0.00002505
    Epoch:   270     LossContext: 0.00002492
    Epoch:   280     LossContext: 0.00002479
    Epoch:   290     LossContext: 0.00002467
    Epoch:   300     LossContext: 0.00002455
    Epoch:   310     LossContext: 0.00002443
    Epoch:   320     LossContext: 0.00002431
    Epoch:   330     LossContext: 0.00002420
    Epoch:   340     LossContext: 0.00002410
    Epoch:   350     LossContext: 0.00002400
    Epoch:   360     LossContext: 0.00002390
    Epoch:   370     LossContext: 0.00002381
    Epoch:   380     LossContext: 0.00002372
    Epoch:   390     LossContext: 0.00002363
    Epoch:   400     LossContext: 0.00002355
    Epoch:   410     LossContext: 0.00002346
    Epoch:   420     LossContext: 0.00002338
    Epoch:   430     LossContext: 0.00002330
    Epoch:   440     LossContext: 0.00002323
    Epoch:   450     LossContext: 0.00002316
    Epoch:   460     LossContext: 0.00002308
    Epoch:   470     LossContext: 0.00002301
    Epoch:   480     LossContext: 0.00002294
    Epoch:   490     LossContext: 0.00002287
    Epoch:   500     LossContext: 0.00002280
    Epoch:   510     LossContext: 0.00002273
    Epoch:   520     LossContext: 0.00002267
    Epoch:   530     LossContext: 0.00002261
    Epoch:   540     LossContext: 0.00002255
    Epoch:   550     LossContext: 0.00002249
    Epoch:   560     LossContext: 0.00002244
    Epoch:   570     LossContext: 0.00002238
    Epoch:   580     LossContext: 0.00002233
    Epoch:   590     LossContext: 0.00002228
    Epoch:   600     LossContext: 0.00002224
    Epoch:   610     LossContext: 0.00002219
    Epoch:   620     LossContext: 0.00002214
    Epoch:   630     LossContext: 0.00002209
    Epoch:   640     LossContext: 0.00002205
    Epoch:   650     LossContext: 0.00002200
    Epoch:   660     LossContext: 0.00002195
    Epoch:   670     LossContext: 0.00002191
    Epoch:   680     LossContext: 0.00002187
    Epoch:   690     LossContext: 0.00002183
    Epoch:   700     LossContext: 0.00002179
    Epoch:   710     LossContext: 0.00002176
    Epoch:   720     LossContext: 0.00002172
    Epoch:   730     LossContext: 0.00002169
    Epoch:   740     LossContext: 0.00002166
    Epoch:   750     LossContext: 0.00002163
    Epoch:   760     LossContext: 0.00002160
    Epoch:   770     LossContext: 0.00002157
    Epoch:   780     LossContext: 0.00002154
    Epoch:   790     LossContext: 0.00002151
    Epoch:   800     LossContext: 0.00002148
    Epoch:   810     LossContext: 0.00002145
    Epoch:   820     LossContext: 0.00002142
    Epoch:   830     LossContext: 0.00002139
    Epoch:   840     LossContext: 0.00002137
    Epoch:   850     LossContext: 0.00002134
    Epoch:   860     LossContext: 0.00002131
    Epoch:   870     LossContext: 0.00002129
    Epoch:   880     LossContext: 0.00002126
    Epoch:   890     LossContext: 0.00002124
    Epoch:   900     LossContext: 0.00002121
    Epoch:   910     LossContext: 0.00002119
    Epoch:   920     LossContext: 0.00002116
    Epoch:   930     LossContext: 0.00002114
    Epoch:   940     LossContext: 0.00002112
    Epoch:   950     LossContext: 0.00002109
    Epoch:   960     LossContext: 0.00002107
    Epoch:   970     LossContext: 0.00002106
    Epoch:   980     LossContext: 0.00002104
    Epoch:   990     LossContext: 0.00002102
    Epoch:  1000     LossContext: 0.00002100
    Epoch:  1010     LossContext: 0.00002099
    Epoch:  1020     LossContext: 0.00002098
    Epoch:  1030     LossContext: 0.00002097
    Epoch:  1040     LossContext: 0.00002096
    Epoch:  1050     LossContext: 0.00002096
    Epoch:  1060     LossContext: 0.00002095
    Epoch:  1070     LossContext: 0.00002094
    Epoch:  1080     LossContext: 0.00002093
    Epoch:  1090     LossContext: 0.00002092
    Epoch:  1100     LossContext: 0.00002092
    Epoch:  1110     LossContext: 0.00002091
    Epoch:  1120     LossContext: 0.00002090
    Epoch:  1130     LossContext: 0.00002089
    Epoch:  1140     LossContext: 0.00002088
    Epoch:  1150     LossContext: 0.00002088
    Epoch:  1160     LossContext: 0.00002087
    Epoch:  1170     LossContext: 0.00002086
    Epoch:  1180     LossContext: 0.00002085
    Epoch:  1190     LossContext: 0.00002085
    Epoch:  1200     LossContext: 0.00002084
    Epoch:  1210     LossContext: 0.00002083
    Epoch:  1220     LossContext: 0.00002082
    Epoch:  1230     LossContext: 0.00002081
    Epoch:  1240     LossContext: 0.00002081
    Epoch:  1250     LossContext: 0.00002080
    Epoch:  1260     LossContext: 0.00002079
    Epoch:  1270     LossContext: 0.00002078
    Epoch:  1280     LossContext: 0.00002078
    Epoch:  1290     LossContext: 0.00002077
    Epoch:  1300     LossContext: 0.00002076
    Epoch:  1310     LossContext: 0.00002075
    Epoch:  1320     LossContext: 0.00002074
    Epoch:  1330     LossContext: 0.00002074
    Epoch:  1340     LossContext: 0.00002073
    Epoch:  1350     LossContext: 0.00002072
    Epoch:  1360     LossContext: 0.00002071
    Epoch:  1370     LossContext: 0.00002071
    Epoch:  1380     LossContext: 0.00002070
    Epoch:  1390     LossContext: 0.00002069
    Epoch:  1400     LossContext: 0.00002068
    Epoch:  1410     LossContext: 0.00002068
    Epoch:  1420     LossContext: 0.00002067
    Epoch:  1430     LossContext: 0.00002066
    Epoch:  1440     LossContext: 0.00002065
    Epoch:  1450     LossContext: 0.00002065
    Epoch:  1460     LossContext: 0.00002064
    Epoch:  1470     LossContext: 0.00002063
    Epoch:  1480     LossContext: 0.00002062
    Epoch:  1490     LossContext: 0.00002062
    Epoch:  1499     LossContext: 0.00002061

Gradient descent adaptation time: 0 hours 1 mins 31 secs

Adapting to environment 3 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.02140427
    Epoch:     1     LossContext: 0.01134402
    Epoch:     2     LossContext: 0.00552557
    Epoch:     3     LossContext: 0.00240839
    Epoch:    10     LossContext: 0.00091260
    Epoch:    20     LossContext: 0.00158080
    Epoch:    30     LossContext: 0.00016120
    Epoch:    40     LossContext: 0.00018937
    Epoch:    50     LossContext: 0.00004099
    Epoch:    60     LossContext: 0.00005356
    Epoch:    70     LossContext: 0.00002857
    Epoch:    80     LossContext: 0.00003137
    Epoch:    90     LossContext: 0.00002747
    Epoch:   100     LossContext: 0.00002729
    Epoch:   110     LossContext: 0.00002685
    Epoch:   120     LossContext: 0.00002644
    Epoch:   130     LossContext: 0.00002619
    Epoch:   140     LossContext: 0.00002594
    Epoch:   150     LossContext: 0.00002569
    Epoch:   160     LossContext: 0.00002545
    Epoch:   170     LossContext: 0.00002522
    Epoch:   180     LossContext: 0.00002499
    Epoch:   190     LossContext: 0.00002478
    Epoch:   200     LossContext: 0.00002457
    Epoch:   210     LossContext: 0.00002437
    Epoch:   220     LossContext: 0.00002417
    Epoch:   230     LossContext: 0.00002398
    Epoch:   240     LossContext: 0.00002379
    Epoch:   250     LossContext: 0.00002361
    Epoch:   260     LossContext: 0.00002344
    Epoch:   270     LossContext: 0.00002328
    Epoch:   280     LossContext: 0.00002311
    Epoch:   290     LossContext: 0.00002295
    Epoch:   300     LossContext: 0.00002279
    Epoch:   310     LossContext: 0.00002264
    Epoch:   320     LossContext: 0.00002250
    Epoch:   330     LossContext: 0.00002236
    Epoch:   340     LossContext: 0.00002222
    Epoch:   350     LossContext: 0.00002208
    Epoch:   360     LossContext: 0.00002195
    Epoch:   370     LossContext: 0.00002181
    Epoch:   380     LossContext: 0.00002169
    Epoch:   390     LossContext: 0.00002158
    Epoch:   400     LossContext: 0.00002147
    Epoch:   410     LossContext: 0.00002137
    Epoch:   420     LossContext: 0.00002126
    Epoch:   430     LossContext: 0.00002117
    Epoch:   440     LossContext: 0.00002108
    Epoch:   450     LossContext: 0.00002099
    Epoch:   460     LossContext: 0.00002090
    Epoch:   470     LossContext: 0.00002081
    Epoch:   480     LossContext: 0.00002073
    Epoch:   490     LossContext: 0.00002065
    Epoch:   500     LossContext: 0.00002057
    Epoch:   510     LossContext: 0.00002049
    Epoch:   520     LossContext: 0.00002042
    Epoch:   530     LossContext: 0.00002035
    Epoch:   540     LossContext: 0.00002028
    Epoch:   550     LossContext: 0.00002021
    Epoch:   560     LossContext: 0.00002013
    Epoch:   570     LossContext: 0.00002007
    Epoch:   580     LossContext: 0.00002000
    Epoch:   590     LossContext: 0.00001993
    Epoch:   600     LossContext: 0.00001987
    Epoch:   610     LossContext: 0.00001981
    Epoch:   620     LossContext: 0.00001976
    Epoch:   630     LossContext: 0.00001970
    Epoch:   640     LossContext: 0.00001964
    Epoch:   650     LossContext: 0.00001959
    Epoch:   660     LossContext: 0.00001954
    Epoch:   670     LossContext: 0.00001948
    Epoch:   680     LossContext: 0.00001944
    Epoch:   690     LossContext: 0.00001939
    Epoch:   700     LossContext: 0.00001935
    Epoch:   710     LossContext: 0.00001931
    Epoch:   720     LossContext: 0.00001927
    Epoch:   730     LossContext: 0.00001923
    Epoch:   740     LossContext: 0.00001919
    Epoch:   750     LossContext: 0.00001916
    Epoch:   760     LossContext: 0.00001915
    Epoch:   770     LossContext: 0.00001910
    Epoch:   780     LossContext: 0.00001911
    Epoch:   790     LossContext: 0.00001903
    Epoch:   800     LossContext: 0.00001916
    Epoch:   810     LossContext: 0.00001899
    Epoch:   820     LossContext: 0.00001929
    Epoch:   830     LossContext: 0.00001903
    Epoch:   840     LossContext: 0.00001889
    Epoch:   850     LossContext: 0.00001915
    Epoch:   860     LossContext: 0.00001883
    Epoch:   870     LossContext: 0.00001915
    Epoch:   880     LossContext: 0.00001878
    Epoch:   890     LossContext: 0.00001922
    Epoch:   900     LossContext: 0.00001889
    Epoch:   910     LossContext: 0.00001872
    Epoch:   920     LossContext: 0.00001897
    Epoch:   930     LossContext: 0.00001868
    Epoch:   940     LossContext: 0.00001905
    Epoch:   950     LossContext: 0.00001872
    Epoch:   960     LossContext: 0.00001880
    Epoch:   970     LossContext: 0.00001893
    Epoch:   980     LossContext: 0.00001858
    Epoch:   990     LossContext: 0.00001905
    Epoch:  1000     LossContext: 0.00001876
    Epoch:  1010     LossContext: 0.00001861
    Epoch:  1020     LossContext: 0.00001854
    Epoch:  1030     LossContext: 0.00001851
    Epoch:  1040     LossContext: 0.00001850
    Epoch:  1050     LossContext: 0.00001848
    Epoch:  1060     LossContext: 0.00001847
    Epoch:  1070     LossContext: 0.00001846
    Epoch:  1080     LossContext: 0.00001845
    Epoch:  1090     LossContext: 0.00001845
    Epoch:  1100     LossContext: 0.00001844
    Epoch:  1110     LossContext: 0.00001843
    Epoch:  1120     LossContext: 0.00001842
    Epoch:  1130     LossContext: 0.00001841
    Epoch:  1140     LossContext: 0.00001840
    Epoch:  1150     LossContext: 0.00001839
    Epoch:  1160     LossContext: 0.00001838
    Epoch:  1170     LossContext: 0.00001837
    Epoch:  1180     LossContext: 0.00001836
    Epoch:  1190     LossContext: 0.00001835
    Epoch:  1200     LossContext: 0.00001834
    Epoch:  1210     LossContext: 0.00001833
    Epoch:  1220     LossContext: 0.00001832
    Epoch:  1230     LossContext: 0.00001831
    Epoch:  1240     LossContext: 0.00001830
    Epoch:  1250     LossContext: 0.00001829
    Epoch:  1260     LossContext: 0.00001828
    Epoch:  1270     LossContext: 0.00001827
    Epoch:  1280     LossContext: 0.00001826
    Epoch:  1290     LossContext: 0.00001825
    Epoch:  1300     LossContext: 0.00001824
    Epoch:  1310     LossContext: 0.00001823
    Epoch:  1320     LossContext: 0.00001822
    Epoch:  1330     LossContext: 0.00001821
    Epoch:  1340     LossContext: 0.00001820
    Epoch:  1350     LossContext: 0.00001819
    Epoch:  1360     LossContext: 0.00001818
    Epoch:  1370     LossContext: 0.00001817
    Epoch:  1380     LossContext: 0.00001816
    Epoch:  1390     LossContext: 0.00001815
    Epoch:  1400     LossContext: 0.00001814
    Epoch:  1410     LossContext: 0.00001813
    Epoch:  1420     LossContext: 0.00001812
    Epoch:  1430     LossContext: 0.00001811
    Epoch:  1440     LossContext: 0.00001810
    Epoch:  1450     LossContext: 0.00001809
    Epoch:  1460     LossContext: 0.00001808
    Epoch:  1470     LossContext: 0.00001806
    Epoch:  1480     LossContext: 0.00001805
    Epoch:  1490     LossContext: 0.00001804
    Epoch:  1499     LossContext: 0.00001803

Gradient descent adaptation time: 0 hours 1 mins 31 secs
WARNING: No key provided for the context initialization. Initializing at 0.

Saving adaptation parameters into ./adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 9
    Number of adaptation environments: 4
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (OOD): 2.5462054e-05

==  Begining out-of-distribution visualisation ... ==
    Environment id: 0
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./adapt/results_ood.png
