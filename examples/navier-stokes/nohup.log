
############# Neural Context Flow #############

Jax version: 0.4.28
Available devices: [cuda(id=0)]
Run folder created successfuly: ./runs/04082024-183922/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 183922
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 183922
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 310955 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training with proximal alternating minimization ... ===
    Number of examples in a batch: 16
    Maximum number of steps per inner minimization: 25
    Maximum number of outer minimizations: 250
    Maximum total number of training steps: 6250

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (5, 16, 10, 1024) (10,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (5, 16, 10, 1024) (10,)
    Outer Step:     0      LossTrajs: 0.96028650     ContextsNorm: 0.00000000     ValIndCrit: 0.93044251
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 4.74e-06
        -DiffCxt:  inf
    Outer Step:     1      LossTrajs: 0.85129189     ContextsNorm: 0.00017596     ValIndCrit: 0.84103405
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.89e-05
        -DiffCxt:  8.91e-03
    Outer Step:     2      LossTrajs: 0.79610437     ContextsNorm: 0.00027659     ValIndCrit: 0.78203261
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 6.18e-05
        -DiffCxt:  6.20e-03
    Outer Step:     3      LossTrajs: 0.54244834     ContextsNorm: 0.00136523     ValIndCrit: 0.52299911
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.22e-04
        -DiffCxt:  1.73e-03
    Outer Step:     5      LossTrajs: 0.37811241     ContextsNorm: 0.01871323     ValIndCrit: 0.37986386
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 7.36e-05
        -DiffCxt:  3.06e-04
    Outer Step:    10      LossTrajs: 0.22722344     ContextsNorm: 0.02522094     ValIndCrit: 0.21840473
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 6.06e-05
        -DiffCxt:  7.45e-06
    Outer Step:    15      LossTrajs: 0.04797491     ContextsNorm: 0.02290101     ValIndCrit: 0.05308999
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 6.57e-06
        -DiffCxt:  8.30e-07
    Outer Step:    20      LossTrajs: 0.02024602     ContextsNorm: 0.02415034     ValIndCrit: 0.02476566
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 7.28e-06
        -DiffCxt:  2.93e-07
    Outer Step:    25      LossTrajs: 0.01039870     ContextsNorm: 0.02458725     ValIndCrit: 0.01462501
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.42e-06
        -DiffCxt:  6.72e-08
    Outer Step:    30      LossTrajs: 0.00715692     ContextsNorm: 0.02466562     ValIndCrit: 0.01071104
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.41e-06
        -DiffCxt:  4.02e-08
    Outer Step:    35      LossTrajs: 0.00527152     ContextsNorm: 0.02457841     ValIndCrit: 0.00852088
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 7.92e-07
        -DiffCxt:  1.80e-07
    Outer Step:    40      LossTrajs: 0.00418672     ContextsNorm: 0.02441405     ValIndCrit: 0.00736122
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 4.35e-07
        -DiffCxt:  1.35e-07
    Outer Step:    45      LossTrajs: 0.00352555     ContextsNorm: 0.02449419     ValIndCrit: 0.00673350
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.60e-07
        -DiffCxt:  5.53e-07
    Outer Step:    50      LossTrajs: 0.00307315     ContextsNorm: 0.02446374     ValIndCrit: 0.00620827
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.94e-07
        -DiffCxt:  4.60e-07
    Outer Step:    55      LossTrajs: 0.00272678     ContextsNorm: 0.02434095     ValIndCrit: 0.00585280
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.39e-07
        -DiffCxt:  5.90e-08
    Outer Step:    60      LossTrajs: 0.00246077     ContextsNorm: 0.02422204     ValIndCrit: 0.00554097
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.06e-07
        -DiffCxt:  2.34e-07
    Outer Step:    65      LossTrajs: 0.00225131     ContextsNorm: 0.02410095     ValIndCrit: 0.00524948
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 8.39e-08
        -DiffCxt:  2.04e-07
    Outer Step:    70      LossTrajs: 0.00208375     ContextsNorm: 0.02434334     ValIndCrit: 0.00501932
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 6.97e-08
        -DiffCxt:  3.57e-08
    Outer Step:    75      LossTrajs: 0.00194128     ContextsNorm: 0.02403141     ValIndCrit: 0.00483642
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 5.65e-08
        -DiffCxt:  1.12e-07
    Outer Step:    80      LossTrajs: 0.00182313     ContextsNorm: 0.02408721     ValIndCrit: 0.00466537
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 4.67e-08
        -DiffCxt:  4.65e-08
    Outer Step:    85      LossTrajs: 0.00174961     ContextsNorm: 0.02356255     ValIndCrit: 0.00457131
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 7.35e-10
        -DiffCxt:  1.58e-09
    Outer Step:    90      LossTrajs: 0.00173835     ContextsNorm: 0.02345801     ValIndCrit: 0.00455714
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 7.73e-10
        -DiffCxt:  9.99e-10
    Outer Step:    95      LossTrajs: 0.00172718     ContextsNorm: 0.02338716     ValIndCrit: 0.00454034
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 8.05e-10
        -DiffCxt:  1.02e-09
    Outer Step:   100      LossTrajs: 0.00171533     ContextsNorm: 0.02331758     ValIndCrit: 0.00452565
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 8.38e-10
        -DiffCxt:  9.01e-10
    Outer Step:   105      LossTrajs: 0.00170297     ContextsNorm: 0.02325921     ValIndCrit: 0.00450870
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 8.70e-10
        -DiffCxt:  1.05e-09
    Outer Step:   110      LossTrajs: 0.00169028     ContextsNorm: 0.02319947     ValIndCrit: 0.00449135
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 9.07e-10
        -DiffCxt:  1.20e-09
    Outer Step:   115      LossTrajs: 0.00167711     ContextsNorm: 0.02310935     ValIndCrit: 0.00447375
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 9.42e-10
        -DiffCxt:  1.06e-09
    Outer Step:   120      LossTrajs: 0.00166345     ContextsNorm: 0.02304235     ValIndCrit: 0.00445684
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 9.83e-10
        -DiffCxt:  1.42e-09
    Outer Step:   125      LossTrajs: 0.00164949     ContextsNorm: 0.02298686     ValIndCrit: 0.00443645
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.02e-09
        -DiffCxt:  1.44e-09
    Outer Step:   130      LossTrajs: 0.00163496     ContextsNorm: 0.02292796     ValIndCrit: 0.00441432
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.06e-09
        -DiffCxt:  1.18e-09
    Outer Step:   135      LossTrajs: 0.00162042     ContextsNorm: 0.02285341     ValIndCrit: 0.00439493
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.10e-09
        -DiffCxt:  1.42e-09
    Outer Step:   140      LossTrajs: 0.00160506     ContextsNorm: 0.02279899     ValIndCrit: 0.00437115
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.14e-09
        -DiffCxt:  1.37e-09
    Outer Step:   145      LossTrajs: 0.00158950     ContextsNorm: 0.02273486     ValIndCrit: 0.00435258
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.17e-09
        -DiffCxt:  1.36e-09
    Outer Step:   150      LossTrajs: 0.00157365     ContextsNorm: 0.02267828     ValIndCrit: 0.00432823
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.21e-09
        -DiffCxt:  2.10e-09
    Outer Step:   155      LossTrajs: 0.00155742     ContextsNorm: 0.02261310     ValIndCrit: 0.00430470
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.25e-09
        -DiffCxt:  1.62e-09
    Outer Step:   160      LossTrajs: 0.00154079     ContextsNorm: 0.02255618     ValIndCrit: 0.00427880
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.29e-09
        -DiffCxt:  1.63e-09
    Outer Step:   165      LossTrajs: 0.00152378     ContextsNorm: 0.02250655     ValIndCrit: 0.00425826
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.33e-09
        -DiffCxt:  1.63e-09
    Outer Step:   170      LossTrajs: 0.00151711     ContextsNorm: 0.02246795     ValIndCrit: 0.00424667
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.48e-11
        -DiffCxt:  1.42e-10
    Outer Step:   175      LossTrajs: 0.00151537     ContextsNorm: 0.02244981     ValIndCrit: 0.00424283
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.55e-11
        -DiffCxt:  1.45e-10
    Outer Step:   180      LossTrajs: 0.00151336     ContextsNorm: 0.02242756     ValIndCrit: 0.00424191
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.63e-11
        -DiffCxt:  1.59e-10
    Outer Step:   185      LossTrajs: 0.00151123     ContextsNorm: 0.02241039     ValIndCrit: 0.00423736
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.73e-11
        -DiffCxt:  1.97e-10
    Outer Step:   190      LossTrajs: 0.00150921     ContextsNorm: 0.02239447     ValIndCrit: 0.00423401
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.82e-11
        -DiffCxt:  1.71e-10
    Outer Step:   195      LossTrajs: 0.00150696     ContextsNorm: 0.02236629     ValIndCrit: 0.00423221
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.92e-11
        -DiffCxt:  1.91e-10
    Outer Step:   200      LossTrajs: 0.00150480     ContextsNorm: 0.02235428     ValIndCrit: 0.00422734
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.01e-11
        -DiffCxt:  1.94e-10
    Outer Step:   205      LossTrajs: 0.00150230     ContextsNorm: 0.02233274     ValIndCrit: 0.00422270
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.11e-11
        -DiffCxt:  1.95e-10
    Outer Step:   210      LossTrajs: 0.00149994     ContextsNorm: 0.02231130     ValIndCrit: 0.00422150
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.22e-11
        -DiffCxt:  2.01e-10
    Outer Step:   215      LossTrajs: 0.00149733     ContextsNorm: 0.02228860     ValIndCrit: 0.00421538
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.35e-11
        -DiffCxt:  2.32e-10
    Outer Step:   220      LossTrajs: 0.00149478     ContextsNorm: 0.02227398     ValIndCrit: 0.00421339
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.46e-11
        -DiffCxt:  2.15e-10
    Outer Step:   225      LossTrajs: 0.00149204     ContextsNorm: 0.02224386     ValIndCrit: 0.00420788
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.58e-11
        -DiffCxt:  2.47e-10
    Outer Step:   230      LossTrajs: 0.00148924     ContextsNorm: 0.02222916     ValIndCrit: 0.00420490
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.70e-11
        -DiffCxt:  2.58e-10
    Outer Step:   235      LossTrajs: 0.00148633     ContextsNorm: 0.02219646     ValIndCrit: 0.00420024
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 2.82e-11
        -DiffCxt:  4.25e-10
    Outer Step:   240      LossTrajs: 0.00148307     ContextsNorm: 0.02217836     ValIndCrit: 0.00419561
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 3.00e-11
        -DiffCxt:  2.96e-10
    Outer Step:   245      LossTrajs: 0.00147984     ContextsNorm: 0.02215501     ValIndCrit: 0.00418887
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 3.10e-11
        -DiffCxt:  2.69e-10
    Outer Step:   249      LossTrajs: 0.00147748     ContextsNorm: 0.02213758     ValIndCrit: 0.00418410
        Saving best model so far ...
        -NbInnerStepsNode:   25
        -NbInnerStepsCxt:   25
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 3.21e-11
        -DiffCxt:  2.71e-10

Total gradient descent training time: 0 hours 19 mins 0 secs
Environment weights at the end of the training: [0.2 0.2 0.2 0.2 0.2]
WARNING: You did not provide a dataloader id. A new one has been generated: 185823
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 5
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Test Score (In-Domain): 0.004184095


Per-environment IND scores: [0.00622867 0.00453323 0.0036319  0.00326162 0.00326505]
==  Begining in-domain visualisation ... ==
    Environment id: 2
    Trajectory id: 23
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/04082024-183922/results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 1500
    Total number of training steps: 1500

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 10, 1024) (10,)
    Epoch:     0     LossContext: 0.01627306
    Epoch:     1     LossContext: 0.01592336
    Epoch:     2     LossContext: 0.01555996
    Epoch:     3     LossContext: 0.01518336
    Epoch:    25     LossContext: 0.00592628
    Epoch:    50     LossContext: 0.00197292
    Epoch:    75     LossContext: 0.00187422
    Epoch:   100     LossContext: 0.00186008
    Epoch:   125     LossContext: 0.00185667
    Epoch:   150     LossContext: 0.00185369
    Epoch:   175     LossContext: 0.00185093
    Epoch:   200     LossContext: 0.00184812
    Epoch:   225     LossContext: 0.00184533
    Epoch:   250     LossContext: 0.00184256
    Epoch:   275     LossContext: 0.00183977
    Epoch:   300     LossContext: 0.00183697
    Epoch:   325     LossContext: 0.00183419
    Epoch:   350     LossContext: 0.00183145
    Epoch:   375     LossContext: 0.00182875
    Epoch:   400     LossContext: 0.00182610
    Epoch:   425     LossContext: 0.00182348
    Epoch:   450     LossContext: 0.00182093
    Epoch:   475     LossContext: 0.00181849
    Epoch:   500     LossContext: 0.00181607
    Epoch:   525     LossContext: 0.00181366
    Epoch:   550     LossContext: 0.00181127
    Epoch:   575     LossContext: 0.00180889
    Epoch:   600     LossContext: 0.00180654
    Epoch:   625     LossContext: 0.00180420
    Epoch:   650     LossContext: 0.00180188
    Epoch:   675     LossContext: 0.00179958
    Epoch:   700     LossContext: 0.00179730
    Epoch:   725     LossContext: 0.00179505
    Epoch:   750     LossContext: 0.00179285
    Epoch:   775     LossContext: 0.00179067
    Epoch:   800     LossContext: 0.00178851
    Epoch:   825     LossContext: 0.00178638
    Epoch:   850     LossContext: 0.00178431
    Epoch:   875     LossContext: 0.00178229
    Epoch:   900     LossContext: 0.00178034
    Epoch:   925     LossContext: 0.00177843
    Epoch:   950     LossContext: 0.00177655
    Epoch:   975     LossContext: 0.00177471
    Epoch:  1000     LossContext: 0.00177291
    Epoch:  1025     LossContext: 0.00177118
    Epoch:  1050     LossContext: 0.00176951
    Epoch:  1075     LossContext: 0.00176788
    Epoch:  1100     LossContext: 0.00176630
    Epoch:  1125     LossContext: 0.00176476
    Epoch:  1150     LossContext: 0.00176325
    Epoch:  1175     LossContext: 0.00176178
    Epoch:  1200     LossContext: 0.00176035
    Epoch:  1225     LossContext: 0.00175895
    Epoch:  1250     LossContext: 0.00175761
    Epoch:  1275     LossContext: 0.00175630
    Epoch:  1300     LossContext: 0.00175502
    Epoch:  1325     LossContext: 0.00175379
    Epoch:  1350     LossContext: 0.00175257
    Epoch:  1375     LossContext: 0.00175138
    Epoch:  1400     LossContext: 0.00175022
    Epoch:  1425     LossContext: 0.00174910
    Epoch:  1450     LossContext: 0.00174800
    Epoch:  1475     LossContext: 0.00174691
    Epoch:  1499     LossContext: 0.00174589

Gradient descent adaptation time: 0 hours 0 mins 10 secs

Adapting to environment 1 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.00765823
    Epoch:     1     LossContext: 0.00742658
    Epoch:     2     LossContext: 0.00718753
    Epoch:     3     LossContext: 0.00694172
    Epoch:    25     LossContext: 0.00203320
    Epoch:    50     LossContext: 0.00126444
    Epoch:    75     LossContext: 0.00124550
    Epoch:   100     LossContext: 0.00124120
    Epoch:   125     LossContext: 0.00123888
    Epoch:   150     LossContext: 0.00123687
    Epoch:   175     LossContext: 0.00123503
    Epoch:   200     LossContext: 0.00123329
    Epoch:   225     LossContext: 0.00123166
    Epoch:   250     LossContext: 0.00123013
    Epoch:   275     LossContext: 0.00122864
    Epoch:   300     LossContext: 0.00122717
    Epoch:   325     LossContext: 0.00122578
    Epoch:   350     LossContext: 0.00122445
    Epoch:   375     LossContext: 0.00122315
    Epoch:   400     LossContext: 0.00122187
    Epoch:   425     LossContext: 0.00122060
    Epoch:   450     LossContext: 0.00121935
    Epoch:   475     LossContext: 0.00121811
    Epoch:   500     LossContext: 0.00121692
    Epoch:   525     LossContext: 0.00121573
    Epoch:   550     LossContext: 0.00121457
    Epoch:   575     LossContext: 0.00121345
    Epoch:   600     LossContext: 0.00121238
    Epoch:   625     LossContext: 0.00121136
    Epoch:   650     LossContext: 0.00121038
    Epoch:   675     LossContext: 0.00120941
    Epoch:   700     LossContext: 0.00120845
    Epoch:   725     LossContext: 0.00120752
    Epoch:   750     LossContext: 0.00120662
    Epoch:   775     LossContext: 0.00120573
    Epoch:   800     LossContext: 0.00120486
    Epoch:   825     LossContext: 0.00120400
    Epoch:   850     LossContext: 0.00120319
    Epoch:   875     LossContext: 0.00120243
    Epoch:   900     LossContext: 0.00120168
    Epoch:   925     LossContext: 0.00120094
    Epoch:   950     LossContext: 0.00120021
    Epoch:   975     LossContext: 0.00119949
    Epoch:  1000     LossContext: 0.00119878
    Epoch:  1025     LossContext: 0.00119811
    Epoch:  1050     LossContext: 0.00119745
    Epoch:  1075     LossContext: 0.00119679
    Epoch:  1100     LossContext: 0.00119615
    Epoch:  1125     LossContext: 0.00119552
    Epoch:  1150     LossContext: 0.00119490
    Epoch:  1175     LossContext: 0.00119429
    Epoch:  1200     LossContext: 0.00119369
    Epoch:  1225     LossContext: 0.00119312
    Epoch:  1250     LossContext: 0.00119257
    Epoch:  1275     LossContext: 0.00119205
    Epoch:  1300     LossContext: 0.00119153
    Epoch:  1325     LossContext: 0.00119102
    Epoch:  1350     LossContext: 0.00119054
    Epoch:  1375     LossContext: 0.00119006
    Epoch:  1400     LossContext: 0.00118959
    Epoch:  1425     LossContext: 0.00118914
    Epoch:  1450     LossContext: 0.00118869
    Epoch:  1475     LossContext: 0.00118825
    Epoch:  1499     LossContext: 0.00118782

Gradient descent adaptation time: 0 hours 0 mins 8 secs

Adapting to environment 2 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.00345094
    Epoch:     1     LossContext: 0.00332525
    Epoch:     2     LossContext: 0.00319731
    Epoch:     3     LossContext: 0.00306781
    Epoch:    25     LossContext: 0.00124987
    Epoch:    50     LossContext: 0.00105232
    Epoch:    75     LossContext: 0.00105123
    Epoch:   100     LossContext: 0.00104795
    Epoch:   125     LossContext: 0.00104593
    Epoch:   150     LossContext: 0.00104400
    Epoch:   175     LossContext: 0.00104216
    Epoch:   200     LossContext: 0.00104030
    Epoch:   225     LossContext: 0.00103844
    Epoch:   250     LossContext: 0.00103656
    Epoch:   275     LossContext: 0.00103471
    Epoch:   300     LossContext: 0.00103294
    Epoch:   325     LossContext: 0.00103129
    Epoch:   350     LossContext: 0.00102975
    Epoch:   375     LossContext: 0.00102830
    Epoch:   400     LossContext: 0.00102690
    Epoch:   425     LossContext: 0.00102555
    Epoch:   450     LossContext: 0.00102424
    Epoch:   475     LossContext: 0.00102298
    Epoch:   500     LossContext: 0.00102175
    Epoch:   525     LossContext: 0.00102056
    Epoch:   550     LossContext: 0.00101944
    Epoch:   575     LossContext: 0.00101838
    Epoch:   600     LossContext: 0.00101736
    Epoch:   625     LossContext: 0.00101638
    Epoch:   650     LossContext: 0.00101547
    Epoch:   675     LossContext: 0.00101461
    Epoch:   700     LossContext: 0.00101376
    Epoch:   725     LossContext: 0.00101295
    Epoch:   750     LossContext: 0.00101216
    Epoch:   775     LossContext: 0.00101140
    Epoch:   800     LossContext: 0.00101065
    Epoch:   825     LossContext: 0.00100992
    Epoch:   850     LossContext: 0.00100923
    Epoch:   875     LossContext: 0.00100854
    Epoch:   900     LossContext: 0.00100789
    Epoch:   925     LossContext: 0.00100724
    Epoch:   950     LossContext: 0.00100662
    Epoch:   975     LossContext: 0.00100602
    Epoch:  1000     LossContext: 0.00100544
    Epoch:  1025     LossContext: 0.00100489
    Epoch:  1050     LossContext: 0.00100435
    Epoch:  1075     LossContext: 0.00100384
    Epoch:  1100     LossContext: 0.00100334
    Epoch:  1125     LossContext: 0.00100284
    Epoch:  1150     LossContext: 0.00100237
    Epoch:  1175     LossContext: 0.00100190
    Epoch:  1200     LossContext: 0.00100145
    Epoch:  1225     LossContext: 0.00100101
    Epoch:  1250     LossContext: 0.00100058
    Epoch:  1275     LossContext: 0.00100016
    Epoch:  1300     LossContext: 0.00099976
    Epoch:  1325     LossContext: 0.00099937
    Epoch:  1350     LossContext: 0.00099900
    Epoch:  1375     LossContext: 0.00099863
    Epoch:  1400     LossContext: 0.00099827
    Epoch:  1425     LossContext: 0.00099792
    Epoch:  1450     LossContext: 0.00099757
    Epoch:  1475     LossContext: 0.00099724
    Epoch:  1499     LossContext: 0.00099692

Gradient descent adaptation time: 0 hours 0 mins 8 secs

Adapting to environment 3 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.00258915
    Epoch:     1     LossContext: 0.00253932
    Epoch:     2     LossContext: 0.00248820
    Epoch:     3     LossContext: 0.00243590
    Epoch:    25     LossContext: 0.00138909
    Epoch:    50     LossContext: 0.00115315
    Epoch:    75     LossContext: 0.00114164
    Epoch:   100     LossContext: 0.00113035
    Epoch:   125     LossContext: 0.00112185
    Epoch:   150     LossContext: 0.00111460
    Epoch:   175     LossContext: 0.00110816
    Epoch:   200     LossContext: 0.00110229
    Epoch:   225     LossContext: 0.00109689
    Epoch:   250     LossContext: 0.00109196
    Epoch:   275     LossContext: 0.00108750
    Epoch:   300     LossContext: 0.00108334
    Epoch:   325     LossContext: 0.00107952
    Epoch:   350     LossContext: 0.00107602
    Epoch:   375     LossContext: 0.00107274
    Epoch:   400     LossContext: 0.00106974
    Epoch:   425     LossContext: 0.00106701
    Epoch:   450     LossContext: 0.00106450
    Epoch:   475     LossContext: 0.00106213
    Epoch:   500     LossContext: 0.00105990
    Epoch:   525     LossContext: 0.00105778
    Epoch:   550     LossContext: 0.00105581
    Epoch:   575     LossContext: 0.00105397
    Epoch:   600     LossContext: 0.00105223
    Epoch:   625     LossContext: 0.00105060
    Epoch:   650     LossContext: 0.00104908
    Epoch:   675     LossContext: 0.00104766
    Epoch:   700     LossContext: 0.00104630
    Epoch:   725     LossContext: 0.00104499
    Epoch:   750     LossContext: 0.00104377
    Epoch:   775     LossContext: 0.00104262
    Epoch:   800     LossContext: 0.00104154
    Epoch:   825     LossContext: 0.00104053
    Epoch:   850     LossContext: 0.00103957
    Epoch:   875     LossContext: 0.00103865
    Epoch:   900     LossContext: 0.00103777
    Epoch:   925     LossContext: 0.00103693
    Epoch:   950     LossContext: 0.00103612
    Epoch:   975     LossContext: 0.00103534
    Epoch:  1000     LossContext: 0.00103460
    Epoch:  1025     LossContext: 0.00103387
    Epoch:  1050     LossContext: 0.00103319
    Epoch:  1075     LossContext: 0.00103255
    Epoch:  1100     LossContext: 0.00103193
    Epoch:  1125     LossContext: 0.00103133
    Epoch:  1150     LossContext: 0.00103077
    Epoch:  1175     LossContext: 0.00103024
    Epoch:  1200     LossContext: 0.00102973
    Epoch:  1225     LossContext: 0.00102927
    Epoch:  1250     LossContext: 0.00102883
    Epoch:  1275     LossContext: 0.00102842
    Epoch:  1300     LossContext: 0.00102802
    Epoch:  1325     LossContext: 0.00102764
    Epoch:  1350     LossContext: 0.00102728
    Epoch:  1375     LossContext: 0.00102693
    Epoch:  1400     LossContext: 0.00102661
    Epoch:  1425     LossContext: 0.00102630
    Epoch:  1450     LossContext: 0.00102600
    Epoch:  1475     LossContext: 0.00102572
    Epoch:  1499     LossContext: 0.00102546

Gradient descent adaptation time: 0 hours 0 mins 8 secs
WARNING: No key provided for the context initialization. Initializing at 0.

Saving adaptation parameters into ./runs/04082024-183922/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 5
    Number of adaptation environments: 4
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Test Score (OOD): 0.004052885

==  Begining out-of-distribution visualisation ... ==
    Environment id: 3
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/04082024-183922/adapt/results_ood.png

Per-environment OOD scores: [0.00531665 0.00402652 0.00342915 0.00343921]
