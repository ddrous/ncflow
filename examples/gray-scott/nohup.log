
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/06042024-101644/
 Seed: 270


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/06042024-101644/
 Seed: 540


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/06042024-101644/adapt/
 Seed: 810


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt_test
 Savepath: ./runs/06042024-101644/adapt/
 Seed: 810


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Run folder created successfuly: ./runs/06042024-101644/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 101741
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 101742
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 610942 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training with proximal alternating minimization ... ===
    Number of examples in a batch: 1
    Maximum number of steps per inner minimization: 20
    Maximum number of outer minimizations: 10
    Maximum total number of training steps: 200

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (4, 1, 10, 2048) (10,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (4, 1, 10, 2048) (10,)
    Outer Step:     0      LossTrajs: 0.09839233     ContextsNorm: 0.00000000     ValIndCrit: 0.07819767
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.12e-04
        -DiffCxt:  inf
    Outer Step:     1      LossTrajs: 0.05260533     ContextsNorm: 0.00086097     ValIndCrit: 0.04939863
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.07e-06
        -DiffCxt:  1.05e-03
    Outer Step:     2      LossTrajs: 0.04863242     ContextsNorm: 0.00072653     ValIndCrit: 0.04529358
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.46e-06
        -DiffCxt:  9.78e-04
    Outer Step:     3      LossTrajs: 0.03999564     ContextsNorm: 0.00089296     ValIndCrit: 0.03838757
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 5.95e-06
        -DiffCxt:  1.93e-03
    Outer Step:     4      LossTrajs: 0.03491956     ContextsNorm: 0.00351889     ValIndCrit: 0.03735553
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.26e-06
        -DiffCxt:  6.61e-04
    Outer Step:     6      LossTrajs: 0.01652552     ContextsNorm: 0.01466636     ValIndCrit: 0.04573702
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 6.25e-05
        -DiffCxt:  2.85e-04
    Outer Step:     8      LossTrajs: 0.01276933     ContextsNorm: 0.01637162     ValIndCrit: 0.04305610
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 3.92e-06
        -DiffCxt:  3.72e-06
    Outer Step:     9      LossTrajs: 0.01193304     ContextsNorm: 0.01635797     ValIndCrit: 0.04167711
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  1.00e-08
        -DiffNode: 1.40e-06
        -DiffCxt:  8.08e-07

Total gradient descent training time: 0 hours 3 mins 15 secs
Environment weights at the end of the training: [0.25 0.25 0.25 0.25]
WARNING: You did not provide a dataloader id. A new one has been generated: 102100
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 4
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Test Score (In-Domain): 0.037355527

==  Begining in-domain visualisation ... ==
    Environment id: 2
    Trajectory id: 20
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/06042024-101644/results_in_domain.png
==  Begining in-domain 2D visualisation ... ==
    Environment id: 1
    Trajectory id: 10
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/06042024-101644/results_2D_ind.png
==  Begining in-domain 2D visualisation ... ==
    Environment id: 1
    Trajectory id: 0
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/06042024-101644/results_2D_ind_train.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 15
    Total number of training steps: 15

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 10, 2048) (10,)
    Epoch:     0     LossContext: 0.02763201
    Epoch:     1     LossContext: 0.02761233
    Epoch:     2     LossContext: 0.02759223
    Epoch:     3     LossContext: 0.02757092
    Epoch:     4     LossContext: 0.02754875
    Epoch:     6     LossContext: 0.02750121
    Epoch:     8     LossContext: 0.02744999
    Epoch:    10     LossContext: 0.02739478
    Epoch:    12     LossContext: 0.02733622
    Epoch:    14     LossContext: 0.02727382

Gradient descent adaptation time: 0 hours 0 mins 19 secs

Adapting to environment 1 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.02827930
    Epoch:     1     LossContext: 0.02825698
    Epoch:     2     LossContext: 0.02823359
    Epoch:     3     LossContext: 0.02820915
    Epoch:     4     LossContext: 0.02818354
    Epoch:     6     LossContext: 0.02812902
    Epoch:     8     LossContext: 0.02807010
    Epoch:    10     LossContext: 0.02800672
    Epoch:    12     LossContext: 0.02793904
    Epoch:    14     LossContext: 0.02786727

Gradient descent adaptation time: 0 hours 0 mins 2 secs

Adapting to environment 2 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.02882041
    Epoch:     1     LossContext: 0.02879977
    Epoch:     2     LossContext: 0.02877885
    Epoch:     3     LossContext: 0.02875636
    Epoch:     4     LossContext: 0.02873286
    Epoch:     6     LossContext: 0.02868325
    Epoch:     8     LossContext: 0.02862927
    Epoch:    10     LossContext: 0.02857168
    Epoch:    12     LossContext: 0.02850987
    Epoch:    14     LossContext: 0.02844419

Gradient descent adaptation time: 0 hours 0 mins 2 secs

Adapting to environment 3 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.02783238
    Epoch:     1     LossContext: 0.02780968
    Epoch:     2     LossContext: 0.02778593
    Epoch:     3     LossContext: 0.02776076
    Epoch:     4     LossContext: 0.02773496
    Epoch:     6     LossContext: 0.02767954
    Epoch:     8     LossContext: 0.02761945
    Epoch:    10     LossContext: 0.02755501
    Epoch:    12     LossContext: 0.02748613
    Epoch:    14     LossContext: 0.02741313

Gradient descent adaptation time: 0 hours 0 mins 2 secs
WARNING: No key provided for the context initialization. Initializing at 0.

Saving adaptation parameters into ./runs/06042024-101644/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 4
    Number of adaptation environments: 4
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Test Score (OOD): 0.034807235

Couldn't get a file descriptor referring to the console
==  Begining out-of-distribution visualisation ... ==
    Environment id: 3
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/06042024-101644/adapt/results_ood.png
