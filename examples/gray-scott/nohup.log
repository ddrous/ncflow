
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/30032024-124824/
 Seed: 2026


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/30032024-124824/
 Seed: 4052


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/30032024-124824/adapt/
 Seed: 6078


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt_test
 Savepath: ./runs/30032024-124824/adapt/
 Seed: 6078


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Run folder created successfuly: ./runs/30032024-124824/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 125144
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 125145
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 531246 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training with proximal alternating minimization ... ===
    Number of examples in a batch: 1
    Maximum number of steps per inner minimization: 20
    Maximum number of outer minimizations: 100
    Maximum total number of training steps: 2000

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (4, 1, 10, 2048) (10,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (4, 1, 10, 2048) (10,)
    Outer Step:     0      LossTrajs: 0.04226905     ContextsNorm: 0.00000000     ValIndCrit: 0.06772978
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 3.27e-06
        -DiffCxt:  inf
    Outer Step:     1      LossTrajs: 0.03384146     ContextsNorm: 0.00001641     ValIndCrit: 0.03470217
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 1.80e-06
        -DiffCxt:  1.62e-03
    Outer Step:     2      LossTrajs: 0.03327401     ContextsNorm: 0.00006984     ValIndCrit: 0.03394751
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 5.77e-08
        -DiffCxt:  1.97e-05
    Outer Step:     3      LossTrajs: 0.03293718     ContextsNorm: 0.00009944     ValIndCrit: 0.03382377
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 1.87e-07
        -DiffCxt:  1.45e-04
    Outer Step:    10      LossTrajs: 0.03260107     ContextsNorm: 0.00019621     ValIndCrit: 0.03365342
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 3.23e-09
        -DiffCxt:  5.26e-06
    Outer Step:    20      LossTrajs: 0.03219702     ContextsNorm: 0.00046783     ValIndCrit: 0.03333115
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 4.82e-09
        -DiffCxt:  3.89e-06
    Outer Step:    30      LossTrajs: 0.03169776     ContextsNorm: 0.00097130     ValIndCrit: 0.03295408
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 6.73e-09
        -DiffCxt:  2.44e-06
    Outer Step:    40      LossTrajs: 0.03114530     ContextsNorm: 0.00174431     ValIndCrit: 0.03256226
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 9.15e-09
        -DiffCxt:  1.54e-06
    Outer Step:    50      LossTrajs: 0.02950353     ContextsNorm: 0.00288154     ValIndCrit: 0.03151193
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 2.32e-08
        -DiffCxt:  1.33e-06
    Outer Step:    60      LossTrajs: 0.02787814     ContextsNorm: 0.00405811     ValIndCrit: 0.03091129
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 1.21e-08
        -DiffCxt:  3.92e-07
    Outer Step:    70      LossTrajs: 0.02736474     ContextsNorm: 0.00456406     ValIndCrit: 0.03100344
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 1.19e-08
        -DiffCxt:  2.30e-07
    Outer Step:    80      LossTrajs: 0.02701075     ContextsNorm: 0.00488895     ValIndCrit: 0.03114833
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 1.33e-08
        -DiffCxt:  1.29e-07
    Outer Step:    90      LossTrajs: 0.02666163     ContextsNorm: 0.00517069     ValIndCrit: 0.03127935
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   19
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 1.60e-08
        -DiffCxt:  9.81e-08
    Outer Step:    99      LossTrajs: 0.02629442     ContextsNorm: 0.00526451     ValIndCrit: 0.03142451
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   16
        -InnerToleranceNode: 1.00e-08
        -InnerToleranceCtx:  1.00e-07
        -DiffNode: 1.90e-08
        -DiffCxt:  9.59e-08

Total gradient descent training time: 4 hours 1 mins 35 secs
Environment weights at the end of the training: [0.25 0.25 0.25 0.25]
WARNING: You did not provide a dataloader id. A new one has been generated: 165327
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 4
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Test Score (In-Domain): 0.031424507

==  Begining in-domain visualisation ... ==
    Environment id: 2
    Trajectory id: 20
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/30032024-124824/results_in_domain.png
==  Begining in-domain 2D visualisation ... ==
    Environment id: 2
    Trajectory id: 28
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/30032024-124824/results_2D_ind.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 100
    Total number of training steps: 100

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 10, 2048) (10,)
    Epoch:     0     LossContext: 0.03146636
    Epoch:     1     LossContext: 0.03129388
    Epoch:     2     LossContext: 0.03111343
    Epoch:     3     LossContext: 0.03092510
    Epoch:    10     LossContext: 0.02940773
    Epoch:    20     LossContext: 0.02694093
    Epoch:    30     LossContext: 0.02507883
    Epoch:    40     LossContext: 0.02456930
    Epoch:    50     LossContext: 0.02463095
    Epoch:    60     LossContext: 0.02459660
    Epoch:    70     LossContext: 0.02456054
    Epoch:    80     LossContext: 0.02455855
    Epoch:    90     LossContext: 0.02455390
    Epoch:    99     LossContext: 0.02454872

Gradient descent adaptation time: 0 hours 6 mins 59 secs

Adapting to environment 1 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.02723626
    Epoch:     1     LossContext: 0.02717242
    Epoch:     2     LossContext: 0.02710715
    Epoch:     3     LossContext: 0.02704082
    Epoch:    10     LossContext: 0.02658818
    Epoch:    20     LossContext: 0.02626510
    Epoch:    30     LossContext: 0.02627779
    Epoch:    40     LossContext: 0.02625285
    Epoch:    50     LossContext: 0.02622920
    Epoch:    60     LossContext: 0.02621855
    Epoch:    70     LossContext: 0.02620326
    Epoch:    80     LossContext: 0.02618895
    Epoch:    90     LossContext: 0.02617385
    Epoch:    99     LossContext: 0.02615975

Gradient descent adaptation time: 0 hours 6 mins 20 secs

Adapting to environment 2 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.03484845
    Epoch:     1     LossContext: 0.03464437
    Epoch:     2     LossContext: 0.03443043
    Epoch:     3     LossContext: 0.03420666
    Epoch:    10     LossContext: 0.03237966
    Epoch:    20     LossContext: 0.02924397
    Epoch:    30     LossContext: 0.02647089
    Epoch:    40     LossContext: 0.02530844
    Epoch:    50     LossContext: 0.02531440
    Epoch:    60     LossContext: 0.02531824
    Epoch:    70     LossContext: 0.02525774
    Epoch:    80     LossContext: 0.02525025
    Epoch:    90     LossContext: 0.02524899
    Epoch:    99     LossContext: 0.02524399

Gradient descent adaptation time: 0 hours 6 mins 19 secs

Adapting to environment 3 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.02862908
    Epoch:     1     LossContext: 0.02853969
    Epoch:     2     LossContext: 0.02844735
    Epoch:     3     LossContext: 0.02835235
    Epoch:    10     LossContext: 0.02765054
    Epoch:    20     LossContext: 0.02688608
    Epoch:    30     LossContext: 0.02674819
    Epoch:    40     LossContext: 0.02677016
    Epoch:    50     LossContext: 0.02673353
    Epoch:    60     LossContext: 0.02671806
    Epoch:    70     LossContext: 0.02670971
    Epoch:    80     LossContext: 0.02669775
    Epoch:    90     LossContext: 0.02668689
    Epoch:    99     LossContext: 0.02667668

Gradient descent adaptation time: 0 hours 6 mins 18 secs
WARNING: No key provided for the context initialization. Initializing at 0.

Saving adaptation parameters into ./runs/30032024-124824/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 4
    Number of adaptation environments: 4
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Test Score (OOD): 0.03162489

Couldn't get a file descriptor referring to the console
==  Begining out-of-distribution visualisation ... ==
    Environment id: 0
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/30032024-124824/adapt/results_ood.png
