
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/29022024-083326/
 Seed: 2026


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/29022024-083326/
 Seed: 4052


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Run folder created successfuly: ./runs/29022024-083326/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 083335
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 083335
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 529397 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 1500
    Total number of training steps: 1500

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (1, 1, 10, 2048) (10,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 10, 2048) (10,)
    Epoch:     0      LossTrajs: 16670.55078125     ContextsNorm: 0.00000000     ValIndCrit: 14036.64550781
    Epoch:     1      LossTrajs: 15997.15039062     ContextsNorm: 0.00000000     ValIndCrit: 13511.75781250
    Epoch:     2      LossTrajs: 15340.59375000     ContextsNorm: 0.00000000     ValIndCrit: 13011.37792969
    Epoch:     3      LossTrajs: 14702.32226562     ContextsNorm: 0.00000000     ValIndCrit: 12533.86328125
    Epoch:   100      LossTrajs: 2081.66210938     ContextsNorm: 0.00000000     ValIndCrit: 2004.96264648
    Epoch:   200      LossTrajs: 1090.43737793     ContextsNorm: 0.00000000     ValIndCrit: 1093.94848633
    Epoch:   300      LossTrajs: 719.80438232     ContextsNorm: 0.00000000     ValIndCrit: 724.48071289
    Epoch:   400      LossTrajs: 526.03906250     ContextsNorm: 0.00000000     ValIndCrit: 519.83862305
    Epoch:   500      LossTrajs: 401.44766235     ContextsNorm: 0.00000000     ValIndCrit: 391.81018066
    Epoch:   600      LossTrajs: 353.87597656     ContextsNorm: 0.00000000     ValIndCrit: 343.55999756
    Epoch:   700      LossTrajs: 312.98727417     ContextsNorm: 0.00000000     ValIndCrit: 302.07696533
    Epoch:   800      LossTrajs: 277.22485352     ContextsNorm: 0.00000000     ValIndCrit: 266.53149414
    Epoch:   900      LossTrajs: 245.64329529     ContextsNorm: 0.00000000     ValIndCrit: 235.94436646
    Epoch:  1000      LossTrajs: 218.02104187     ContextsNorm: 0.00000000     ValIndCrit: 209.75468445
    Epoch:  1100      LossTrajs: 205.55009460     ContextsNorm: 0.00000000     ValIndCrit: 197.91421509
    Epoch:  1200      LossTrajs: 193.67922974     ContextsNorm: 0.00000000     ValIndCrit: 186.62001038
    Epoch:  1300      LossTrajs: 182.44961548     ContextsNorm: 0.00000000     ValIndCrit: 175.88470459
    Epoch:  1400      LossTrajs: 171.85581970     ContextsNorm: 0.00000000     ValIndCrit: 165.70281982
    Epoch:  1499      LossTrajs: 161.95893860     ContextsNorm: 0.00000000     ValIndCrit: 156.15777588

Total gradient descent training time: 0 hours 42 mins 11 secs
Environment weights at the end of the training: [1.]
WARNING: You did not provide a dataloader id. A new one has been generated: 091548
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 1
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Test Score (In-Domain): 156.15778

==  Begining in-domain visualisation ... ==
    Environment id: 0
    Trajectory id: 31
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 10
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/29022024-083326/results_in_domain.png
==  Begining in-domain 2D visualisation ... ==
    Environment id: 0
    Trajectory id: 11
    Length of the testing trajectories: 10
Testing finished. Figure saved in: ./runs/29022024-083326/results_2D_ind.png
Traceback (most recent call last):
  File "/home/gb21553/Projects/Nodax/examples/gray-scott/main.py", line 625, in <module>
    print("Kernel layer 1\n", trainer.learner.neuralode.vectorfield.physics.layers[0].weight)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'layers'
