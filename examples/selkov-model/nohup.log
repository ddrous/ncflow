
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/05042024-183849/
 Seed: 2700


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/05042024-183849/
 Seed: 5400


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Run folder created successfuly: ./runs/05042024-183849/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 183851
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 183851
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 50000 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training with proximal alternating minimization ... ===
    Number of examples in a batch: 4
    Maximum number of steps per inner minimization: 10
    Maximum number of outer minimizations: 1500
    Maximum total number of training steps: 15000

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (21, 4, 11, 2) (11,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (21, 4, 11, 2) (11,)
    Outer Step:     0      LossTrajs: 6.51976824     ContextsNorm: 0.00000000     ValIndCrit: 7.38977575
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.60e-06
        -DiffCxt:  inf
    Outer Step:     1      LossTrajs: 5.48647451     ContextsNorm: 0.00093095     ValIndCrit: 6.26712608
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.54e-06
        -DiffCxt:  9.20e-03
    Outer Step:     2      LossTrajs: 4.57777643     ContextsNorm: 0.00183708     ValIndCrit: 5.27184868
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.06e-06
        -DiffCxt:  2.43e-03
    Outer Step:     3      LossTrajs: 3.77236652     ContextsNorm: 0.00275964     ValIndCrit: 4.38054228
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.38e-06
        -DiffCxt:  1.15e-03
    Outer Step:    25      LossTrajs: 0.40128815     ContextsNorm: 0.02412955     ValIndCrit: 0.77388912
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.73e-07
        -DiffCxt:  2.72e-06
    Outer Step:    50      LossTrajs: 0.17692451     ContextsNorm: 0.02797504     ValIndCrit: 0.42253581
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 7.60e-08
        -DiffCxt:  2.81e-07
    Outer Step:    75      LossTrajs: 0.12650222     ContextsNorm: 0.02862106     ValIndCrit: 0.17999005
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.96e-08
        -DiffCxt:  1.46e-07
    Outer Step:   100      LossTrajs: 0.11114580     ContextsNorm: 0.02857290     ValIndCrit: 0.13547076
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.42e-08
        -DiffCxt:  4.91e-08
    Outer Step:   125      LossTrajs: 0.10482915     ContextsNorm: 0.02866794     ValIndCrit: 0.12384328
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.28e-09
        -DiffCxt:  4.58e-08
    Outer Step:   150      LossTrajs: 0.10184951     ContextsNorm: 0.02876187     ValIndCrit: 0.11964321
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.46e-09
        -DiffCxt:  3.84e-08
    Outer Step:   175      LossTrajs: 0.10048344     ContextsNorm: 0.02875595     ValIndCrit: 0.11801206
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.01e-09
        -DiffCxt:  3.91e-08
    Outer Step:   200      LossTrajs: 0.09949150     ContextsNorm: 0.02861852     ValIndCrit: 0.11734626
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.03e-09
        -DiffCxt:  3.24e-08
    Outer Step:   225      LossTrajs: 0.09896055     ContextsNorm: 0.02872871     ValIndCrit: 0.11698961
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 5.39e-09
        -DiffCxt:  2.91e-08
    Outer Step:   250      LossTrajs: 0.09833339     ContextsNorm: 0.02876450     ValIndCrit: 0.11691199
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.86e-09
        -DiffCxt:  1.02e-07
    Outer Step:   275      LossTrajs: 0.09592115     ContextsNorm: 0.02912202     ValIndCrit: 0.11558121
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 9.43e-08
        -DiffCxt:  5.18e-07
    Outer Step:   300      LossTrajs: 0.06401758     ContextsNorm: 0.02903675     ValIndCrit: 0.08221480
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.34e-08
        -DiffCxt:  3.11e-07
    Outer Step:   325      LossTrajs: 0.06245197     ContextsNorm: 0.02943683     ValIndCrit: 0.08124813
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.25e-08
        -DiffCxt:  7.19e-08
    Outer Step:   350      LossTrajs: 0.06111355     ContextsNorm: 0.02920479     ValIndCrit: 0.08002191
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.02e-08
        -DiffCxt:  8.67e-08
    Outer Step:   375      LossTrajs: 0.05873952     ContextsNorm: 0.02878297     ValIndCrit: 0.07808916
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 5.22e-08
        -DiffCxt:  1.09e-06
    Outer Step:   400      LossTrajs: 0.05475009     ContextsNorm: 0.02913500     ValIndCrit: 0.07503939
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.07e-07
        -DiffCxt:  9.16e-07
    Outer Step:   425      LossTrajs: 0.04856071     ContextsNorm: 0.02959327     ValIndCrit: 0.06946163
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.45e-08
        -DiffCxt:  1.87e-06
    Outer Step:   450      LossTrajs: 0.04579378     ContextsNorm: 0.03002410     ValIndCrit: 0.06925091
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 6.50e-08
        -DiffCxt:  1.00e-06
    Outer Step:   475      LossTrajs: 0.04372475     ContextsNorm: 0.02985699     ValIndCrit: 0.06730447
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.61e-08
        -DiffCxt:  3.91e-07
    Outer Step:   500      LossTrajs: 0.04232891     ContextsNorm: 0.02931762     ValIndCrit: 0.06655029
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.13e-08
        -DiffCxt:  5.05e-07
    Outer Step:   525      LossTrajs: 0.04210759     ContextsNorm: 0.02879736     ValIndCrit: 0.06551696
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.38e-08
        -DiffCxt:  7.12e-07
    Outer Step:   550      LossTrajs: 0.04090320     ContextsNorm: 0.02869397     ValIndCrit: 0.06513907
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.60e-08
        -DiffCxt:  2.14e-06
    Outer Step:   575      LossTrajs: 0.03655271     ContextsNorm: 0.02813134     ValIndCrit: 0.05866840
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 9.10e-08
        -DiffCxt:  1.14e-06
    Outer Step:   600      LossTrajs: 0.03031815     ContextsNorm: 0.02808674     ValIndCrit: 0.04661546
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.48e-08
        -DiffCxt:  1.15e-06
    Outer Step:   625      LossTrajs: 0.02353734     ContextsNorm: 0.02867275     ValIndCrit: 0.03866636
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.39e-07
        -DiffCxt:  6.10e-06
    Outer Step:   650      LossTrajs: 0.01047598     ContextsNorm: 0.02729410     ValIndCrit: 0.02338936
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.73e-08
        -DiffCxt:  4.06e-06
    Outer Step:   675      LossTrajs: 0.00557783     ContextsNorm: 0.02689247     ValIndCrit: 0.01813138
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.19e-08
        -DiffCxt:  2.08e-06
    Outer Step:   700      LossTrajs: 0.00524893     ContextsNorm: 0.02707670     ValIndCrit: 0.01354112
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.93e-08
        -DiffCxt:  8.49e-07
    Outer Step:   725      LossTrajs: 0.00317269     ContextsNorm: 0.02626442     ValIndCrit: 0.01017151
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.57e-08
        -DiffCxt:  1.72e-06
    Outer Step:   750      LossTrajs: 0.00269741     ContextsNorm: 0.02650791     ValIndCrit: 0.00842150
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 5.33e-09
        -DiffCxt:  7.95e-07
    Outer Step:   775      LossTrajs: 0.00234574     ContextsNorm: 0.02716495     ValIndCrit: 0.00756853
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.19e-09
        -DiffCxt:  2.87e-07
    Outer Step:   800      LossTrajs: 0.00272516     ContextsNorm: 0.02677828     ValIndCrit: 0.00829114
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 6.67e-08
        -DiffCxt:  1.22e-06
    Outer Step:   825      LossTrajs: 0.00478722     ContextsNorm: 0.02740546     ValIndCrit: 0.00688531
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.13e-08
        -DiffCxt:  3.88e-06
    Outer Step:   850      LossTrajs: 0.00163167     ContextsNorm: 0.02654602     ValIndCrit: 0.00583577
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.17e-09
        -DiffCxt:  9.02e-08
    Outer Step:   875      LossTrajs: 0.00144322     ContextsNorm: 0.02641395     ValIndCrit: 0.00530158
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.31e-09
        -DiffCxt:  1.67e-07
    Outer Step:   900      LossTrajs: 0.00146139     ContextsNorm: 0.02627908     ValIndCrit: 0.00482683
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.73e-09
        -DiffCxt:  2.31e-07
    Outer Step:   925      LossTrajs: 0.00125957     ContextsNorm: 0.02627683     ValIndCrit: 0.00442027
        -NbInnerStepsNode:    2
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 9.91e-10
        -DiffCxt:  1.10e-07
    Outer Step:   950      LossTrajs: 0.00120936     ContextsNorm: 0.02608239     ValIndCrit: 0.00425312
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 7.33e-09
        -DiffCxt:  1.11e-07
    Outer Step:   975      LossTrajs: 0.00116378     ContextsNorm: 0.02611130     ValIndCrit: 0.00406381
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.99e-09
        -DiffCxt:  3.22e-07
    Outer Step:  1000      LossTrajs: 0.00107101     ContextsNorm: 0.02636371     ValIndCrit: 0.00394408
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.31e-09
        -DiffCxt:  1.95e-07
    Outer Step:  1025      LossTrajs: 0.00094593     ContextsNorm: 0.02611439     ValIndCrit: 0.00403277
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.66e-09
        -DiffCxt:  1.90e-07
    Outer Step:  1050      LossTrajs: 0.00082179     ContextsNorm: 0.02616219     ValIndCrit: 0.00398021
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.59e-09
        -DiffCxt:  2.19e-07
    Outer Step:  1075      LossTrajs: 0.00099399     ContextsNorm: 0.02665392     ValIndCrit: 0.00401089
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.49e-09
        -DiffCxt:  3.66e-07
    Outer Step:  1100      LossTrajs: 0.00073657     ContextsNorm: 0.02676214     ValIndCrit: 0.00466213
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 6.11e-09
        -DiffCxt:  2.91e-07
    Outer Step:  1125      LossTrajs: 0.00078121     ContextsNorm: 0.02717344     ValIndCrit: 0.00571778
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.17e-08
        -DiffCxt:  1.06e-07
    Outer Step:  1150      LossTrajs: 0.00079480     ContextsNorm: 0.02670001     ValIndCrit: 0.00475413
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.53e-08
        -DiffCxt:  2.96e-07
    Outer Step:  1175      LossTrajs: 0.00057381     ContextsNorm: 0.02671510     ValIndCrit: 0.00667676
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.13e-08
        -DiffCxt:  4.87e-07
    Outer Step:  1200      LossTrajs: 0.00063719     ContextsNorm: 0.02655238     ValIndCrit: 0.00658871
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.06e-08
        -DiffCxt:  8.51e-07
    Outer Step:  1225      LossTrajs: 0.00051086     ContextsNorm: 0.02611396     ValIndCrit: 0.00528161
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 7.26e-09
        -DiffCxt:  6.73e-07
    Outer Step:  1250      LossTrajs: 0.00046852     ContextsNorm: 0.02592045     ValIndCrit: 0.00383111
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.40e-09
        -DiffCxt:  1.92e-07
    Outer Step:  1275      LossTrajs: 0.00046814     ContextsNorm: 0.02562730     ValIndCrit: 0.00435542
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 6.21e-10
        -DiffCxt:  1.48e-07
    Outer Step:  1300      LossTrajs: 0.00045262     ContextsNorm: 0.02587498     ValIndCrit: 0.00279361
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.84e-09
        -DiffCxt:  2.43e-07
    Outer Step:  1325      LossTrajs: 0.00046038     ContextsNorm: 0.02610054     ValIndCrit: 0.00290969
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.87e-09
        -DiffCxt:  2.69e-07
    Outer Step:  1350      LossTrajs: 0.00035763     ContextsNorm: 0.02650637     ValIndCrit: 0.00358947
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 5.34e-09
        -DiffCxt:  1.90e-07
    Outer Step:  1375      LossTrajs: 0.00036906     ContextsNorm: 0.02660806     ValIndCrit: 0.00320828
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 6.88e-09
        -DiffCxt:  1.55e-07
    Outer Step:  1400      LossTrajs: 0.00066260     ContextsNorm: 0.02701778     ValIndCrit: 0.00476855
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.29e-08
        -DiffCxt:  5.95e-07
    Outer Step:  1425      LossTrajs: 0.00035607     ContextsNorm: 0.02761816     ValIndCrit: 0.00299681
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.03e-09
        -DiffCxt:  2.63e-07
    Outer Step:  1450      LossTrajs: 0.00066894     ContextsNorm: 0.02773939     ValIndCrit: 0.00299559
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.79e-08
        -DiffCxt:  7.08e-07
    Outer Step:  1475      LossTrajs: 0.00030213     ContextsNorm: 0.02804326     ValIndCrit: 0.00345215
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 5.87e-09
        -DiffCxt:  8.43e-08
    Outer Step:  1499      LossTrajs: 0.00046795     ContextsNorm: 0.02817370     ValIndCrit: 0.00298366
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.61e-08
        -DiffCxt:  1.87e-07

Total gradient descent training time: 1 hours 20 mins 4 secs
Environment weights at the end of the training: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905
 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905
 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905
 0.04761905 0.04761905 0.04761905]
WARNING: You did not provide a dataloader id. A new one has been generated: 195857
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 21
    Final length of the training trajectories: 11
    Length of the testing trajectories: 11
Test Score (In-Domain): 0.0029836586


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.23
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/05042024-183849/adapt/
 Seed: 8100

==  Begining in-domain visualisation ... ==
    Environment id: 0
    Trajectory id: 2
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 11
    Length of the testing trajectories: 11
Testing finished. Figure saved in: ./runs/05042024-183849/results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 1500
    Total number of training steps: 1500

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 11, 2) (11,)
    Epoch:     0     LossContext: 1.29144192
    Epoch:     1     LossContext: 1.13326979
    Epoch:     2     LossContext: 1.20689714
    Epoch:     3     LossContext: 1.17543900
    Epoch:    25     LossContext: 0.49400678
    Epoch:    50     LossContext: 0.08985560
    Epoch:    75     LossContext: 0.00647278
    Epoch:   100     LossContext: 0.00084357
    Epoch:   125     LossContext: 0.00066239
    Epoch:   150     LossContext: 0.00066207
    Epoch:   175     LossContext: 0.00060544
    Epoch:   200     LossContext: 0.00061423
    Epoch:   225     LossContext: 0.00063068
    Epoch:   250     LossContext: 0.00063661
    Epoch:   275     LossContext: 0.00060921
    Epoch:   300     LossContext: 0.00061683
    Epoch:   325     LossContext: 0.00061435
    Epoch:   350     LossContext: 0.00060351
    Epoch:   375     LossContext: 0.00062698
    Epoch:   400     LossContext: 0.00063285
    Epoch:   425     LossContext: 0.00063746
    Epoch:   450     LossContext: 0.00070616
    Epoch:   475     LossContext: 0.00070744
    Epoch:   500     LossContext: 0.00062813
    Epoch:   525     LossContext: 0.00060048
    Epoch:   550     LossContext: 0.00063717
    Epoch:   575     LossContext: 0.00063799
    Epoch:   600     LossContext: 0.00062804
    Epoch:   625     LossContext: 0.00059929
    Epoch:   650     LossContext: 0.00070802
    Epoch:   675     LossContext: 0.00060881
    Epoch:   700     LossContext: 0.00063705
    Epoch:   725     LossContext: 0.00063749
    Epoch:   750     LossContext: 0.00063045
    Epoch:   775     LossContext: 0.00060862
    Epoch:   800     LossContext: 0.00063268
    Epoch:   825     LossContext: 0.00060863
    Epoch:   850     LossContext: 0.00061333
    Epoch:   875     LossContext: 0.00062722
    Epoch:   900     LossContext: 0.00062302
    Epoch:   925     LossContext: 0.00060641
    Epoch:   950     LossContext: 0.00063557
    Epoch:   975     LossContext: 0.00062965
    Epoch:  1000     LossContext: 0.00062318
    Epoch:  1025     LossContext: 0.00063704
    Epoch:  1050     LossContext: 0.00070719
    Epoch:  1075     LossContext: 0.00062832
    Epoch:  1100     LossContext: 0.00061971
    Epoch:  1125     LossContext: 0.00062734
    Epoch:  1150     LossContext: 0.00064417
    Epoch:  1175     LossContext: 0.00061897
    Epoch:  1200     LossContext: 0.00061446
    Epoch:  1225     LossContext: 0.00063833
    Epoch:  1250     LossContext: 0.00061346
    Epoch:  1275     LossContext: 0.00060957
    Epoch:  1300     LossContext: 0.00063066
    Epoch:  1325     LossContext: 0.00061509
    Epoch:  1350     LossContext: 0.00063948
    Epoch:  1375     LossContext: 0.00063998
    Epoch:  1400     LossContext: 0.00064546
    Epoch:  1425     LossContext: 0.00070548
    Epoch:  1450     LossContext: 0.00061992
    Epoch:  1475     LossContext: 0.00064591
    Epoch:  1499     LossContext: 0.00063075

Gradient descent adaptation time: 0 hours 1 mins 10 secs

Adapting to environment 1 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.99598002
    Epoch:     1     LossContext: 0.48206267
    Epoch:     2     LossContext: 0.45436659
    Epoch:     3     LossContext: 0.47760075
    Epoch:    25     LossContext: 0.15976650
    Epoch:    50     LossContext: 0.01309126
    Epoch:    75     LossContext: 0.00188553
    Epoch:   100     LossContext: 0.00054965
    Epoch:   125     LossContext: 0.00071260
    Epoch:   150     LossContext: 0.00085022
    Epoch:   175     LossContext: 0.00162963
    Epoch:   200     LossContext: 0.00117555
    Epoch:   225     LossContext: 0.00085512
    Epoch:   250     LossContext: 0.00051297
    Epoch:   275     LossContext: 0.00074585
    Epoch:   300     LossContext: 0.00058963
    Epoch:   325     LossContext: 0.00049994
    Epoch:   350     LossContext: 0.00091565
    Epoch:   375     LossContext: 0.00081551
    Epoch:   400     LossContext: 0.00449743
    Epoch:   425     LossContext: 0.00062827
    Epoch:   450     LossContext: 0.00057322
    Epoch:   475     LossContext: 0.00127913
    Epoch:   500     LossContext: 0.00090703
    Epoch:   525     LossContext: 0.00101516
    Epoch:   550     LossContext: 0.00109808
    Epoch:   575     LossContext: 0.00095448
    Epoch:   600     LossContext: 0.00089784
    Epoch:   625     LossContext: 0.00050767
    Epoch:   650     LossContext: 0.00083760
    Epoch:   675     LossContext: 0.00054877
    Epoch:   700     LossContext: 0.00051532
    Epoch:   725     LossContext: 0.00230796
    Epoch:   750     LossContext: 0.00063494
    Epoch:   775     LossContext: 0.00056353
    Epoch:   800     LossContext: 0.00050675
    Epoch:   825     LossContext: 0.00234643
    Epoch:   850     LossContext: 0.00260248
    Epoch:   875     LossContext: 0.00082692
    Epoch:   900     LossContext: 0.00101379
    Epoch:   925     LossContext: 0.00070332
    Epoch:   950     LossContext: 0.00037355
    Epoch:   975     LossContext: 0.00093444
    Epoch:  1000     LossContext: 0.00103655
    Epoch:  1025     LossContext: 0.00063116
    Epoch:  1050     LossContext: 0.00100189
    Epoch:  1075     LossContext: 0.00056214
    Epoch:  1100     LossContext: 0.00048487
    Epoch:  1125     LossContext: 0.00137280
    Epoch:  1150     LossContext: 0.00046889
    Epoch:  1175     LossContext: 0.00066510
    Epoch:  1200     LossContext: 0.00072966
    Epoch:  1225     LossContext: 0.00049580
    Epoch:  1250     LossContext: 0.00076860
    Epoch:  1275     LossContext: 0.00058468
    Epoch:  1300     LossContext: 0.00076909
    Epoch:  1325     LossContext: 0.00053590
    Epoch:  1350     LossContext: 0.00067284
    Epoch:  1375     LossContext: 0.00170529
    Epoch:  1400     LossContext: 0.00092741
    Epoch:  1425     LossContext: 0.00080479
    Epoch:  1450     LossContext: 0.00059395
    Epoch:  1475     LossContext: 0.00043419
    Epoch:  1499     LossContext: 0.00049582

Gradient descent adaptation time: 0 hours 1 mins 36 secs

Adapting to environment 2 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.02002377
    Epoch:     1     LossContext: 0.17345628
    Epoch:     2     LossContext: 0.01587018
    Epoch:     3     LossContext: 0.03245315
    Epoch:    25     LossContext: 0.01050683
    Epoch:    50     LossContext: 0.00150825
    Epoch:    75     LossContext: 0.00037918
    Epoch:   100     LossContext: 0.00013637
    Epoch:   125     LossContext: 0.00006123
    Epoch:   150     LossContext: 0.00004560
    Epoch:   175     LossContext: 0.00004347
    Epoch:   200     LossContext: 0.00004333
    Epoch:   225     LossContext: 0.00004333
    Epoch:   250     LossContext: 0.00004332
    Epoch:   275     LossContext: 0.00004332
    Epoch:   300     LossContext: 0.00004331
    Epoch:   325     LossContext: 0.00004331
    Epoch:   350     LossContext: 0.00004330
    Epoch:   375     LossContext: 0.00004330
    Epoch:   400     LossContext: 0.00004329
    Epoch:   425     LossContext: 0.00004328
    Epoch:   450     LossContext: 0.00004328
    Epoch:   475     LossContext: 0.00004327
    Epoch:   500     LossContext: 0.00004326
    Epoch:   525     LossContext: 0.00004327
    Epoch:   550     LossContext: 0.00004326
    Epoch:   575     LossContext: 0.00004325
    Epoch:   600     LossContext: 0.00004323
    Epoch:   625     LossContext: 0.00004325
    Epoch:   650     LossContext: 0.00004325
    Epoch:   675     LossContext: 0.00004324
    Epoch:   700     LossContext: 0.00004322
    Epoch:   725     LossContext: 0.00004323
    Epoch:   750     LossContext: 0.00004323
    Epoch:   775     LossContext: 0.00004322
    Epoch:   800     LossContext: 0.00004322
    Epoch:   825     LossContext: 0.00004322
    Epoch:   850     LossContext: 0.00004321
    Epoch:   875     LossContext: 0.00004321
    Epoch:   900     LossContext: 0.00004320
    Epoch:   925     LossContext: 0.00004320
    Epoch:   950     LossContext: 0.00004319
    Epoch:   975     LossContext: 0.00004319
    Epoch:  1000     LossContext: 0.00004318
    Epoch:  1025     LossContext: 0.00004318
    Epoch:  1050     LossContext: 0.00004318
    Epoch:  1075     LossContext: 0.00004315
    Epoch:  1100     LossContext: 0.00004317
    Epoch:  1125     LossContext: 0.00004317
    Epoch:  1150     LossContext: 0.00004317
    Epoch:  1175     LossContext: 0.00004316
    Epoch:  1200     LossContext: 0.00004316
    Epoch:  1225     LossContext: 0.00004316
    Epoch:  1250     LossContext: 0.00004316
    Epoch:  1275     LossContext: 0.00004315
    Epoch:  1300     LossContext: 0.00004315
    Epoch:  1325     LossContext: 0.00004315
    Epoch:  1350     LossContext: 0.00004314
    Epoch:  1375     LossContext: 0.00004314
    Epoch:  1400     LossContext: 0.00004314
    Epoch:  1425     LossContext: 0.00004313
    Epoch:  1450     LossContext: 0.00004313
    Epoch:  1475     LossContext: 0.00004313
    Epoch:  1499     LossContext: 0.00004312

Gradient descent adaptation time: 0 hours 0 mins 55 secs

Adapting to environment 3 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.06198695
    Epoch:     1     LossContext: 0.03565384
    Epoch:     2     LossContext: 0.06813416
    Epoch:     3     LossContext: 0.03615936
    Epoch:    25     LossContext: 0.00375796
    Epoch:    50     LossContext: 0.00097583
    Epoch:    75     LossContext: 0.00019581
    Epoch:   100     LossContext: 0.00005084
    Epoch:   125     LossContext: 0.00002981
    Epoch:   150     LossContext: 0.00002877
    Epoch:   175     LossContext: 0.00002876
    Epoch:   200     LossContext: 0.00002875
    Epoch:   225     LossContext: 0.00002874
    Epoch:   250     LossContext: 0.00002873
    Epoch:   275     LossContext: 0.00002873
    Epoch:   300     LossContext: 0.00002873
    Epoch:   325     LossContext: 0.00002872
    Epoch:   350     LossContext: 0.00002871
    Epoch:   375     LossContext: 0.00002870
    Epoch:   400     LossContext: 0.00002869
    Epoch:   425     LossContext: 0.00002869
    Epoch:   450     LossContext: 0.00002868
    Epoch:   475     LossContext: 0.00002867
    Epoch:   500     LossContext: 0.00002866
    Epoch:   525     LossContext: 0.00002865
    Epoch:   550     LossContext: 0.00002865
    Epoch:   575     LossContext: 0.00002864
    Epoch:   600     LossContext: 0.00002864
    Epoch:   625     LossContext: 0.00002863
    Epoch:   650     LossContext: 0.00002863
    Epoch:   675     LossContext: 0.00002863
    Epoch:   700     LossContext: 0.00002862
    Epoch:   725     LossContext: 0.00002862
    Epoch:   750     LossContext: 0.00002861
    Epoch:   775     LossContext: 0.00002860
    Epoch:   800     LossContext: 0.00002860
    Epoch:   825     LossContext: 0.00002859
    Epoch:   850     LossContext: 0.00002859
    Epoch:   875     LossContext: 0.00002858
    Epoch:   900     LossContext: 0.00002857
    Epoch:   925     LossContext: 0.00002857
    Epoch:   950     LossContext: 0.00002856
    Epoch:   975     LossContext: 0.00002855
    Epoch:  1000     LossContext: 0.00002855
    Epoch:  1025     LossContext: 0.00002854
    Epoch:  1050     LossContext: 0.00002854
    Epoch:  1075     LossContext: 0.00002854
    Epoch:  1100     LossContext: 0.00002853
    Epoch:  1125     LossContext: 0.00002853
    Epoch:  1150     LossContext: 0.00002852
    Epoch:  1175     LossContext: 0.00002852
    Epoch:  1200     LossContext: 0.00002851
    Epoch:  1225     LossContext: 0.00002851
    Epoch:  1250     LossContext: 0.00002851
    Epoch:  1275     LossContext: 0.00002850
    Epoch:  1300     LossContext: 0.00002850
    Epoch:  1325     LossContext: 0.00002849
    Epoch:  1350     LossContext: 0.00002849
    Epoch:  1375     LossContext: 0.00002849
    Epoch:  1400     LossContext: 0.00002848
    Epoch:  1425     LossContext: 0.00002848
    Epoch:  1450     LossContext: 0.00002847
    Epoch:  1475     LossContext: 0.00002847
    Epoch:  1499     LossContext: 0.00002846

Gradient descent adaptation time: 0 hours 0 mins 55 secs

Adapting to environment 4 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 1.29155064
    Epoch:     1     LossContext: 0.60960877
    Epoch:     2     LossContext: 0.32688773
    Epoch:     3     LossContext: 0.23013964
    Epoch:    25     LossContext: 0.04146887
    Epoch:    50     LossContext: 0.00224957
    Epoch:    75     LossContext: 0.02454436
    Epoch:   100     LossContext: 0.00171852
    Epoch:   125     LossContext: 0.00021571
    Epoch:   150     LossContext: 0.00043061
    Epoch:   175     LossContext: 0.00160802
    Epoch:   200     LossContext: 0.00045983
    Epoch:   225     LossContext: 0.00026741
    Epoch:   250     LossContext: 0.00055942
    Epoch:   275     LossContext: 0.00095039
    Epoch:   300     LossContext: 0.00034021
    Epoch:   325     LossContext: 0.00025103
    Epoch:   350     LossContext: 0.00036798
    Epoch:   375     LossContext: 0.00101972
    Epoch:   400     LossContext: 0.00113729
    Epoch:   425     LossContext: 0.00059368
    Epoch:   450     LossContext: 0.00032551
    Epoch:   475     LossContext: 0.00029534
    Epoch:   500     LossContext: 0.00222979
    Epoch:   525     LossContext: 0.00109286
    Epoch:   550     LossContext: 0.00029293
    Epoch:   575     LossContext: 0.00028247
    Epoch:   600     LossContext: 0.00142420
    Epoch:   625     LossContext: 0.00023474
    Epoch:   650     LossContext: 0.00023698
    Epoch:   675     LossContext: 0.00045024
    Epoch:   700     LossContext: 0.00029579
    Epoch:   725     LossContext: 0.00039424
    Epoch:   750     LossContext: 0.00036967
    Epoch:   775     LossContext: 0.00037095
    Epoch:   800     LossContext: 0.00027740
    Epoch:   825     LossContext: 0.00051754
    Epoch:   850     LossContext: 0.00026623
    Epoch:   875     LossContext: 0.00024943
    Epoch:   900     LossContext: 0.00024328
    Epoch:   925     LossContext: 0.00081893
    Epoch:   950     LossContext: 0.00026796
    Epoch:   975     LossContext: 0.00088929
    Epoch:  1000     LossContext: 0.00030265
    Epoch:  1025     LossContext: 0.00035366
    Epoch:  1050     LossContext: 0.00029956
    Epoch:  1075     LossContext: 0.00021227
    Epoch:  1100     LossContext: 0.00021559
    Epoch:  1125     LossContext: 0.00021121
    Epoch:  1150     LossContext: 0.00050092
    Epoch:  1175     LossContext: 0.00039968
    Epoch:  1200     LossContext: 0.00025152
    Epoch:  1225     LossContext: 0.00026521
    Epoch:  1250     LossContext: 0.00029802
    Epoch:  1275     LossContext: 0.00033339
    Epoch:  1300     LossContext: 0.00029355
    Epoch:  1325     LossContext: 0.00030510
    Epoch:  1350     LossContext: 0.00038151
    Epoch:  1375     LossContext: 0.00031602
    Epoch:  1400     LossContext: 0.00032105
    Epoch:  1425     LossContext: 0.00022876
    Epoch:  1450     LossContext: 0.00026368
    Epoch:  1475     LossContext: 0.00023823
    Epoch:  1499     LossContext: 0.00032627

Gradient descent adaptation time: 0 hours 1 mins 31 secs

Adapting to environment 5 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 1.02219439
    Epoch:     1     LossContext: 0.58539760
    Epoch:     2     LossContext: 0.46547908
    Epoch:     3     LossContext: 0.44603008
    Epoch:    25     LossContext: 0.00249358
    Epoch:    50     LossContext: 0.00632335
    Epoch:    75     LossContext: 0.00268919
    Epoch:   100     LossContext: 0.00245950
    Epoch:   125     LossContext: 0.00244877
    Epoch:   150     LossContext: 0.00244449
    Epoch:   175     LossContext: 0.00243753
    Epoch:   200     LossContext: 0.00243080
    Epoch:   225     LossContext: 0.00242279
    Epoch:   250     LossContext: 0.00241496
    Epoch:   275     LossContext: 0.00240660
    Epoch:   300     LossContext: 0.00239794
    Epoch:   325     LossContext: 0.00234940
    Epoch:   350     LossContext: 0.00234031
    Epoch:   375     LossContext: 0.00233053
    Epoch:   400     LossContext: 0.00231946
    Epoch:   425     LossContext: 0.00230941
    Epoch:   450     LossContext: 0.00229357
    Epoch:   475     LossContext: 0.00227617
    Epoch:   500     LossContext: 0.00225801
    Epoch:   525     LossContext: 0.00225851
    Epoch:   550     LossContext: 0.00224692
    Epoch:   575     LossContext: 0.00224069
    Epoch:   600     LossContext: 0.00223307
    Epoch:   625     LossContext: 0.00222772
    Epoch:   650     LossContext: 0.00222114
    Epoch:   675     LossContext: 0.00221421
    Epoch:   700     LossContext: 0.00220898
    Epoch:   725     LossContext: 0.00220229
    Epoch:   750     LossContext: 0.00219559
    Epoch:   775     LossContext: 0.00220097
    Epoch:   800     LossContext: 0.00219307
    Epoch:   825     LossContext: 0.00218422
    Epoch:   850     LossContext: 0.00217539
    Epoch:   875     LossContext: 0.00216617
    Epoch:   900     LossContext: 0.00215838
    Epoch:   925     LossContext: 0.00214917
    Epoch:   950     LossContext: 0.00213980
    Epoch:   975     LossContext: 0.00213028
    Epoch:  1000     LossContext: 0.00212126
    Epoch:  1025     LossContext: 0.00211683
    Epoch:  1050     LossContext: 0.00211248
    Epoch:  1075     LossContext: 0.00210815
    Epoch:  1100     LossContext: 0.00210357
    Epoch:  1125     LossContext: 0.00209894
    Epoch:  1150     LossContext: 0.00209438
    Epoch:  1175     LossContext: 0.00208952
    Epoch:  1200     LossContext: 0.00208472
    Epoch:  1225     LossContext: 0.00208006
    Epoch:  1250     LossContext: 0.00207514
    Epoch:  1275     LossContext: 0.00207021
    Epoch:  1300     LossContext: 0.00206515
    Epoch:  1325     LossContext: 0.00205981
    Epoch:  1350     LossContext: 0.00205466
    Epoch:  1375     LossContext: 0.00204929
    Epoch:  1400     LossContext: 0.00204397
    Epoch:  1425     LossContext: 0.00203849
    Epoch:  1450     LossContext: 0.00203301
    Epoch:  1475     LossContext: 0.00202765
    Epoch:  1499     LossContext: 0.00202225

Gradient descent adaptation time: 0 hours 0 mins 52 secs
WARNING: No key provided for the context initialization. Initializing at 0.

Saving adaptation parameters into ./runs/05042024-183849/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 21
    Number of adaptation environments: 6
    Final length of the training trajectories: 11
    Length of the testing trajectories: 11
Test Score (OOD): 0.0005505078

==  Begining out-of-distribution visualisation ... ==
    Environment id: 4
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 11
    Length of the testing trajectories: 11
Testing finished. Figure saved in: ./runs/05042024-183849/adapt/results_ood.png
