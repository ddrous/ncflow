
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/04042024-132052/
 Seed: 20


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/04042024-132052/
 Seed: 40


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Run folder created successfuly: ./runs/04042024-132052/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 132102
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 132102
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 50000 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training with proximal alternating minimization ... ===
    Number of examples in a batch: 4
    Maximum number of steps per inner minimization: 10
    Maximum number of outer minimizations: 1500
    Maximum total number of training steps: 15000

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (21, 4, 11, 2) (11,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (21, 4, 11, 2) (11,)
    Outer Step:     0      LossTrajs: 2.54637051     ContextsNorm: 0.00000000     ValIndCrit: 2.10715222
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.59e-06
        -DiffCxt:  inf
    Outer Step:     1      LossTrajs: 2.11090231     ContextsNorm: 0.00086396     ValIndCrit: 1.87978280
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.47e-06
        -DiffCxt:  8.20e-03
    Outer Step:     2      LossTrajs: 1.81619585     ContextsNorm: 0.00166027     ValIndCrit: 1.78128767
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.69e-06
        -DiffCxt:  2.40e-03
    Outer Step:     3      LossTrajs: 1.65160990     ContextsNorm: 0.00244897     ValIndCrit: 1.78571320
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.73e-06
        -DiffCxt:  1.27e-03
    Outer Step:    25      LossTrajs: 0.19729158     ContextsNorm: 0.02386529     ValIndCrit: 0.44344357
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.10e-07
        -DiffCxt:  4.84e-07
    Outer Step:    50      LossTrajs: 0.11921336     ContextsNorm: 0.02476840     ValIndCrit: 0.15620394
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.45e-08
        -DiffCxt:  2.74e-07
    Outer Step:    75      LossTrajs: 0.10573639     ContextsNorm: 0.02542958     ValIndCrit: 0.12546818
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.04e-08
        -DiffCxt:  4.01e-08
    Outer Step:   100      LossTrajs: 0.10184509     ContextsNorm: 0.02562276     ValIndCrit: 0.11856090
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 6.27e-09
        -DiffCxt:  2.44e-08
    Outer Step:   125      LossTrajs: 0.10005891     ContextsNorm: 0.02589765     ValIndCrit: 0.11644045
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.16e-09
        -DiffCxt:  3.36e-08
    Outer Step:   150      LossTrajs: 0.09902762     ContextsNorm: 0.02595495     ValIndCrit: 0.11575081
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.79e-09
        -DiffCxt:  5.83e-08
    Outer Step:   175      LossTrajs: 0.09834274     ContextsNorm: 0.02602919     ValIndCrit: 0.11585344
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.55e-09
        -DiffCxt:  4.06e-07
    Outer Step:   200      LossTrajs: 0.09644140     ContextsNorm: 0.02679792     ValIndCrit: 0.11575449
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.46e-08
        -DiffCxt:  4.44e-07
    Outer Step:   225      LossTrajs: 0.09496514     ContextsNorm: 0.02585057     ValIndCrit: 0.11186702
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.31e-08
        -DiffCxt:  4.36e-06
    Outer Step:   250      LossTrajs: 0.08097856     ContextsNorm: 0.02681445     ValIndCrit: 0.10688708
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.93e-08
        -DiffCxt:  2.16e-06
    Outer Step:   275      LossTrajs: 0.07331894     ContextsNorm: 0.02746376     ValIndCrit: 0.10152806
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.59e-08
        -DiffCxt:  1.12e-06
    Outer Step:   300      LossTrajs: 0.07812699     ContextsNorm: 0.02695715     ValIndCrit: 0.10328841
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.53e-09
        -DiffCxt:  8.76e-07
    Outer Step:   325      LossTrajs: 0.07490817     ContextsNorm: 0.02560991     ValIndCrit: 0.10372841
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 7.89e-09
        -DiffCxt:  9.13e-07
    Outer Step:   350      LossTrajs: 0.07800189     ContextsNorm: 0.02528797     ValIndCrit: 0.10108746
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.89e-09
        -DiffCxt:  4.73e-07
    Outer Step:   375      LossTrajs: 0.14467289     ContextsNorm: 0.02946608     ValIndCrit: 0.17642128
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.25e-08
        -DiffCxt:  7.57e-06
    Outer Step:   400      LossTrajs: 0.16013809     ContextsNorm: 0.03163830     ValIndCrit: 0.15390822
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 5.91e-07
        -DiffCxt:  1.33e-05
    Outer Step:   425      LossTrajs: 0.10207021     ContextsNorm: 0.03809344     ValIndCrit: 0.12773915
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.01e-10
        -DiffCxt:  3.20e-07
    Outer Step:   450      LossTrajs: 0.09321409     ContextsNorm: 0.03924129     ValIndCrit: 0.12004381
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.28e-10
        -DiffCxt:  4.08e-07
    Outer Step:   475      LossTrajs: 0.08928524     ContextsNorm: 0.03949162     ValIndCrit: 0.11582879
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.66e-10
        -DiffCxt:  1.22e-06
    Outer Step:   500      LossTrajs: 0.08837075     ContextsNorm: 0.03929485     ValIndCrit: 0.11317303
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.23e-11
        -DiffCxt:  4.99e-08
    Outer Step:   525      LossTrajs: 0.08907148     ContextsNorm: 0.04027283     ValIndCrit: 0.11336708
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.14e-10
        -DiffCxt:  4.52e-07
    Outer Step:   550      LossTrajs: 0.08871592     ContextsNorm: 0.04025067     ValIndCrit: 0.10949154
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 9.64e-08
        -DiffCxt:  2.65e-06
    Outer Step:   575      LossTrajs: 0.08410606     ContextsNorm: 0.03959463     ValIndCrit: 0.10963026
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.23e-11
        -DiffCxt:  7.11e-07
    Outer Step:   600      LossTrajs: 0.08436988     ContextsNorm: 0.03925116     ValIndCrit: 0.10901825
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.12e-11
        -DiffCxt:  5.15e-07
    Outer Step:   625      LossTrajs: 0.08966944     ContextsNorm: 0.03942310     ValIndCrit: 0.10727608
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.28e-11
        -DiffCxt:  8.67e-07
    Outer Step:   650      LossTrajs: 0.09519430     ContextsNorm: 0.04067041     ValIndCrit: 0.11796179
        -NbInnerStepsNode:   10
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.53e-09
        -DiffCxt:  2.47e-06
    Outer Step:   675      LossTrajs: 0.09290508     ContextsNorm: 0.04298407     ValIndCrit: 0.11642680
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.99e-11
        -DiffCxt:  8.09e-08
    Outer Step:   700      LossTrajs: 0.09251793     ContextsNorm: 0.04277498     ValIndCrit: 0.11485026
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.84e-11
        -DiffCxt:  1.87e-08
    Outer Step:   725      LossTrajs: 0.08859807     ContextsNorm: 0.04301942     ValIndCrit: 0.11485884
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.97e-11
        -DiffCxt:  3.26e-07
    Outer Step:   750      LossTrajs: 0.08943387     ContextsNorm: 0.04372850     ValIndCrit: 0.11551312
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.47e-11
        -DiffCxt:  7.75e-07
    Outer Step:   775      LossTrajs: 0.08694758     ContextsNorm: 0.04303103     ValIndCrit: 0.11332362
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.18e-11
        -DiffCxt:  2.18e-08
    Outer Step:   800      LossTrajs: 0.08834997     ContextsNorm: 0.04376524     ValIndCrit: 0.11520188
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.13e-11
        -DiffCxt:  1.85e-08
    Outer Step:   825      LossTrajs: 0.08610021     ContextsNorm: 0.04348836     ValIndCrit: 0.11361144
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 5.02e-11
        -DiffCxt:  2.00e-08
    Outer Step:   850      LossTrajs: 0.08943392     ContextsNorm: 0.04355388     ValIndCrit: 0.11287400
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 6.52e-11
        -DiffCxt:  1.72e-06
    Outer Step:   875      LossTrajs: 0.08853162     ContextsNorm: 0.04358109     ValIndCrit: 0.11254939
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.50e-11
        -DiffCxt:  1.41e-06
    Outer Step:   900      LossTrajs: 0.08822893     ContextsNorm: 0.04368078     ValIndCrit: 0.11299849
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.60e-11
        -DiffCxt:  4.94e-08
    Outer Step:   925      LossTrajs: 0.08639567     ContextsNorm: 0.04358641     ValIndCrit: 0.11218338
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 5.53e-11
        -DiffCxt:  3.32e-08
    Outer Step:   950      LossTrajs: 0.08645672     ContextsNorm: 0.04400223     ValIndCrit: 0.11285896
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.85e-11
        -DiffCxt:  1.64e-07
    Outer Step:   975      LossTrajs: 0.08340620     ContextsNorm: 0.04354906     ValIndCrit: 0.11144351
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.10e-11
        -DiffCxt:  1.22e-08
    Outer Step:  1000      LossTrajs: 0.08538610     ContextsNorm: 0.04346609     ValIndCrit: 0.11037812
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.03e-11
        -DiffCxt:  2.43e-07
    Outer Step:  1025      LossTrajs: 0.08623300     ContextsNorm: 0.04380110     ValIndCrit: 0.11043751
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.31e-11
        -DiffCxt:  1.55e-08
    Outer Step:  1050      LossTrajs: 0.08595388     ContextsNorm: 0.04386735     ValIndCrit: 0.11036261
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.76e-11
        -DiffCxt:  6.45e-07
    Outer Step:  1075      LossTrajs: 0.08731490     ContextsNorm: 0.04396094     ValIndCrit: 0.11065138
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.33e-11
        -DiffCxt:  1.94e-08
    Outer Step:  1100      LossTrajs: 0.08280842     ContextsNorm: 0.04361221     ValIndCrit: 0.10986174
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.79e-11
        -DiffCxt:  9.90e-08
    Outer Step:  1125      LossTrajs: 0.08081508     ContextsNorm: 0.04340165     ValIndCrit: 0.10850331
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.31e-11
        -DiffCxt:  1.91e-08
    Outer Step:  1150      LossTrajs: 0.08148956     ContextsNorm: 0.04396809     ValIndCrit: 0.10920911
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 4.00e-11
        -DiffCxt:  3.45e-07
    Outer Step:  1175      LossTrajs: 0.08214092     ContextsNorm: 0.04344201     ValIndCrit: 0.10776792
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.44e-11
        -DiffCxt:  2.27e-08
    Outer Step:  1200      LossTrajs: 0.08288296     ContextsNorm: 0.04371016     ValIndCrit: 0.10769868
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.78e-11
        -DiffCxt:  3.47e-07
    Outer Step:  1225      LossTrajs: 0.08105896     ContextsNorm: 0.04375456     ValIndCrit: 0.10760397
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.34e-11
        -DiffCxt:  1.16e-08
    Outer Step:  1250      LossTrajs: 0.08109735     ContextsNorm: 0.04386613     ValIndCrit: 0.10861163
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.64e-11
        -DiffCxt:  1.44e-07
    Outer Step:  1275      LossTrajs: 0.08112562     ContextsNorm: 0.04363938     ValIndCrit: 0.10796213
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.23e-11
        -DiffCxt:  3.17e-07
    Outer Step:  1300      LossTrajs: 0.08375321     ContextsNorm: 0.04388769     ValIndCrit: 0.10883415
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.52e-11
        -DiffCxt:  3.22e-07
    Outer Step:  1325      LossTrajs: 0.08356079     ContextsNorm: 0.04345210     ValIndCrit: 0.10764022
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 6.79e-12
        -DiffCxt:  2.22e-07
    Outer Step:  1350      LossTrajs: 0.08147337     ContextsNorm: 0.04400112     ValIndCrit: 0.10830554
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.44e-11
        -DiffCxt:  1.58e-08
    Outer Step:  1375      LossTrajs: 0.07807201     ContextsNorm: 0.04441034     ValIndCrit: 0.10911548
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 2.75e-11
        -DiffCxt:  1.01e-06
    Outer Step:  1400      LossTrajs: 0.08085650     ContextsNorm: 0.04387941     ValIndCrit: 0.10752173
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    5
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 8.18e-12
        -DiffCxt:  4.28e-08
    Outer Step:  1425      LossTrajs: 0.08032040     ContextsNorm: 0.04384584     ValIndCrit: 0.10711553
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    5
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.04e-11
        -DiffCxt:  4.44e-08
    Outer Step:  1450      LossTrajs: 0.08104780     ContextsNorm: 0.04421739     ValIndCrit: 0.10736990
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.74e-11
        -DiffCxt:  3.91e-08
    Outer Step:  1475      LossTrajs: 0.08346519     ContextsNorm: 0.04459163     ValIndCrit: 0.10805953
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 1.77e-11
        -DiffCxt:  5.61e-07
    Outer Step:  1499      LossTrajs: 0.09243813     ContextsNorm: 0.04337743     ValIndCrit: 0.11791526
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:   10
        -InnerToleranceNode: 1.00e-09
        -InnerToleranceCtx:  5.00e-08
        -DiffNode: 3.43e-11
        -DiffCxt:  1.26e-06

Total gradient descent training time: 1 hours 34 mins 49 secs
Environment weights at the end of the training: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905
 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905
 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905
 0.04761905 0.04761905 0.04761905]
WARNING: You did not provide a dataloader id. A new one has been generated: 145609
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 21
    Final length of the training trajectories: 11
    Length of the testing trajectories: 11
Test Score (In-Domain): 0.11791526


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.14
Available devices: [gpu(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/04042024-132052/adapt/
 Seed: 60

==  Begining in-domain visualisation ... ==
    Environment id: 0
    Trajectory id: 1
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 11
    Length of the testing trajectories: 11
Testing finished. Figure saved in: ./runs/04042024-132052/results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 1500
    Total number of training steps: 1500

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 11, 2) (11,)
    Epoch:     0     LossContext: 0.87675011
    Epoch:     1     LossContext: 0.78283310
    Epoch:     2     LossContext: 0.69899642
    Epoch:     3     LossContext: 0.62352073
    Epoch:    25     LossContext: 0.04468319
    Epoch:    50     LossContext: 0.04557783
    Epoch:    75     LossContext: 0.04364054
    Epoch:   100     LossContext: 0.04349321
    Epoch:   125     LossContext: 0.04347591
    Epoch:   150     LossContext: 0.04344537
    Epoch:   175     LossContext: 0.04341575
    Epoch:   200     LossContext: 0.04338526
    Epoch:   225     LossContext: 0.04335259
    Epoch:   250     LossContext: 0.04331818
    Epoch:   275     LossContext: 0.04328196
    Epoch:   300     LossContext: 0.04324435
    Epoch:   325     LossContext: 0.04320535
    Epoch:   350     LossContext: 0.04316484
    Epoch:   375     LossContext: 0.04312323
    Epoch:   400     LossContext: 0.04308043
    Epoch:   425     LossContext: 0.04303650
    Epoch:   450     LossContext: 0.04299160
    Epoch:   475     LossContext: 0.04294576
    Epoch:   500     LossContext: 0.04289906
    Epoch:   525     LossContext: 0.04287530
    Epoch:   550     LossContext: 0.04285096
    Epoch:   575     LossContext: 0.04282594
    Epoch:   600     LossContext: 0.04280076
    Epoch:   625     LossContext: 0.04277483
    Epoch:   650     LossContext: 0.04274865
    Epoch:   675     LossContext: 0.04272182
    Epoch:   700     LossContext: 0.04269477
    Epoch:   725     LossContext: 0.04266748
    Epoch:   750     LossContext: 0.04263935
    Epoch:   775     LossContext: 0.04261115
    Epoch:   800     LossContext: 0.04258243
    Epoch:   825     LossContext: 0.04255357
    Epoch:   850     LossContext: 0.04252414
    Epoch:   875     LossContext: 0.04249461
    Epoch:   900     LossContext: 0.04246486
    Epoch:   925     LossContext: 0.04243465
    Epoch:   950     LossContext: 0.04240425
    Epoch:   975     LossContext: 0.04237367
    Epoch:  1000     LossContext: 0.04234280
    Epoch:  1025     LossContext: 0.04232732
    Epoch:  1050     LossContext: 0.04231154
    Epoch:  1075     LossContext: 0.04229573
    Epoch:  1100     LossContext: 0.04227969
    Epoch:  1125     LossContext: 0.04226337
    Epoch:  1150     LossContext: 0.04224692
    Epoch:  1175     LossContext: 0.04223038
    Epoch:  1200     LossContext: 0.04221352
    Epoch:  1225     LossContext: 0.04219672
    Epoch:  1250     LossContext: 0.04217961
    Epoch:  1275     LossContext: 0.04216233
    Epoch:  1300     LossContext: 0.04214500
    Epoch:  1325     LossContext: 0.04212749
    Epoch:  1350     LossContext: 0.04210985
    Epoch:  1375     LossContext: 0.04209219
    Epoch:  1400     LossContext: 0.04207439
    Epoch:  1425     LossContext: 0.04205626
    Epoch:  1450     LossContext: 0.04203817
    Epoch:  1475     LossContext: 0.04202017
    Epoch:  1499     LossContext: 0.04200258

Gradient descent adaptation time: 0 hours 1 mins 32 secs

Adapting to environment 1 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.59962565
    Epoch:     1     LossContext: 0.49074674
    Epoch:     2     LossContext: 0.39669064
    Epoch:     3     LossContext: 0.31926805
    Epoch:    25     LossContext: 0.17827615
    Epoch:    50     LossContext: 0.17054242
    Epoch:    75     LossContext: 0.17024899
    Epoch:   100     LossContext: 0.16995178
    Epoch:   125     LossContext: 0.16963108
    Epoch:   150     LossContext: 0.16927387
    Epoch:   175     LossContext: 0.16888763
    Epoch:   200     LossContext: 0.16847306
    Epoch:   225     LossContext: 0.16803157
    Epoch:   250     LossContext: 0.16756943
    Epoch:   275     LossContext: 0.16708511
    Epoch:   300     LossContext: 0.16658123
    Epoch:   325     LossContext: 0.16606167
    Epoch:   350     LossContext: 0.16552520
    Epoch:   375     LossContext: 0.16497691
    Epoch:   400     LossContext: 0.16441563
    Epoch:   425     LossContext: 0.16384380
    Epoch:   450     LossContext: 0.16326420
    Epoch:   475     LossContext: 0.16267824
    Epoch:   500     LossContext: 0.16208732
    Epoch:   525     LossContext: 0.16178888
    Epoch:   550     LossContext: 0.16148585
    Epoch:   575     LossContext: 0.16117853
    Epoch:   600     LossContext: 0.16086759
    Epoch:   625     LossContext: 0.16055220
    Epoch:   650     LossContext: 0.16023542
    Epoch:   675     LossContext: 0.15991558
    Epoch:   700     LossContext: 0.15959457
    Epoch:   725     LossContext: 0.15927126
    Epoch:   750     LossContext: 0.15894815
    Epoch:   775     LossContext: 0.15862381
    Epoch:   800     LossContext: 0.15829970
    Epoch:   825     LossContext: 0.15797661
    Epoch:   850     LossContext: 0.15765491
    Epoch:   875     LossContext: 0.15733409
    Epoch:   900     LossContext: 0.15701556
    Epoch:   925     LossContext: 0.15670015
    Epoch:   950     LossContext: 0.15638712
    Epoch:   975     LossContext: 0.15607798
    Epoch:  1000     LossContext: 0.15577309
    Epoch:  1025     LossContext: 0.15562168
    Epoch:  1050     LossContext: 0.15547055
    Epoch:  1075     LossContext: 0.15531868
    Epoch:  1100     LossContext: 0.15516692
    Epoch:  1125     LossContext: 0.15501580
    Epoch:  1150     LossContext: 0.15486433
    Epoch:  1175     LossContext: 0.15471341
    Epoch:  1200     LossContext: 0.15456249
    Epoch:  1225     LossContext: 0.15441251
    Epoch:  1250     LossContext: 0.15426300
    Epoch:  1275     LossContext: 0.15411445
    Epoch:  1300     LossContext: 0.15396678
    Epoch:  1325     LossContext: 0.15381956
    Epoch:  1350     LossContext: 0.15367375
    Epoch:  1375     LossContext: 0.15352914
    Epoch:  1400     LossContext: 0.15338592
    Epoch:  1425     LossContext: 0.15324450
    Epoch:  1450     LossContext: 0.15310375
    Epoch:  1475     LossContext: 0.15296517
    Epoch:  1499     LossContext: 0.15283364

Gradient descent adaptation time: 0 hours 1 mins 11 secs

Adapting to environment 2 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.02431374
    Epoch:     1     LossContext: 0.01208409
    Epoch:     2     LossContext: 0.01459322
    Epoch:     3     LossContext: 0.01787799
    Epoch:    25     LossContext: 0.01163914
    Epoch:    50     LossContext: 0.01165696
    Epoch:    75     LossContext: 0.01163459
    Epoch:   100     LossContext: 0.01163177
    Epoch:   125     LossContext: 0.01162831
    Epoch:   150     LossContext: 0.01162493
    Epoch:   175     LossContext: 0.01162163
    Epoch:   200     LossContext: 0.01161828
    Epoch:   225     LossContext: 0.01161504
    Epoch:   250     LossContext: 0.01161177
    Epoch:   275     LossContext: 0.01160871
    Epoch:   300     LossContext: 0.01160567
    Epoch:   325     LossContext: 0.01160204
    Epoch:   350     LossContext: 0.01159924
    Epoch:   375     LossContext: 0.01159652
    Epoch:   400     LossContext: 0.01159391
    Epoch:   425     LossContext: 0.01159137
    Epoch:   450     LossContext: 0.01158893
    Epoch:   475     LossContext: 0.01158663
    Epoch:   500     LossContext: 0.01158442
    Epoch:   525     LossContext: 0.01158334
    Epoch:   550     LossContext: 0.01158229
    Epoch:   575     LossContext: 0.01158129
    Epoch:   600     LossContext: 0.01158024
    Epoch:   625     LossContext: 0.01157923
    Epoch:   650     LossContext: 0.01157824
    Epoch:   675     LossContext: 0.01157729
    Epoch:   700     LossContext: 0.01157633
    Epoch:   725     LossContext: 0.01157541
    Epoch:   750     LossContext: 0.01157448
    Epoch:   775     LossContext: 0.01157723
    Epoch:   800     LossContext: 0.01157279
    Epoch:   825     LossContext: 0.01157200
    Epoch:   850     LossContext: 0.01157116
    Epoch:   875     LossContext: 0.01157041
    Epoch:   900     LossContext: 0.01156966
    Epoch:   925     LossContext: 0.01156893
    Epoch:   950     LossContext: 0.01156819
    Epoch:   975     LossContext: 0.01156755
    Epoch:  1000     LossContext: 0.01156691
    Epoch:  1025     LossContext: 0.01156658
    Epoch:  1050     LossContext: 0.01156629
    Epoch:  1075     LossContext: 0.01156595
    Epoch:  1100     LossContext: 0.01156567
    Epoch:  1125     LossContext: 0.01156538
    Epoch:  1150     LossContext: 0.01156509
    Epoch:  1175     LossContext: 0.01156475
    Epoch:  1200     LossContext: 0.01156448
    Epoch:  1225     LossContext: 0.01156424
    Epoch:  1250     LossContext: 0.01156394
    Epoch:  1275     LossContext: 0.01156363
    Epoch:  1300     LossContext: 0.01156335
    Epoch:  1325     LossContext: 0.01156307
    Epoch:  1350     LossContext: 0.01156280
    Epoch:  1375     LossContext: 0.01156257
    Epoch:  1400     LossContext: 0.01156233
    Epoch:  1425     LossContext: 0.01156206
    Epoch:  1450     LossContext: 0.01156184
    Epoch:  1475     LossContext: 0.01156163
    Epoch:  1499     LossContext: 0.01156137

Gradient descent adaptation time: 0 hours 1 mins 30 secs

Adapting to environment 3 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 0.21893305
    Epoch:     1     LossContext: 0.14340575
    Epoch:     2     LossContext: 0.08124471
    Epoch:     3     LossContext: 0.03673917
    Epoch:    25     LossContext: 0.01370275
    Epoch:    50     LossContext: 0.00728621
    Epoch:    75     LossContext: 0.00705734
    Epoch:   100     LossContext: 0.00699225
    Epoch:   125     LossContext: 0.00694597
    Epoch:   150     LossContext: 0.00689482
    Epoch:   175     LossContext: 0.00684049
    Epoch:   200     LossContext: 0.00678314
    Epoch:   225     LossContext: 0.00672270
    Epoch:   250     LossContext: 0.00665996
    Epoch:   275     LossContext: 0.00659498
    Epoch:   300     LossContext: 0.00652802
    Epoch:   325     LossContext: 0.00645995
    Epoch:   350     LossContext: 0.00639037
    Epoch:   375     LossContext: 0.00632035
    Epoch:   400     LossContext: 0.00624933
    Epoch:   425     LossContext: 0.00617775
    Epoch:   450     LossContext: 0.00610577
    Epoch:   475     LossContext: 0.00603359
    Epoch:   500     LossContext: 0.00596076
    Epoch:   525     LossContext: 0.00592463
    Epoch:   550     LossContext: 0.00588784
    Epoch:   575     LossContext: 0.00585020
    Epoch:   600     LossContext: 0.00581213
    Epoch:   625     LossContext: 0.00577399
    Epoch:   650     LossContext: 0.00573509
    Epoch:   675     LossContext: 0.00569576
    Epoch:   700     LossContext: 0.00565664
    Epoch:   725     LossContext: 0.00561674
    Epoch:   750     LossContext: 0.00557676
    Epoch:   775     LossContext: 0.00553664
    Epoch:   800     LossContext: 0.00549619
    Epoch:   825     LossContext: 0.00545555
    Epoch:   850     LossContext: 0.00541461
    Epoch:   875     LossContext: 0.00537366
    Epoch:   900     LossContext: 0.00533283
    Epoch:   925     LossContext: 0.00529179
    Epoch:   950     LossContext: 0.00525062
    Epoch:   975     LossContext: 0.00520955
    Epoch:  1000     LossContext: 0.00516858
    Epoch:  1025     LossContext: 0.00514773
    Epoch:  1050     LossContext: 0.00512716
    Epoch:  1075     LossContext: 0.00510607
    Epoch:  1100     LossContext: 0.00508492
    Epoch:  1125     LossContext: 0.00506352
    Epoch:  1150     LossContext: 0.00504207
    Epoch:  1175     LossContext: 0.00502025
    Epoch:  1200     LossContext: 0.00499854
    Epoch:  1225     LossContext: 0.00497627
    Epoch:  1250     LossContext: 0.00495445
    Epoch:  1275     LossContext: 0.00493211
    Epoch:  1300     LossContext: 0.00490975
    Epoch:  1325     LossContext: 0.00488710
    Epoch:  1350     LossContext: 0.00486449
    Epoch:  1375     LossContext: 0.00484169
    Epoch:  1400     LossContext: 0.00481839
    Epoch:  1425     LossContext: 0.00479557
    Epoch:  1450     LossContext: 0.00477256
    Epoch:  1475     LossContext: 0.00474937
    Epoch:  1499     LossContext: 0.00472742

Gradient descent adaptation time: 0 hours 1 mins 27 secs

Adapting to environment 4 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 1.86880624
    Epoch:     1     LossContext: 1.63899291
    Epoch:     2     LossContext: 1.41097236
    Epoch:     3     LossContext: 1.18988717
    Epoch:    25     LossContext: 0.24716412
    Epoch:    50     LossContext: 0.16497944
    Epoch:    75     LossContext: 0.16162831
    Epoch:   100     LossContext: 0.16156684
    Epoch:   125     LossContext: 0.16151187
    Epoch:   150     LossContext: 0.16149469
    Epoch:   175     LossContext: 0.16148242
    Epoch:   200     LossContext: 0.16145778
    Epoch:   225     LossContext: 0.16144173
    Epoch:   250     LossContext: 0.16140726
    Epoch:   275     LossContext: 0.16138457
    Epoch:   300     LossContext: 0.16135727
    Epoch:   325     LossContext: 0.16133621
    Epoch:   350     LossContext: 0.16131751
    Epoch:   375     LossContext: 0.16128039
    Epoch:   400     LossContext: 0.16124712
    Epoch:   425     LossContext: 0.16121875
    Epoch:   450     LossContext: 0.16119154
    Epoch:   475     LossContext: 0.16115688
    Epoch:   500     LossContext: 0.16112058
    Epoch:   525     LossContext: 0.16110931
    Epoch:   550     LossContext: 0.16109346
    Epoch:   575     LossContext: 0.16107130
    Epoch:   600     LossContext: 0.16106553
    Epoch:   625     LossContext: 0.16103671
    Epoch:   650     LossContext: 0.16101839
    Epoch:   675     LossContext: 0.16099733
    Epoch:   700     LossContext: 0.16098906
    Epoch:   725     LossContext: 0.16096544
    Epoch:   750     LossContext: 0.16093804
    Epoch:   775     LossContext: 0.16092737
    Epoch:   800     LossContext: 0.16090378
    Epoch:   825     LossContext: 0.16087885
    Epoch:   850     LossContext: 0.16085765
    Epoch:   875     LossContext: 0.16084024
    Epoch:   900     LossContext: 0.16081899
    Epoch:   925     LossContext: 0.16079456
    Epoch:   950     LossContext: 0.16077231
    Epoch:   975     LossContext: 0.16076033
    Epoch:  1000     LossContext: 0.16072825
    Epoch:  1025     LossContext: 0.16071516
    Epoch:  1050     LossContext: 0.16069594
    Epoch:  1075     LossContext: 0.16069655
    Epoch:  1100     LossContext: 0.16068311
    Epoch:  1125     LossContext: 0.16067262
    Epoch:  1150     LossContext: 0.16065703
    Epoch:  1175     LossContext: 0.16064310
    Epoch:  1200     LossContext: 0.16062792
    Epoch:  1225     LossContext: 0.16061628
    Epoch:  1250     LossContext: 0.16059707
    Epoch:  1275     LossContext: 0.16058403
    Epoch:  1300     LossContext: 0.16058348
    Epoch:  1325     LossContext: 0.16056791
    Epoch:  1350     LossContext: 0.16053456
    Epoch:  1375     LossContext: 0.16053286
    Epoch:  1400     LossContext: 0.16051418
    Epoch:  1425     LossContext: 0.16050287
    Epoch:  1450     LossContext: 0.16048709
    Epoch:  1475     LossContext: 0.16047029
    Epoch:  1499     LossContext: 0.16044939

Gradient descent adaptation time: 0 hours 1 mins 24 secs

Adapting to environment 5 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed
    Epoch:     0     LossContext: 1.53393495
    Epoch:     1     LossContext: 1.33792090
    Epoch:     2     LossContext: 1.14709485
    Epoch:     3     LossContext: 0.96543312
    Epoch:    25     LossContext: 0.25967026
    Epoch:    50     LossContext: 0.20396946
    Epoch:    75     LossContext: 0.20332398
    Epoch:   100     LossContext: 0.20254907
    Epoch:   125     LossContext: 0.20199744
    Epoch:   150     LossContext: 0.20137523
    Epoch:   175     LossContext: 0.20068984
    Epoch:   200     LossContext: 0.19993594
    Epoch:   225     LossContext: 0.19911346
    Epoch:   250     LossContext: 0.19822288
    Epoch:   275     LossContext: 0.19726440
    Epoch:   300     LossContext: 0.19623388
    Epoch:   325     LossContext: 0.19512895
    Epoch:   350     LossContext: 0.19394763
    Epoch:   375     LossContext: 0.19268532
    Epoch:   400     LossContext: 0.19133909
    Epoch:   425     LossContext: 0.18990488
    Epoch:   450     LossContext: 0.18837883
    Epoch:   475     LossContext: 0.18675627
    Epoch:   500     LossContext: 0.18503276
    Epoch:   525     LossContext: 0.18412329
    Epoch:   550     LossContext: 0.18317063
    Epoch:   575     LossContext: 0.18217625
    Epoch:   600     LossContext: 0.18113697
    Epoch:   625     LossContext: 0.18005252
    Epoch:   650     LossContext: 0.17892119
    Epoch:   675     LossContext: 0.17774129
    Epoch:   700     LossContext: 0.17651640
    Epoch:   725     LossContext: 0.17523915
    Epoch:   750     LossContext: 0.17391104
    Epoch:   775     LossContext: 0.17252903
    Epoch:   800     LossContext: 0.17109613
    Epoch:   825     LossContext: 0.16960520
    Epoch:   850     LossContext: 0.16806449
    Epoch:   875     LossContext: 0.16646224
    Epoch:   900     LossContext: 0.16480273
    Epoch:   925     LossContext: 0.16309123
    Epoch:   950     LossContext: 0.16131622
    Epoch:   975     LossContext: 0.15948519
    Epoch:  1000     LossContext: 0.15759434
    Epoch:  1025     LossContext: 0.15662466
    Epoch:  1050     LossContext: 0.15562299
    Epoch:  1075     LossContext: 0.15460339
    Epoch:  1100     LossContext: 0.15355545
    Epoch:  1125     LossContext: 0.15248717
    Epoch:  1150     LossContext: 0.15139170
    Epoch:  1175     LossContext: 0.15026999
    Epoch:  1200     LossContext: 0.14912030
    Epoch:  1225     LossContext: 0.14795192
    Epoch:  1250     LossContext: 0.14675584
    Epoch:  1275     LossContext: 0.14553176
    Epoch:  1300     LossContext: 0.14428525
    Epoch:  1325     LossContext: 0.14301448
    Epoch:  1350     LossContext: 0.14171976
    Epoch:  1375     LossContext: 0.14039491
    Epoch:  1400     LossContext: 0.13904980
    Epoch:  1425     LossContext: 0.13767640
    Epoch:  1450     LossContext: 0.13628185
    Epoch:  1475     LossContext: 0.13486370
    Epoch:  1499     LossContext: 0.13347559

Gradient descent adaptation time: 0 hours 1 mins 27 secs
WARNING: No key provided for the context initialization. Initializing at 0.

Saving adaptation parameters into ./runs/04042024-132052/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 21
    Number of adaptation environments: 6
    Final length of the training trajectories: 11
    Length of the testing trajectories: 11
Test Score (OOD): 0.083800934

==  Begining out-of-distribution visualisation ... ==
    Environment id: 1
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 11
    Length of the testing trajectories: 11
Testing finished. Figure saved in: ./runs/04042024-132052/adapt/results_ood.png
