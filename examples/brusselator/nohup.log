Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/21112024-212158/
 Seed: 2026

Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/21112024-212158/
 Seed: 4052

Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/21112024-212158/adapt/
 Seed: 6078

Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt_test
 Savepath: ./runs/21112024-212158/adapt/
 Seed: 6078


############# Neural Context Flow #############

Jax version: 0.4.35
Available devices: [CudaDevice(id=0)]
Run folder created successfuly: ./runs/21112024-212158/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 212215
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: You did not provide a dataloader id. A new one has been generated: 212215
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 117502 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training with proximal alternating minimization ... ===
    Number of examples in a batch: 12
    Maximum number of steps per inner minimization: 20
    Maximum number of outer minimizations: 150
    Maximum total number of training steps: 3000

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (9, 12, 20, 128) (20,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (9, 12, 20, 128) (20,)
    Outer Step:     0      LossTrajs: 4.33880901     ContextsNorm: 0.00000000     ValIndCrit: 4.30899191
        Saving best model so far ...
        -NbInnerStepsNode:    1
        -NbInnerStepsCxt:    1
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 7.02e-04
        -DiffCxt:  inf
    Outer Step:     1      LossTrajs: 2.00718665     ContextsNorm: 0.02268054     ValIndCrit: 2.09103870
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 4.34e-04
        -DiffCxt:  3.73e-03
    Outer Step:     2      LossTrajs: 1.87387228     ContextsNorm: 0.03895722     ValIndCrit: 1.88362420
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 9.75e-05
        -DiffCxt:  5.38e-04
    Outer Step:     3      LossTrajs: 2.00728273     ContextsNorm: 0.03406818     ValIndCrit: 2.07669449
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 4.94e-06
        -DiffCxt:  3.78e-04
    Outer Step:    10      LossTrajs: 1.71446860     ContextsNorm: 0.03509998     ValIndCrit: 1.82976508
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 6.55e-08
        -DiffCxt:  1.92e-05
    Outer Step:    20      LossTrajs: 1.57581878     ContextsNorm: 0.03869852     ValIndCrit: 1.65087390
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 7.22e-08
        -DiffCxt:  4.85e-07
    Outer Step:    30      LossTrajs: 1.55015743     ContextsNorm: 0.03877636     ValIndCrit: 1.61895883
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.27e-07
        -DiffCxt:  9.36e-08
    Outer Step:    40      LossTrajs: 1.54267442     ContextsNorm: 0.03884573     ValIndCrit: 1.61069560
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 3.91e-07
        -DiffCxt:  1.36e-07
    Outer Step:    50      LossTrajs: 1.53423643     ContextsNorm: 0.03812679     ValIndCrit: 1.60497844
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.44e-07
        -DiffCxt:  6.88e-07
    Outer Step:    60      LossTrajs: 1.52463925     ContextsNorm: 0.03776665     ValIndCrit: 1.59697056
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 6.22e-08
        -DiffCxt:  4.38e-07
    Outer Step:    70      LossTrajs: 1.51088226     ContextsNorm: 0.03751673     ValIndCrit: 1.58386326
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.06e-07
        -DiffCxt:  1.55e-06
    Outer Step:    80      LossTrajs: 1.49659824     ContextsNorm: 0.03738520     ValIndCrit: 1.56673181
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 6.55e-08
        -DiffCxt:  1.50e-06
    Outer Step:    90      LossTrajs: 1.48345256     ContextsNorm: 0.03754777     ValIndCrit: 1.54986703
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 7.78e-08
        -DiffCxt:  4.25e-07
    Outer Step:   100      LossTrajs: 1.46777022     ContextsNorm: 0.03694518     ValIndCrit: 1.53014016
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.57e-07
        -DiffCxt:  1.93e-06
    Outer Step:   110      LossTrajs: 1.44530368     ContextsNorm: 0.03672628     ValIndCrit: 1.50848961
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.04e-07
        -DiffCxt:  4.60e-07
    Outer Step:   120      LossTrajs: 1.39938605     ContextsNorm: 0.03583631     ValIndCrit: 1.46816337
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 1.91e-07
        -DiffCxt:  9.51e-08
    Outer Step:   130      LossTrajs: 1.34405100     ContextsNorm: 0.03500433     ValIndCrit: 1.42397201
        Saving best model so far ...
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: 5.31e-07
        -DiffCxt:  3.87e-05
    Outer Step:   140      LossTrajs: nan     ContextsNorm: nan     ValIndCrit: nan
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: nan
        -DiffCxt:  nan
    Outer Step:   149      LossTrajs: nan     ContextsNorm: nan     ValIndCrit: nan
        -NbInnerStepsNode:   20
        -NbInnerStepsCxt:   20
        -InnerToleranceNode: 1.00e-16
        -InnerToleranceCtx:  1.00e-16
        -DiffNode: nan
        -DiffCxt:  nan

Total gradient descent training time: 1 hours 5 mins 15 secs
Environment weights at the end of the training: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111
 0.11111111 0.11111111 0.11111111]
WARNING: You did not provide a dataloader id. A new one has been generated: 222732
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 9
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (In-Domain): 1.423972

==  Begining in-domain visualisation ... ==
    Environment id: 2
    Trajectory id: 7
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/21112024-212158/results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


=== Beginning sequential adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 1500
    Total number of training steps: 1500

Adapting to environment 0 ...
WARNING: You are demanding a shuffled dataset but did not provide any keys for that.
WARNING: No key provided, using time as seed
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (1, 1, 20, 128) (20,)
Traceback (most recent call last):
  File "/home/gb21553/Projects/NCFlow/examples/brusselator/main_T2_scaling.py", line 301, in <module>
    trainer.train_proximal(nb_outer_steps_max=nb_outer_steps_max, 
  File "/home/gb21553/Projects/NCFlow/nodax/trainer.py", line 297, in train_proximal
    node, contexts, opt_state_node, loss_node, (nb_steps_node_, term1, term2, diff_node_) = train_step_node(node, node_old, contexts, batch, weights, opt_state_node, loss_key)
  File "/home/gb21553/Projects/NCFlow/nodax/trainer.py", line 227, in train_step_node
    (loss, aux_data), grads = eqx.filter_value_and_grad(prox_loss_fn, has_aux=True)(node, contexts, batch, weights, key)
  File "/home/gb21553/Projects/NCFlow/nodax/trainer.py", line 223, in prox_loss_fn
    loss, aux_data = loss_fn(node, contexts, batch, weights, key)
  File "/home/gb21553/Projects/NCFlow/nodax/learner.py", line 26, in <lambda>
    self.loss_fn = lambda model, contexts, batch, weights, key: loss_fn(model, contexts, batch, weights, loss_fn_ctx, key)
  File "/home/gb21553/Projects/NCFlow/nodax/learner.py", line 277, in loss_fn
    all_loss, (all_nb_steps, all_term1, all_term2) = jax.vmap(loss_fn_ctx, in_axes=(None, 0, None, 0, None, None))(model, Xs[:, :, :, :], t_eval, contexts.params, contexts.params, key)
  File "/home/gb21553/Projects/NCFlow/examples/brusselator/main_T2_scaling.py", line 257, in loss_fn_ctx
    trajs_hat, nb_steps = jax.vmap(model, in_axes=(None, None, None, 0))(trajs[:, 0, :], t_eval, ctx, ctx_s)
  File "/home/gb21553/Projects/NCFlow/nodax/learner.py", line 139, in __call__
    return jax.vmap(integrate)(x0s)
  File "/home/gb21553/Projects/NCFlow/nodax/learner.py", line 113, in integrate
    sol = diffrax.diffeqsolve(
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/diffrax/_integrate.py", line 1423, in diffeqsolve
    sol = result.error_if(sol, jnp.invert(is_okay(result)))
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/equinox/_unvmap.py", line 80, in unvmap_max
    return cast(Array, unvmap_max_p.bind(x))
jax._src.source_info_util.JaxStackTraceBeforeTransformation: ValueError: zero-size array to reduction operation max which has no identity

The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gb21553/Projects/NCFlow/examples/brusselator/main_T2_scaling.py", line 465, in <module>
    trainer.adapt_sequential(adapt_dataloader, nb_epochs=nb_epochs_adapt, optimizer=opt_adapt, print_error_every=print_error_every, save_path=adapt_folder)
  File "/home/gb21553/Projects/NCFlow/nodax/trainer.py", line 639, in adapt_sequential
    node, context, opt_state, loss, (nb_steps_, term1, term2) = train_step(node, context, batch, weights, opt_state, loss_key)
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/equinox/_jit.py", line 275, in __call__
    return self._call(False, args, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/equinox/_module.py", line 1096, in __call__
    return self.__func__(self.__self__, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/equinox/_jit.py", line 244, in _call
    marker, _, _ = out = self._cached(
                         ^^^^^^^^^^^^^
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/equinox/_unvmap.py", line 84, in _unvmap_max_impl
    return jnp.max(x)
           ^^^^^^^^^^
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/jax/_src/numpy/reductions.py", line 459, in max
    return _reduce_max(a, axis=_ensure_optional_axes(axis), out=out,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/jax/_src/numpy/reductions.py", line 384, in _reduce_max
    return _reduction(a, "max", np.max, lax.max, -np.inf, has_identity=False,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gb21553/miniconda3/envs/jax/lib/python3.12/site-packages/jax/_src/numpy/reductions.py", line 116, in _reduction
    raise ValueError(f"zero-size array to reduction operation {name} which has no identity")
ValueError: zero-size array to reduction operation max which has no identity
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
