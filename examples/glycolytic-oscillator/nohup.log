Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/17022024-104027/
 Seed: 2026

Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/17022024-104027/
 Seed: 4052

Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/17022024-104027/adapt/
 Seed: 6078


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]
Data folder created successfuly: ./runs/17022024-104027/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 104047
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: You did not provide a dataloader id. A new one has been generated: 104047
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 319911 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training ... ===
    Number of examples in a batch: 4
    Number of train steps per epoch: 1
    Number of training epochs: 24000
    Total number of training steps: 24000

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (9, 4, 20, 7) (20,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (9, 4, 20, 7) (20,)
    Epoch:     0      LossTrajs: 0.34723818     ContextsNorm: 0.00000000     ValIndCrit: 0.34152010
    Epoch:     1      LossTrajs: 0.30881241     ContextsNorm: 0.00020662     ValIndCrit: 0.30847868
    Epoch:     2      LossTrajs: 0.27640679     ContextsNorm: 0.00041702     ValIndCrit: 0.28143620
    Epoch:     3      LossTrajs: 0.25024748     ContextsNorm: 0.00063654     ValIndCrit: 0.26066950
    Epoch:  1000      LossTrajs: 0.00721235     ContextsNorm: 0.05857073     ValIndCrit: 0.04702786
    Epoch:  2000      LossTrajs: 0.00326752     ContextsNorm: 0.06860913     ValIndCrit: 0.03058908
    Epoch:  3000      LossTrajs: 0.00239492     ContextsNorm: 0.07509123     ValIndCrit: 0.02454148
    Epoch:  4000      LossTrajs: 0.00107134     ContextsNorm: 0.08310269     ValIndCrit: 0.02656134
    Epoch:  5000      LossTrajs: 0.00065975     ContextsNorm: 0.09638612     ValIndCrit: 0.03273949
    Epoch:  6000      LossTrajs: 0.00053955     ContextsNorm: 0.10029094     ValIndCrit: 0.02608804
    Epoch:  7000      LossTrajs: 0.00180310     ContextsNorm: 0.10303105     ValIndCrit: 0.02388812
    Epoch:  8000      LossTrajs: 0.00037864     ContextsNorm: 0.10285693     ValIndCrit: 0.02549764
    Epoch:  9000      LossTrajs: 0.00033221     ContextsNorm: 0.10301345     ValIndCrit: 0.02767505
    Epoch: 10000      LossTrajs: 0.00031346     ContextsNorm: 0.10325626     ValIndCrit: 0.03135622
    Epoch: 11000      LossTrajs: 0.00027678     ContextsNorm: 0.10339222     ValIndCrit: 0.03929656
