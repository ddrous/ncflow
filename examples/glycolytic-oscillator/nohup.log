
############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: train
 Savepath: ./runs/24022024-230441/
 Seed: 2026


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: test
 Savepath: ./runs/24022024-230441/
 Seed: 4052


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]
Running this script in ipython (Jupyter) session ? False
=== Parsed arguments to generate data ===
 Split: adapt
 Savepath: ./runs/24022024-230441/adapt/
 Seed: 6078


############# Inductive Bias Learning for Dynamical Systems #############

Jax version: 0.4.19
Available devices: [cuda(id=0)]
Data folder created successfuly: ./runs/24022024-230441/
Completed copied scripts 
WARNING: You did not provide a dataloader id. A new one has been generated: 230649
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: You did not provide a dataloader id. A new one has been generated: 230649
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.


Total number of parameters in the model: 47303 


WARNING: No key provided for the context initialization. Initializing at 0.
WARNING: No key provided, using time as seed


=== Beginning training ... ===
    Number of examples in a batch: 32
    Number of train steps per epoch: 1
    Number of training epochs: 24000
    Total number of training steps: 24000

Compiling function "train_step" for neural ode ...
Shapes of elements in a batch: (9, 32, 20, 7) (20,)

Compiling function "train_step" for context ...
Shapes of elements in a batch: (9, 32, 20, 7) (20,)
    Epoch:     0      LossTrajs: 0.37900388     ContextsNorm: 0.00000000     ValIndCrit: 0.34141138
    Epoch:     1      LossTrajs: 0.33987069     ContextsNorm: 0.00042312     ValIndCrit: 0.30818683
    Epoch:     2      LossTrajs: 0.30647290     ContextsNorm: 0.00084323     ValIndCrit: 0.28107119
    Epoch:     3      LossTrajs: 0.27930894     ContextsNorm: 0.00126379     ValIndCrit: 0.26024070
    Epoch:  1000      LossTrajs: 0.00714550     ContextsNorm: 0.13303085     ValIndCrit: 0.00926127
    Epoch:  2000      LossTrajs: 0.00483281     ContextsNorm: 0.18125743     ValIndCrit: 0.00693495
    Epoch:  3000      LossTrajs: 0.00367378     ContextsNorm: 0.20268086     ValIndCrit: 0.00492932
    Epoch:  4000      LossTrajs: 0.00334507     ContextsNorm: 0.20607893     ValIndCrit: 0.00473821
    Epoch:  5000      LossTrajs: 0.00308303     ContextsNorm: 0.22700305     ValIndCrit: 0.00445523
    Epoch:  6000      LossTrajs: 0.00240074     ContextsNorm: 0.24036942     ValIndCrit: 0.00410946
    Epoch:  7000      LossTrajs: 0.00250769     ContextsNorm: 0.24818823     ValIndCrit: 0.00444893
    Epoch:  8000      LossTrajs: 0.00262021     ContextsNorm: 0.26231617     ValIndCrit: 0.00464937
    Epoch:  9000      LossTrajs: 0.00194848     ContextsNorm: 0.26296145     ValIndCrit: 0.00393860
    Epoch: 10000      LossTrajs: 0.00188006     ContextsNorm: 0.26329672     ValIndCrit: 0.00400658
    Epoch: 11000      LossTrajs: 0.00185312     ContextsNorm: 0.26433125     ValIndCrit: 0.00413260
    Epoch: 12000      LossTrajs: 0.00179350     ContextsNorm: 0.26396647     ValIndCrit: 0.00417814
    Epoch: 13000      LossTrajs: 0.00215199     ContextsNorm: 0.26270241     ValIndCrit: 0.00441424
    Epoch: 14000      LossTrajs: 0.00171060     ContextsNorm: 0.26339880     ValIndCrit: 0.00429746
    Epoch: 15000      LossTrajs: 0.00166242     ContextsNorm: 0.26443583     ValIndCrit: 0.00434384
    Epoch: 16000      LossTrajs: 0.00162628     ContextsNorm: 0.26341835     ValIndCrit: 0.00440637
    Epoch: 17000      LossTrajs: 0.00162009     ContextsNorm: 0.26355726     ValIndCrit: 0.00443489
    Epoch: 18000      LossTrajs: 0.00158603     ContextsNorm: 0.26367548     ValIndCrit: 0.00442654
    Epoch: 19000      LossTrajs: 0.00159544     ContextsNorm: 0.26374060     ValIndCrit: 0.00445637
    Epoch: 20000      LossTrajs: 0.00157530     ContextsNorm: 0.26394734     ValIndCrit: 0.00448408
    Epoch: 21000      LossTrajs: 0.00156575     ContextsNorm: 0.26403889     ValIndCrit: 0.00447635
    Epoch: 22000      LossTrajs: 0.00156315     ContextsNorm: 0.26421922     ValIndCrit: 0.00449939
    Epoch: 23000      LossTrajs: 0.00155536     ContextsNorm: 0.26433861     ValIndCrit: 0.00450426
    Epoch: 23999      LossTrajs: 0.00152310     ContextsNorm: 0.26437342     ValIndCrit: 0.00451461

Total gradient descent training time: 1 hours 57 mins 15 secs
Environment weights at the end of the training: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111
 0.11111111 0.11111111 0.11111111]
WARNING: You did not provide a dataloader id. A new one has been generated: 010414
WARNING: Note that this id used to distuinguish between adaptations to different environments.
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided, using time as seed
==  Begining in-domain testing ... ==
    Number of training environments: 9
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (In-Domain): 0.004514607

==  Begining in-domain visualisation ... ==
    Environment id: 7
    Trajectory id: 9
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/24022024-230441/results_in_domain.png
WARNING: batch_size must be between 0 and nb_trajs_per_env. Setting batch_size to maximum.
WARNING: No key provided for the context initialization. Initializing at 0.


=== Beginning adaptation ... ===
    Number of examples in a batch: 1
    Number of train steps per epoch: 1
    Number of training epochs: 24000
    Total number of training steps: 24000
WARNING: No key provided, using time as seed

Compiling function "train_step" for context ...
Shapes of elements in a batch: (4, 1, 20, 7) (20,)
    Epoch:     0     LossContext: 0.01222937
    Epoch:     1     LossContext: 0.01210346
    Epoch:     2     LossContext: 0.01197230
    Epoch:     3     LossContext: 0.01183485
    Epoch:  1000     LossContext: 0.00196688
    Epoch:  2000     LossContext: 0.00195134
    Epoch:  3000     LossContext: 0.00193291
    Epoch:  4000     LossContext: 0.00188423
    Epoch:  5000     LossContext: 0.00185932
    Epoch:  6000     LossContext: 0.00185573
    Epoch:  7000     LossContext: 0.00186984
    Epoch:  8000     LossContext: 0.00179037
    Epoch:  9000     LossContext: 0.00181659
    Epoch: 10000     LossContext: 0.00181327
    Epoch: 11000     LossContext: 0.00178586
    Epoch: 12000     LossContext: 0.00174446
    Epoch: 13000     LossContext: 0.00184779
    Epoch: 14000     LossContext: 0.00180653
    Epoch: 15000     LossContext: 0.00184471
    Epoch: 16000     LossContext: 0.00184315
    Epoch: 17000     LossContext: 0.00180333
    Epoch: 18000     LossContext: 0.00177590
    Epoch: 19000     LossContext: 0.00184244
    Epoch: 20000     LossContext: 0.00180250
    Epoch: 21000     LossContext: 0.00180253
    Epoch: 22000     LossContext: 0.00177515
    Epoch: 23000     LossContext: 0.00184187
    Epoch: 23999     LossContext: 0.00173508

Total gradient descent adaptation time: 0 hours 23 mins 50 secs
Environment weights at the end of the adaptation: [0.25 0.25 0.25 0.25]

Saving adaptation parameters into ./runs/24022024-230441/adapt/ folder with id 170846 ...

==  Begining out-of-distribution testing ... ==
    Number of training environments: 9
    Number of adaptation environments: 4
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Test Score (OOD): 0.0018020284

sh: 1: open: not found
==  Begining out-of-distribution visualisation ... ==
    Environment id: 3
    Trajectory id: 0
    Visualized dimensions: (0, 1)
    Final length of the training trajectories: 20
    Length of the testing trajectories: 20
Testing finished. Figure saved in: ./runs/24022024-230441/adapt/results_ood.png
